[
    {
        "name": "Alex Morgan",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, learning-first environment that values clear communication, ownership, and production-quality engineering. Prefers teams that balance research with pragmatic delivery and emphasize mentoring and continuous improvement.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "San Francisco, CA, USA"
            },
            "phone": "+1-415-555-0123",
            "email": "alex.morgan@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-morgan-ai",
            "github": "https://github.com/alexmorgan-ai"
        },
        "summary": "AI Engineer with 9+ years building and productionizing deep learning and ML systems for recommendation, search, and NLP. Strong background in model architecture, MLOps, and scalable inference on cloud and edge. Experienced in leading cross-functional teams to ship high-impact features and reduce costs while improving model performance and latency.",
        "experience": [
            {
                "name": "NovaAI Labs \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multimodal recommendation system (text + image) that increased CTR by 19% and revenue per user by 12%.",
                    "Built end-to-end MLOps workflows (data validation, CI/CD for models, automated monitoring) using Terraform, Kubernetes, ArgoCD, and Kubeflow; reduced model rollout time from weeks to days.",
                    "Implemented model distillation and quantization pipelines enabling 3x inference speedup and 2.5x reduction in serving costs on GPU clusters.",
                    "Mentored a team of 4 ML engineers and collaborated with product and infra to define KPIs, A/B experiments, and rollout strategy."
                ]
            },
            {
                "name": "DeepSense Technologies \u2014 AI Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed NLP production services (entity extraction, intent classification, semantic search) using Transformers and FAISS, improving query relevance by 28%.",
                    "Implemented a low-latency serving stack with TensorFlow Serving and Redis-based caching; reduced 95th percentile latency from 420ms to 120ms.",
                    "Led initiative to transition models to AWS SageMaker and containerized inference, standardizing deployments and permissions across teams.",
                    "Collaborated on privacy-preserving data pipelines and automated retraining schedules to mitigate model drift."
                ]
            },
            {
                "name": "Orbital Analytics \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built end-to-end pipelines for structured and unstructured data; created feature stores and reproducible training pipelines.",
                    "Prototyped CNN and RNN models for document classification and OCR post-processing, achieving 92% accuracy on validation sets.",
                    "Worked closely with data engineering to optimize ETL jobs and reduce training data latency for nightly model updates."
                ]
            }
        ],
        "projects": [
            {
                "name": "Raven \u2014 Multimodal Recommendation Engine",
                "description": "Production recommender combining text embeddings and image features with a two-stage retrieval + re-rank architecture. Includes online A/B testing, personalization signals, and real-time feature updates.",
                "technologies": [
                    "PyTorch",
                    "FAISS",
                    "Kubernetes",
                    "Kafka",
                    "Redis"
                ],
                "year": 2023
            },
            {
                "name": "EdgeNLP \u2014 Mobile-friendly Inference Stack",
                "description": "Optimized Transformer-based models for on-device inference using quantization, pruning, and ONNX Runtime; integrated with CI to produce size-optimized builds for Android/iOS.",
                "technologies": [
                    "ONNX",
                    "TensorRT",
                    "ONNX Runtime",
                    "Torch",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "AutoTrain \u2014 Automated Model Training Pipeline",
                "description": "AutoML-style pipeline that automates feature engineering, hyperparameter tuning, and model selection for tabular and text tasks; includes automated model validation and deployment hooks.",
                "technologies": [
                    "Kubeflow",
                    "scikit-learn",
                    "XGBoost",
                    "Optuna"
                ],
                "year": 2019
            },
            {
                "name": "SentimentAnalyzer \u2014 Scalable Sentiment Service",
                "description": "Microservice for sentiment classification with streaming ingestion and near-real-time dashboards for analytics; used by product to monitor user sentiment shifts.",
                "technologies": [
                    "TensorFlow",
                    "Flask",
                    "Elasticsearch",
                    "Prometheus"
                ],
                "year": 2017
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Artificial Intelligence)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Electrical Engineering & Computer Science"
            }
        ],
        "skills": [
            "Deep Learning (Transformers, CNNs, RNNs)",
            "PyTorch",
            "TensorFlow",
            "Model Serving (TensorFlow Serving, TorchServe, ONNX Runtime)",
            "MLOps (Kubeflow, Argo, MLflow)",
            "Cloud (AWS, GCP)",
            "Kubernetes & Docker",
            "Retrieval (FAISS, Annoy)",
            "NLP & Semantic Search",
            "Python, SQL",
            "Data Engineering (Spark, Kafka)",
            "Model Monitoring & A/B testing"
        ],
        "achievements": [
            "Improved production recommendation CTR by 19% and revenue per user by 12% at NovaAI Labs",
            "Reduced model serving latency (95th percentile) from 420ms to 120ms at DeepSense Technologies",
            "Published a benchmarking study on quantization strategies for Transformer models (internal whitepaper)",
            "Led team efforts that cut model deployment time from weeks to days via CI/CD and MLOps practices"
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2021
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Data-driven, collaborative, and mentorship-focused; values continuous learning, reproducibility, and clear product impact.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "Based in San Francisco Bay Area"
            },
            "phone": "+1-415-555-0123",
            "email": "aisha.rahman@email.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 7+ years building production ML systems and analytics platforms for healthcare and e-commerce. Strong background in end-to-end model development, feature engineering, and deploying scalable pipelines on cloud infrastructure. Experienced mentoring teams and translating business problems into measurable ML solutions.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nova Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development of a predictive hospital readmission model that reduced 30-day readmission rate by 12% for two major hospital partners, improving patient outcomes and saving an estimated $2.1M annually.",
                    "Designed and productionized real-time inference pipeline using AWS SageMaker, Lambda, and DynamoDB, supporting 100k+ daily predictions with <100ms latency.",
                    "Mentored a team of 4 data scientists and established code review, model governance, and MLflow-based experiment tracking practices.",
                    "Collaborated with product and clinical teams to define KPIs, A/B test model variants, and integrate models into clinician workflows."
                ]
            },
            {
                "name": "Machine Learning Engineer, Helix Health",
                "date": {
                    "start": 2019,
                    "end": 2021
                },
                "bullets": [
                    "Built NLP pipeline to extract structured clinical features from EHR notes using spaCy and transformer-based models, increasing structured capture by 45%.",
                    "Implemented CI/CD for models with Docker, Kubernetes, and Argo Workflows, reducing deployment time from weeks to hours.",
                    "Optimized model inference costs by 35% through model quantization and batching; wrote performance monitoring dashboards in Grafana."
                ]
            },
            {
                "name": "Data Engineer / ML Consultant (Freelance)",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Delivered end-to-end recommendation engine for an e-commerce client using collaborative filtering and LightGBM; increased click-through-rate by 18%.",
                    "Built ETL and feature stores using Airflow, Spark, and PostgreSQL to support multiple analytics and ML use cases.",
                    "Advised startups on instrumentation, data quality, and A/B testing best practices; produced reproducible notebooks and technical documentation."
                ]
            }
        ],
        "projects": [
            {
                "name": "Predictive Hospital Readmission Model",
                "description": "Developed a tabular ML model combining EHR features and NLP-derived signals to predict 30-day readmission risk; integrated into clinical workflow with risk stratification alerts.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "spaCy",
                    "AWS SageMaker",
                    "MLflow"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Built a hybrid recommendation system (matrix factorization + session-based embeddings) serving personalized suggestions with sub-100ms latency.",
                "technologies": [
                    "Spark",
                    "LightGBM",
                    "Redis",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "tslab: Open-source Time Series Feature Library",
                "description": "Authored a Python library for scalable time-series feature extraction and preprocessing used in several internal forecasting pipelines.",
                "technologies": [
                    "Python",
                    "pandas",
                    "numba",
                    "pytest"
                ],
                "year": 2020
            },
            {
                "name": "Resume Parser & Candidate Matcher",
                "description": "Created an NLP-based resume parser and skill-matching tool to rank candidates against job requirements, increasing recruiter throughput by 40%.",
                "technologies": [
                    "spaCy",
                    "transformers",
                    "PostgreSQL",
                    "FastAPI"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Computer Science",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "University of Toronto \u2014 B.Sc. Computer Science",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.Sc. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "SQL",
            "Spark",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLflow",
            "Airflow",
            "NLP",
            "Computer Vision"
        ],
        "achievements": [
            "Delivered models in production that generated >$2M annualized value through reduced readmissions and operational efficiencies.",
            "Published an open-source time-series feature library adopted by multiple engineering teams.",
            "Presented work at NeurIPS workshop and internal healthcare ML symposium."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified ScrumMaster (CSM)",
                "date": 2019
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Ravi Kapoor",
        "title": "Data Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, outcome-driven, and engineering-first with emphasis on automation and continuous improvement",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala"
            },
            "phone": "+91-98450-12345",
            "email": "ravi.kapoor@email.com",
            "linkedin": "linkedin.com/in/ravikapoor",
            "github": "github.com/ravikapoor"
        },
        "summary": "Data Engineer with 7+ years building scalable data platforms and ETL pipelines for fintech and e-commerce. Experienced with Spark, Kafka, Airflow, dbt, and cloud data warehouses (Snowflake, BigQuery). Proven track record delivering low-latency streaming ingestion, reproducible ELT, and performance-tuned analytics pipelines that drive product and business decisions.",
        "experience": [
            {
                "name": "Senior Data Engineer, Finlytics (fintech analytics)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Designed and owned streaming ingestion platform using Kafka + Spark Structured Streaming, supporting 100k events/sec and reducing end-to-end latency from 15s to under 2s.",
                    "Led migration of analytical data warehouse from Redshift to Snowflake; reimplemented 120+ dbt models, cutting monthly compute costs by 28% and improving query performance on key dashboards by 3x.",
                    "Built CI/CD pipelines for dbt + Airflow with automated data quality tests, reducing incidents due to schema drift by 80%.",
                    "Mentored 4 junior engineers, established coding standards and review practices for SQL and PySpark."
                ]
            },
            {
                "name": "Data Engineer, PayGrid (payments platform)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Implemented event-driven ETL with Kafka Connect and Apache Flink to enrich payment events and populate real-time analytics tables used for fraud detection.",
                    "Developed partitioning and clustering strategies in BigQuery that reduced query costs by 40% for monthly reports serving product and risk teams.",
                    "Created reusable ingestion templates and Airflow DAGs, accelerating onboarding of new data sources from weeks to days."
                ]
            },
            {
                "name": "Data Engineering Intern, AI Research Labs",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Built preprocessing pipelines for large text corpora using Spark; improved downstream model training throughput by 2x.",
                    "Automated data validation checks and logging, surfacing quality issues early in the development lifecycle."
                ]
            }
        ],
        "projects": [
            {
                "name": "Customer 360 Data Platform",
                "description": "End-to-end platform to unify customer events, transactions and CRM data into a single analytics schema. Included ELT pipelines, identity resolution, and materialized views for marketing and product analytics.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "dbt",
                    "Snowflake",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Fraud Scoring Pipeline",
                "description": "Streaming pipeline that enriches transaction events and computes fraud scores in sub-second latency, feeding alerts to downstream risk systems.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Cost-aware BigQuery Refactor",
                "description": "Refactored large analytics dataset into partitioned and clustered tables with templated SQL to reduce storage and query costs while preserving SLAs for dashboards.",
                "technologies": [
                    "BigQuery",
                    "SQL",
                    "Airflow"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Technology, Kanpur",
                "date": {
                    "start": 2013,
                    "end": 2017
                },
                "degree": "B.Tech, Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PySpark",
            "SQL",
            "Apache Spark",
            "Kafka",
            "Airflow",
            "dbt",
            "Snowflake",
            "BigQuery",
            "Flink",
            "Kubernetes",
            "ETL/ELT design",
            "Data modeling",
            "Data quality and observability"
        ],
        "achievements": [
            "Reduced analytics query costs by 28% after Snowflake migration and model optimization.",
            "Delivered streaming ingestion platform handling 100k events/sec with sub-2s latency.",
            "Presented internal tech talk on building cost-efficient ELT pipelines; adopted across two business units."
        ],
        "certifications": [
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2022
            },
            {
                "name": "Databricks Certified Data Engineer Associate",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Maya R. Singh",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused, data-driven; emphasis on cross-functional partnership and continuous learning",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Downtown / willing to relocate"
            },
            "phone": "+1-206-555-0147",
            "email": "maya.singh.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-singh",
            "github": "https://github.com/mayar-singh"
        },
        "summary": "AI Engineer with 6+ years building and deploying production ML systems for personalization, search relevance, and computer vision. Strong background in deep learning, MLOps, and model optimization. Experienced in leading cross-functional efforts from research prototyping to scalable production services.",
        "experience": [
            {
                "name": "Senior AI Engineer, Search & Personalization \u2014 Nimbus Media",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a hybrid deep-learning ranking model that improved click-through rate (CTR) by 12% and reduced latency by 25% using distilled transformer encoders and feature caching.",
                    "Built end-to-end training pipelines with TF 2.x and PyTorch on Kubernetes and Kubeflow, enabling weekly retraining and A/B experiments.",
                    "Implemented model monitoring (drift detection, slice metrics) and automated rollback procedures, reducing incident mean time to resolution by 40%.",
                    "Mentored a team of 3 ML engineers and collaborated with product and infra teams to define KPIs and production SLAs."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 Helix Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed a CNN-based medical image segmentation pipeline that increased diagnostic sensitivity from 78% to 88% while maintaining specificity, validated on multi-site datasets.",
                    "Designed data augmentation, domain adaptation, and class-balancing strategies to improve model generalization across scanners and populations.",
                    "Worked closely with MLOps to containerize models, integrate them into CI/CD, and deploy inference services using AWS ECS and SageMaker endpoints.",
                    "Authored reproducible evaluation suites and documentation to support regulatory review and clinical evaluation."
                ]
            },
            {
                "name": "Data Scientist \u2014 BrightCart (e-commerce startup)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built recommendation models (matrix factorization + session-based RNN) that increased average order value by 9%.",
                    "Implemented A/B testing frameworks and instrumentation for online experiments; translated results into shipping priorities.",
                    "Developed ETL pipelines with Airflow and Spark to process clickstream and transaction data for feature generation."
                ]
            }
        ],
        "projects": [
            {
                "name": "Compact Transformer Ranking",
                "description": "Designed and distilled a compact transformer-based ranking model for low-latency serving on CPU instances. Combined knowledge distillation, quantization, and token pruning to achieve a 4x throughput improvement with <2% relative accuracy loss.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "DistilBERT",
                    "Quantization",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Cross-Domain Medical Segmentation",
                "description": "Implemented domain-adaptive segmentation using adversarial feature alignment and self-supervised pretraining to improve performance across heterogeneous imaging devices.",
                "technologies": [
                    "TensorFlow",
                    "UNet",
                    "Domain Adaptation",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Personalized Recommender Microservice",
                "description": "Built a recommender microservice that combined collaborative filtering with content-based neural embeddings; served predictions via a low-latency gRPC API and supported online feature updates.",
                "technologies": [
                    "Spark",
                    "TensorFlow",
                    "gRPC",
                    "Redis"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Machine Learning specialization)"
            },
            {
                "name": "University of Delhi",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Deep Learning",
            "PyTorch",
            "TensorFlow",
            "MLOps",
            "Model Deployment",
            "Kubernetes",
            "Docker",
            "Python",
            "SQL",
            "Spark",
            "ONNX",
            "Model Monitoring",
            "A/B Testing"
        ],
        "achievements": [
            "Published 2 workshop papers on efficient transformer compression and model monitoring best practices (NeurIPS workshops).",
            "Led cross-team initiative that reduced model inference cost by 38% through batching, caching, and model compression.",
            "Recipient of 'Engineering Excellence' award at Nimbus Media for impactful model improvements (2022)."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2022
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Alexandra Chen",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, fast-paced environment with emphasis on mentorship and cross-functional impact",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "1354 Market St, Suite 400, 94103"
            },
            "phone": "+1 (415) 555-1287",
            "email": "alexandra.chen@example.com",
            "linkedin": "https://www.linkedin.com/in/alexandra-chen-ds",
            "github": "https://github.com/alexchen-ds"
        },
        "summary": "Data scientist with 7+ years of experience building production ML systems and analytics solutions for fintech and SaaS. Strong background in statistical modeling, time series forecasting, and end-to-end model deployment. Proven track record of improving revenue forecasting accuracy, reducing fraud false positives, and partnering with product and engineering to deliver business impact. Comfortable leading small teams and mentoring junior data scientists.",
        "experience": [
            {
                "name": "Nimbus Analytics \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of a real-time fraud scoring pipeline (Spark + Kafka) that reduced false positive rate by 30% while maintaining 95% fraud capture.",
                    "Designed and deployed a probabilistic customer lifetime value (CLV) model used by sales and finance to prioritize accounts; model increased targeted upsell conversions by 12%.",
                    "Architected A/B testing framework and statistical analysis workflows that accelerated feature rollouts and reduced experiment analysis time by 40%.",
                    "Mentored 4 junior data scientists and established code-review and model validation standards across the team."
                ]
            },
            {
                "name": "AeroPay \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built demand forecasting models (Prophet, LSTM ensembles) for subscription revenue; improved 12-week forecast MAPE from 18% to 9%.",
                    "Collaborated with engineering to containerize models (Docker) and implement CI/CD for ML using GitLab pipelines, reducing deployment time from weeks to days.",
                    "Performed cohort analysis and churn modeling to identify at-risk segments; targeted interventions reduced churn by 7% in pilot programs.",
                    "Automated ETL and feature pipelines with Airflow and dbt, increasing analyst productivity and enabling near real-time reporting."
                ]
            },
            {
                "name": "BrightEdge \u2014 Data Science Intern",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Implemented an NLP-based sentiment scoring system for customer feedback that improved topic classification precision by 20%.",
                    "Produced interactive dashboards and KPIs for product and support teams using Tableau and Looker."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Fraud Scoring Platform",
                "description": "End-to-end fraud detection system processing streaming transactions with feature enrichment, model scoring, and adaptive thresholds for alerts. Integrated model monitoring and drift detection.",
                "technologies": [
                    "Python",
                    "Spark",
                    "Kafka",
                    "AWS (Kinesis, Lambda)",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Subscription Revenue Forecasting",
                "description": "Built ensemble forecasting pipeline combining Prophet, XGBoost, and LSTM to generate rolling 12-week revenue forecasts with automated feature engineering and backtesting.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "TensorFlow",
                    "Airflow",
                    "dbt"
                ],
                "year": 2022
            },
            {
                "name": "ML Deployment & CI/CD Framework",
                "description": "Designed a reusable CI/CD template for model packaging, testing, and deployment using GitLab, Docker, and Kubernetes; reduced deployment friction for data teams.",
                "technologies": [
                    "Docker",
                    "Kubernetes",
                    "GitLab CI",
                    "MLflow"
                ],
                "year": 2021
            },
            {
                "name": "Customer Sentiment Analyzer",
                "description": "NLP pipeline for multi-channel customer feedback classification and sentiment scoring used to prioritize product improvements.",
                "technologies": [
                    "Python",
                    "spaCy",
                    "scikit-learn"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Carnegie Mellon University \u2014 M.S. in Data Science",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "degree": "Master of Science in Data Science"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S. in Statistics",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "degree": "Bachelor of Science in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "TensorFlow",
            "PyTorch",
            "XGBoost",
            "Spark",
            "Airflow",
            "dbt",
            "Docker",
            "Kubernetes",
            "AWS (S3, EC2, Lambda, SageMaker)",
            "MLflow",
            "Time Series Forecasting",
            "Experiment Design",
            "A/B Testing",
            "NLP"
        ],
        "achievements": [
            "Reduced fraud false positive rate by 30% while preserving detection rate through model and feature improvements.",
            "Improved medium-term revenue forecast accuracy (12-week MAPE) from 18% to 9% using ensemble models.",
            "Speaker at a regional data science meetup on production ML pipelines (2023).",
            "Established team-wide model validation and monitoring standards adopted across two product lines."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Databricks Certified Data Engineer Associate",
                "date": 2021
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Ethan Park",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-minded teams that prioritize mentorship, data-driven decision making, and responsible AI practices.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-1287",
            "email": "ethan.park.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/ethan-park",
            "github": "https://github.com/ethanpark"
        },
        "summary": "AI Engineer with 7+ years building production ML systems, specializing in deep learning, model optimization, and scalable inference. Experience delivering end-to-end solutions from experimentation and model training to deployment and monitoring. Passionate about MLOps, latency optimization, and mentoring engineers.",
        "experience": [
            {
                "name": "Senior AI Engineer, Dynamo AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of a multimodal recommendation model (text + image) that increased click-through-rate by 18% and revenue per user by 9%.",
                    "Designed and implemented a PyTorch Lightning training pipeline with mixed precision, distributed training (DDP), and automated hyperparameter sweeps, reducing training iteration time by 3x.",
                    "Built low-latency TensorRT-backed inference service and model sharding; reduced 99th percentile latency from 360ms to 85ms under peak load.",
                    "Introduced CI/CD for models using MLflow and GitHub Actions; established A/B testing and rollout policies, lowering failed deploy rate by 70%.",
                    "Mentored 4 junior engineers and led weekly model reviews and reproducibility practices."
                ]
            },
            {
                "name": "Data Scientist, InsightAnalytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built customer segmentation and propensity models using gradient boosting (XGBoost/LightGBM) and deep learning, improving targeted campaign conversion by 26%.",
                    "Created feature store primitives and automated ETL jobs (Airflow + Spark) to ensure reproducible features across training and serving.",
                    "Collaborated with product and infra teams to deploy models to Kubernetes with Seldon Core, monitored drift and retrained models on schedule.",
                    "Optimized model inference cost via quantization and batching, cutting serving costs by 40%."
                ]
            },
            {
                "name": "Machine Learning Engineer (Intern \u2192 Full-time), Nova Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Prototyped convolutional neural network architectures for image classification tasks; improved baseline accuracy by 11% through data augmentation and architecture changes.",
                    "Implemented experiment tracking and reproducible pipelines using DVC and Jenkins.",
                    "Authored internal guidelines for model evaluation and validation used across teams."
                ]
            }
        ],
        "projects": [
            {
                "name": "SmartSearch \u2014 Document Retrieval System",
                "description": "Built a semantic search system combining dense retrieval (Sentence-BERT) with a lightweight re-ranker. Achieved a 28% improvement in relevant-first retrieval metrics and reduced average query latency to 120ms.",
                "technologies": [
                    "PyTorch",
                    "Transformers",
                    "Faiss",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2024
            },
            {
                "name": "Real-time Fraud Detector",
                "description": "Designed a streaming fraud detection pipeline using streaming feature extraction and an ensemble model to flag anomalies in real-time, lowering false positives by 15% and preventing estimated $1.2M in fraud annually.",
                "technologies": [
                    "Apache Flink",
                    "Kafka",
                    "LightGBM",
                    "AWS Lambda",
                    "Terraform"
                ],
                "year": 2022
            },
            {
                "name": "On-device Model Compression Toolkit",
                "description": "Developed a toolkit for model pruning, quantization, and knowledge distillation to deploy models to mobile devices. Enabled a 4x reduction in model size with <2% accuracy drop.",
                "technologies": [
                    "TensorFlow Lite",
                    "ONNX",
                    "TensorRT",
                    "NumPy"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Deep Learning",
            "NLP",
            "Computer Vision",
            "MLOps",
            "Kubernetes",
            "Docker",
            "SQL",
            "Spark",
            "AWS",
            "Model Optimization",
            "Experimentation"
        ],
        "achievements": [
            "Deployed multiple production models serving millions of requests per day with reliable CI/CD and monitoring.",
            "Reduced model inference latency by 4x across services through optimization and architecture changes.",
            "Presented work on model compression at an internal industry workshop; adopted across 3 product teams."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Ava Martinez",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, learning-focused, data-driven teams that value clear ownership, code quality, and pragmatic experimentation",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (415) 555-0198",
            "email": "ava.martinez@example.com",
            "linkedin": "https://www.linkedin.com/in/avamartinez",
            "github": "https://github.com/avamartinez"
        },
        "summary": "AI Engineer with 6+ years building production ML systems and end-to-end MLOps pipelines. Experienced in model design, deployment, monitoring, and scaling across recommendation, NLP, and computer vision use cases. Strong background in Python, PyTorch, model optimization, and cloud-native infra (Kubernetes, AWS). Passionate about reproducible research and operationalizing models for measurable product impact.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 NimbleHealth",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and delivery of a real-time recommendation service (PyTorch \u2192 TorchScript) deployed on Kubernetes, reducing recommendation latency by 42% and increasing click-through by 12%.",
                    "Built MLOps platform components: CI for model training, automated deployment pipelines, model registry and rollout strategies (canary/blue-green) using GitHub Actions, ArgoCD, and Seldon.",
                    "Implemented monitoring and drift detection (Prometheus + custom scoring hooks), cutting undetected performance regressions by 90% and enabling automated alerts tied to retraining workflows.",
                    "Collaborated with product and infra teams to define SLAs; mentored three junior engineers on production ML best practices and code reviews."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 BrightPath Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed an ensemble-based NLP pipeline for entity extraction and document classification that improved accuracy by 18% over baseline and reduced manual labeling effort by 60%.",
                    "Optimized model serving stack: converted large Transformer models into distilled variants and quantized TorchScript models, achieving 3x throughput gains with <2% accuracy loss.",
                    "Designed feature stores and ETL jobs (Airflow) to ensure reproducible feature computation and lineage across experiments.",
                    "Partnered with data engineering to migrate workflows to AWS (EKS, S3, SageMaker), improving training throughput and reducing infrastructure cost by 25%."
                ]
            },
            {
                "name": "Data Science Intern \u2014 ClearVision Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built computer vision prototypes for automated quality inspection using transfer learning (ResNet, EfficientNet), increasing defect detection recall by 30%.",
                    "Ran A/B experiments and produced dashboards to measure model impact; worked closely with QA and production teams to integrate models into the release pipeline.",
                    "Documented reproducible experiments and contributed to internal tooling for dataset versioning and annotation workflows."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Recommendation Service",
                "description": "End-to-end system for personalized item recommendations: offline training pipeline, model registry, feature store, REST/gRPC serving with model ensembles and online feature fetch. Focused on latency optimization and safe rollout strategies.",
                "technologies": [
                    "PyTorch",
                    "TorchScript",
                    "Kubernetes",
                    "Redis",
                    "Seldon",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Document Understanding Pipeline",
                "description": "Hybrid OCR + Transformer pipeline for extracting structured fields from semi-structured documents. Achieved 94% field-level accuracy using a combination of layout-aware models and rule-based postprocessing.",
                "technologies": [
                    "Detectron2",
                    "Hugging Face Transformers",
                    "Tesseract",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "fastmetrics (open-source)",
                "description": "Lightweight Python library for fast, reproducible ML metrics and monitoring hooks used in CI to validate model performance before deployment.",
                "technologies": [
                    "Python",
                    "pytest",
                    "GitHub Actions"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S., Computer Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science"
            },
            {
                "name": "University of California, Davis \u2014 B.S., Computer Engineering",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Computer Engineering"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Model Optimization (quantization, distillation)",
            "MLOps (CI/CD, model registry, monitoring)",
            "Kubernetes / Docker",
            "AWS (S3, EKS, SageMaker)",
            "SQL",
            "Data pipelines (Airflow)",
            "NLP",
            "Computer Vision",
            "Experimentation & A/B testing"
        ],
        "achievements": [
            "Published conference paper on lightweight Transformer distillation (NeurIPS workshop, 2021).",
            "Led cross-functional team that shipped a recommendation feature that increased user retention by 8%.",
            "Maintainer of an open-source metrics library (fastmetrics) with 600+ stars and adopted by two startups."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, experimental, and inclusive \u2014 values clear communication, reproducibility, and continuous learning",
        "contact": {
            "address": {
                "region": "MA, USA",
                "detail": "Cambridge"
            },
            "phone": "+1-617-555-0123",
            "email": "aisha.rahman@email.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aishar-dev"
        },
        "summary": "Data scientist with 7+ years of experience designing and productionizing ML systems for healthcare and retail. Strong background in predictive modeling, causal inference, MLOps, and experimentation. Proven record of turning data into measurable business impact and deploying scalable, maintainable pipelines.",
        "experience": [
            {
                "name": "NexGen Health \u2014 Senior Data Scientist",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a readmission-risk model (XGBoost + calibration) integrated with EHR, improving early-intervention targeting and reducing 30-day readmissions by 14%.",
                    "Designed an automatic model-monitoring pipeline using Airflow, Prometheus, and Great Expectations to track data drift and model performance; reduced incident response time from days to hours.",
                    "Collaborated with clinicians to define feature engineering for interpretable risk scores and produced explainability reports (SHAP) used in clinical decision meetings.",
                    "Implemented A/B tests for discharge planning workflows; quantified a 7% improvement in post-discharge follow-up adherence and presented results to executive leadership."
                ]
            },
            {
                "name": "OptiTech Analytics \u2014 Data Scientist",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Built customer lifetime value (LTV) and churn prediction models (LightGBM) that informed personalized retention campaigns, increasing retention lift by 18% for high-value cohorts.",
                    "Developed a feature store on Delta Lake and Spark to unify feature computation across offline and real-time scoring, reducing model retrain time by 40%.",
                    "Partnered with product teams to instrument experiments and analyze heterogeneous treatment effects, improving targeting for promotions and increasing ROI by 22%."
                ]
            },
            {
                "name": "Insight Labs \u2014 Junior Data Scientist",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Implemented NLP pipelines for customer feedback classification (spaCy, transformers), reducing manual labeling effort by 60%.",
                    "Built dashboards (Tableau) and ETL jobs to operationalize KPIs across marketing and operations teams.",
                    "Contributed to codebase improvements and CI for model training, enabling reproducible experiments and faster iteration."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Sepsis Early Warning",
                "description": "Prototype and productionized a streaming sepsis early-warning system ingesting EHR vitals and labs, delivering alerts to clinical staff with interpretable risk drivers.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Kafka",
                    "Docker",
                    "AWS (EKS, RDS)"
                ],
                "year": 2023
            },
            {
                "name": "Customer LTV and Segmenter",
                "description": "End-to-end pipeline computing customer lifetime value, segments for personalized offers, and a dashboard for business stakeholders to query expected ROI by segment.",
                "technologies": [
                    "Spark",
                    "Delta Lake",
                    "LightGBM",
                    "Airflow",
                    "Looker"
                ],
                "year": 2021
            },
            {
                "name": "Feedback Summarization",
                "description": "Abstractive summarization service for product reviews using transformer-based models fine-tuned for domain-specific brevity and helpfulness scoring.",
                "technologies": [
                    "Hugging Face Transformers",
                    "spaCy",
                    "FastAPI"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "Carnegie Mellon University \u2014 M.S. Data Science",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Dhaka \u2014 B.Sc. Computer Science",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.Sc. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "PyTorch",
            "TensorFlow",
            "LightGBM",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "MLOps",
            "Experimentation / A/B testing",
            "Causal inference",
            "Data visualization (Looker, Tableau)"
        ],
        "achievements": [
            "Reduced hospital 30-day readmission rate by 14% via risk model and workflow changes.",
            "Delivered a 22% increase in marketing ROI through targeted experimentation and predictive models.",
            "Published an internal best-practices guide for model monitoring adopted across two business units."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Asha Varma",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven team with emphasis on mentorship, reproducible ML engineering, and responsible AI practices",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Currently based in Seattle; willing to relocate within North America"
            },
            "phone": "+1-206-555-0147",
            "email": "asha.varma@email.com",
            "linkedin": "https://www.linkedin.com/in/ashavarma",
            "github": "https://github.com/ashavarma"
        },
        "summary": "AI Engineer with 9+ years building and deploying machine learning systems at scale. Strong track record integrating LLMs and deep learning models into production, improving inference latency and model robustness, and establishing MLOps pipelines. Experienced across cloud (AWS/GCP), container orchestration, model serving, and responsible AI tooling.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 NovaGen Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led integration of retrieval-augmented generation pipelines with LLMs (Llama 2 variants) to power a domain-specific assistant, reducing query failure rate by 28% and improving user satisfaction scores.",
                    "Designed and implemented scalable model serving using TorchServe/KServe and Kubernetes, achieving 40% lower median latency through batching, quantization, and adaptive autoscaling.",
                    "Built end-to-end MLOps stack: data ingestion (Kafka), feature store, CI/CD for models (GitHub Actions), and monitoring (Prometheus + Grafana + custom drift detection).",
                    "Established evaluation framework for safety and bias testing across releases, integrating unit tests for model behavior and automated rollbacks for regressions."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 SignalSense",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed real-time recommendation engine and feature pipelines serving millions of daily requests using Spark, Redis, and AWS Lambda.",
                    "Implemented feature-store-backed training pipelines and orchestrated batch and streaming data flows using Airflow and Kafka.",
                    "Executed online A/B tests and multi-armed bandit experiments to validate model improvements, increasing key engagement metrics by up to 12%.",
                    "Mentored junior engineers on production ML best practices and code review processes; improved deployment frequency and reduced rollback incidents."
                ]
            },
            {
                "name": "Data Scientist \u2014 InsightWorks",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built NLP classification and entity extraction models for customer feedback analysis using spaCy and TensorFlow, reducing manual triage workload by 60%.",
                    "Designed ETL pipelines and reproducible experiments; standardized model training artifacts and created reproducible notebooks for stakeholders.",
                    "Collaborated with product and engineering teams to translate business metrics into model objectives and measurable KPIs."
                ]
            }
        ],
        "projects": [
            {
                "name": "OpenAssist \u2014 LLM-powered domain assistant",
                "description": "End-to-end assistant using retrieval-augmented generation: document ingestion, vector search, and LLM orchestration to provide context-aware responses for enterprise knowledge. Emphasized hallucination mitigation and safety guardrails.",
                "technologies": [
                    "LangChain",
                    "FAISS",
                    "Llama 2",
                    "PyTorch",
                    "Docker",
                    "Kubernetes",
                    "AWS (S3, ECR, ECS)"
                ],
                "year": 2023
            },
            {
                "name": "Edge Model Optimizer",
                "description": "Toolchain to quantize and prune models for on-device inference with automated benchmarking across target hardware (ARM, NVIDIA Jetson). Achieved 3x speedup with minimal accuracy loss.",
                "technologies": [
                    "ONNX",
                    "TorchScript",
                    "TensorRT",
                    "Python",
                    "CI/CD"
                ],
                "year": 2022
            },
            {
                "name": "Streaming Anomaly Detection Platform",
                "description": "Real-time anomaly detection service for telemetry data using streaming feature extraction, online learning, and alerting; integrated with Grafana for visualization.",
                "technologies": [
                    "Kafka",
                    "Spark Streaming",
                    "Python",
                    "scikit-learn",
                    "Prometheus"
                ],
                "year": 2020
            },
            {
                "name": "AutoML Pipeline for Time Series Forecasting",
                "description": "Automated pipeline to evaluate and deploy forecasting models with backtesting and automated hyperparameter tuning, reducing manual model selection time.",
                "technologies": [
                    "Prophet",
                    "XGBoost",
                    "Optuna",
                    "Airflow",
                    "Docker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington \u2014 M.S., Computer Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Machine Learning focus)"
            },
            {
                "name": "Birla Institute of Technology and Science \u2014 B.E., Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.E. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "LLMs (Llama, GPT-family)",
            "NLP",
            "MLOps",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "SQL",
            "Spark",
            "Model Serving",
            "Monitoring & Observability",
            "Data Engineering (Kafka, Airflow)"
        ],
        "achievements": [
            "Published conference paper on efficient retrieval strategies for domain-specific LLM applications (2023).",
            "Reduced production inference latency by 40% through batching and model optimization techniques.",
            "Introduced automated drift detection and rollback system that prevented two major production incidents.",
            "Mentored and grew an internal ML onboarding program adopted company-wide."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Deep Learning Specialization (Coursera)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Raman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and inclusive. Values mentorship, reproducible experiments, clear communication, and rapid iteration with strong emphasis on product impact.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (510) 555-0198",
            "email": "aisha.raman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharaman",
            "github": "https://github.com/aisharaman"
        },
        "summary": "Data scientist with 7+ years building production ML systems and analytics platforms for healthcare and e\u2011commerce. Strong background in end-to-end model development, real-time feature engineering, experimentation, and mentoring cross-functional teams to turn data into measurable product improvements.",
        "experience": [
            {
                "name": "OctoHealth \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time risk scoring pipeline (Kafka, Spark Streaming, Redis) used by clinical operations; improved early-intervention detection recall by 28%.",
                    "Built and maintained production ML models with PyTorch and scikit-learn, implementing CI/CD using MLflow, Docker, and GitHub Actions to reduce deployment time from weeks to days.",
                    "Partnered with product and engineering to define metrics and run >40 randomized experiments; validated feature rollout that increased engagement by 12%.",
                    "Mentored 4 junior data scientists and established code review and model card best practices to improve model reproducibility and reduce training feedback loops."
                ]
            },
            {
                "name": "MarketLytics \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed personalized product recommendation systems (matrix factorization and deep learning hybrids) that lifted conversion by 9% and average order value by 6%.",
                    "Implemented automated A/B testing framework and experiment analysis pipelines using Python, SQL and Bayesian methods \u2014 standardized experiment reporting across the product org.",
                    "Designed customer segmentation and lifetime value models using XGBoost and survival analysis; informed targeted marketing that reduced acquisition cost by 15%.",
                    "Collaborated with data engineering to productionize feature stores (Delta Lake on AWS) and onboarded feature versioning for reproducible training."
                ]
            },
            {
                "name": "Insights Lab \u2014 Data Analyst",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built executive dashboards and automated ETL pipelines (Airflow, Redshift) to track core KPIs and weekly cohort metrics.",
                    "Performed exploratory analysis and A/B test post\u2011hoc analyses to guide product decisions; reduced churn in a pilot cohort by 7% through targeted interventions.",
                    "Optimized SQL queries and database schemas, improving dashboard refresh times by 60%."
                ]
            }
        ],
        "projects": [
            {
                "name": "ChurnPredict",
                "description": "End-to-end churn prediction system for a subscription product: data ingestion, feature store, model training with XGBoost, serving via REST API, and monitoring dashboards for data drift and model performance.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Airflow",
                    "Docker",
                    "AWS (S3, EKS)",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "RealTimeFraud",
                "description": "Real-time scoring pipeline for transaction fraud detection using streaming features and a lightweight neural network, achieving sub-150ms end-to-end latency in production.",
                "technologies": [
                    "Kafka",
                    "Spark Streaming",
                    "PyTorch",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "CustomerSegmentationToolkit",
                "description": "Reusable toolkit for behavioral segmentation combining clustering, dimensionality reduction, and automated cohort reporting to enable targeted campaigns.",
                "technologies": [
                    "scikit-learn",
                    "pandas",
                    "UMAP",
                    "SQL",
                    "Tableau"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Mumbai",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "pandas",
            "Spark",
            "Airflow",
            "Kafka",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Experimentation & A/B testing",
            "Feature engineering",
            "Model monitoring"
        ],
        "achievements": [
            "Improved model recall for early clinical risk detection by 28% at OctoHealth, enabling earlier interventions.",
            "Delivered recommendation system that increased conversion by 9% at MarketLytics.",
            "Reduced dashboard refresh latency by 60% through query optimization and ETL improvements.",
            "Presented a workshop on reproducible ML workflows at Bay Area Data Meetup (2022)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Applied Data Science Specialization (Coursera)",
                "date": 2017
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and growth-minded \u2014 values mentorship, cross-functional communication, and clear product impact.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "Mission District"
            },
            "phone": "+1-415-555-0130",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data scientist with 8+ years of experience building production ML systems and analytics platforms for healthcare and e-commerce. Strong track record of deploying scalable models, improving business KPIs through experimentation and causal inference, and mentoring cross-functional teams. Comfortable with end-to-end ML lifecycle: feature engineering, model development, CI/CD, monitoring, and stakeholder communication.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Orbital Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a patient readmission risk model that reduced 30-day readmissions by 12% after integration with care-management workflows.",
                    "Designed feature store and ETL pipelines (Airflow, Spark) enabling 10x faster feature turnaround and consistent production features across teams.",
                    "Implemented model monitoring and drift detection (Prometheus + Grafana), cutting false positive alerts by 40% via automated retraining triggers.",
                    "Mentored 4 junior data scientists; introduced code review guidelines and unit tests for model logic, improving reproducibility and reducing incidents."
                ]
            },
            {
                "name": "Data Scientist \u2014 Nova Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built CTR and conversion prediction models for personalization pipelines; increased revenue-per-user by 6% through better ranking and calibration.",
                    "Developed A/B test frameworks and ran over 70 experiments to inform product decisions; applied causal inference methods to estimate long-term impact.",
                    "Ported models from research (scikit-learn, TensorFlow) to production using Docker, Kubeflow, and AWS SageMaker, reducing deployment time by 50%.",
                    "Collaborated with product managers and engineers to define metrics and success criteria, enabling clearer roadmaps and faster iteration."
                ]
            },
            {
                "name": "Data Analyst \u2014 CityData Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Performed exploratory and time-series analyses on city sensor and mobility data to identify optimization opportunities for transit planning.",
                    "Automated ETL reports and dashboards in Looker and Tableau, saving 15+ analyst hours per week and improving stakeholder visibility.",
                    "Built early anomaly detection prototype using isolation forest, which informed a production anomaly system used by operations teams."
                ]
            }
        ],
        "projects": [
            {
                "name": "Predictive Readmission Model",
                "description": "End-to-end ML system predicting 30-day hospital readmissions using EHR, social determinants, and time-series vitals. Included feature engineering pipelines, model training, calibration, and integration with clinician-facing dashboards.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Spark",
                    "Airflow",
                    "AWS S3",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Built a low-latency ranking pipeline for personalized content recommendations with online feature computation and model scoring under 50ms SLA.",
                "technologies": [
                    "Kafka",
                    "Redis",
                    "TensorFlow",
                    "Kubernetes",
                    "gRPC"
                ],
                "year": 2019
            },
            {
                "name": "Anomaly Detection Pipeline",
                "description": "Developed scalable anomaly detection for streaming telemetry using clustering and statistical tests; integrated alerting and root-cause analysis tools.",
                "technologies": [
                    "PySpark",
                    "MLflow",
                    "Prometheus",
                    "Grafana"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Dhaka \u2014 B.Sc. Statistics",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.Sc. Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "pandas",
            "NumPy",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "Spark",
            "Kafka",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS (S3, EC2, SageMaker)",
            "GCP",
            "MLflow",
            "Feature Engineering",
            "A/B Testing",
            "Causal Inference",
            "Data Visualization (Tableau, Looker)"
        ],
        "achievements": [
            "Reduced 30-day readmissions by 12% through a deployed risk model impacting ~80k patients/year.",
            "Delivered production-ready recommendation system that increased revenue-per-user by 6%.",
            "Authored a company-wide feature engineering guide adopted across three product teams.",
            "Presented work on model monitoring and drift detection at a regional ML meetup (2023)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "Certified Data Scientist (DataCamp Professional Track)",
                "date": 2018
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that value experimentation, clear metrics, and mentorship; prefers organizations that balance autonomy with cross-functional partnership.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA, USA",
                "detail": "Based in Oakland; willing to relocate or travel"
            },
            "phone": "+1-415-555-0198",
            "email": "aisha.patel@example.com",
            "linkedin": "https://www.linkedin.com/in/aisha-patel-ds",
            "github": "https://github.com/aishapatel"
        },
        "summary": "Data Scientist with 7+ years of experience building and deploying ML systems in healthcare and enterprise SaaS. Strong background in end-to-end model development, production ML engineering, and cross-functional delivery\u2014combines statistical rigor with pragmatic engineering to drive measurable outcomes.",
        "experience": [
            {
                "name": "Senior Data Scientist, BrightHealth AI",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of an end-to-end ML platform for patient risk scoring; containerized models and deployed on EKS with CI/CD, reducing deployment time from weeks to days.",
                    "Built and shipped deep learning and gradient-boosted models that decreased 30-day readmission prediction error by 18% vs. prior baseline; validated with temporal holdouts and clinician review.",
                    "Implemented model monitoring (latency, data drift, performance) with Prometheus/Grafana and automated alerts to reduce production incidents by 60%.",
                    "Mentored a team of 4 junior data scientists and established code-review and testing standards for ML pipelines."
                ]
            },
            {
                "name": "Data Scientist, Carelytics",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed a gradient-boosting model (XGBoost) to predict 30-day hospital readmissions achieving AUC 0.87, improving on an existing model AUC of 0.72.",
                    "Architected Spark-based feature engineering workflows and orchestrated reproducible pipelines with Apache Airflow.",
                    "Integrated SHAP-based explainability into clinician-facing reports, increasing clinical adoption of model outputs by 35%.",
                    "Collaborated with product and engineering to instrument A/B tests and track treatment effects using causal uplift analysis."
                ]
            },
            {
                "name": "Data Analyst, CityHealth Labs",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Built production ETL pipelines using Python and SQL to consolidate multi-source clinical and claims data, reducing data prep time by 50%.",
                    "Developed interactive dashboards and regular reporting used by clinical operations to identify high-risk cohorts.",
                    "Performed cohort analyses and statistical hypothesis tests to support new care management programs."
                ]
            }
        ],
        "projects": [
            {
                "name": "Readmission Risk Predictor",
                "description": "End-to-end system predicting 30-day readmission risk using structured EHR and claims features. Included feature store, model training, explainability, and real-time serving.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "MLflow",
                    "Docker",
                    "AWS (S3, EKS)"
                ],
                "year": 2021
            },
            {
                "name": "Image-based Wound Classifier",
                "description": "Convolutional neural network to classify wound severity from clinical photos; focused on data augmentation, class imbalance handling, and uncertainty estimation for triage.",
                "technologies": [
                    "PyTorch",
                    "FastAI",
                    "OpenCV",
                    "AWS (S3, SageMaker)"
                ],
                "year": 2023
            },
            {
                "name": "Feature Store & ETL Pipeline",
                "description": "Designed a reusable feature engineering layer and automated ETL pipelines to support multiple modeling teams, enabling faster experiment iteration and consistent features across models.",
                "technologies": [
                    "Spark",
                    "Airflow",
                    "Kafka",
                    "Postgres"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S., Computer Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.S., Statistics & Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "XGBoost",
            "pandas",
            "NumPy",
            "MLflow",
            "A/B testing",
            "SHAP",
            "statistics"
        ],
        "achievements": [
            "Reduced model inference latency by 40% through model optimization and batching, enabling real-time scoring.",
            "Published a workshop paper at NeurIPS Workshop on ML for Healthcare (2023).",
            "Invited speaker at PyData SF (2024) on production ML pipelines in healthcare.",
            "Introduced organization-wide ML monitoring practices, cutting incident response time by over half."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Aria Patel",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven, impact-oriented teams that value code quality, continuous learning, and strong cross-functional partnership.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "1358 Market St, Apt 7B, San Francisco, CA 94103"
            },
            "phone": "+1-415-555-0132",
            "email": "aria.patel@example.com",
            "linkedin": "https://www.linkedin.com/in/ariapatel",
            "github": "https://github.com/ariapatel"
        },
        "summary": "AI Engineer with 6+ years building and productionizing ML systems for computer vision and time-series applications. Strong background in model development, MLOps, and scalable inference pipelines. Experienced taking research ideas into robust, low-latency production services.",
        "experience": [
            {
                "name": "NimbusAI \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and implementation of an end-to-end ML inference pipeline (PyTorch -> ONNX -> Triton) deployed across Kubernetes clusters, reducing tail latency by 4x and improving throughput by 3x.",
                    "Built model monitoring and CI/CD for model rollouts using MLflow, ArgoCD, and Prometheus to enable safe canary deployments and automated rollback.",
                    "Collaborated with product and edge teams to optimize vision models (quantization, pruning, TensorRT) enabling deployment to 1,200 edge devices with 2.5x reduction in memory footprint.",
                    "Mentored junior engineers and established best practices for reproducible experiments, data versioning (DVC), and unit-tested model pipelines."
                ]
            },
            {
                "name": "DataWave Analytics \u2014 ML Engineer",
                "date": {
                    "start": 2019,
                    "end": 2021
                },
                "bullets": [
                    "Developed a hybrid recommendation system combining embedding-based retrieval and gradient-boosted ranking models, increasing CTR by 18%.",
                    "Implemented automated feature engineering and backtesting pipelines using Airflow and Great Expectations, shortening model iteration cycles from weeks to days.",
                    "Built time-series forecasting solutions (Prophet, LSTM) for inventory planning that reduced stockouts by 12% for key accounts."
                ]
            },
            {
                "name": "Google Research \u2014 Research Intern",
                "date": {
                    "start": 2018,
                    "end": 2019
                },
                "bullets": [
                    "Researched efficient neural architecture modifications for low-power vision tasks and co-authored a workshop paper on edge-aware model pruning.",
                    "Prototyped experiments in TensorFlow and collected datasets, contributing code and reproducible experiment notebooks."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeVision",
                "description": "Production-ready computer vision stack for autonomous inspection drones featuring on-device inference, dynamic model selection, and remote update capabilities.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "Docker",
                    "Kubernetes",
                    "AWS Greengrass"
                ],
                "year": 2023
            },
            {
                "name": "AutoML-Pipeline",
                "description": "Automated model training and deployment pipeline integrating hyperparameter search, feature engineering, and end-to-end CI/CD to push models to staging automatically.",
                "technologies": [
                    "MLflow",
                    "Ray Tune",
                    "Airflow",
                    "FastAPI",
                    "GCP"
                ],
                "year": 2020
            },
            {
                "name": "OpenForecast",
                "description": "Open-source toolkit for hierarchical time-series forecasting with backtesting and visualization modules used by internal analytics teams.",
                "technologies": [
                    "PyTorch",
                    "Pandas",
                    "Prophet",
                    "Docker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "degree": "M.S. Computer Science (Artificial Intelligence)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "degree": "B.S. Electrical Engineering & Computer Sciences"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "ONNX",
            "CUDA",
            "TensorRT",
            "Scikit-learn",
            "Pandas",
            "NumPy",
            "SQL",
            "Docker",
            "Kubernetes",
            "MLflow",
            "Airflow",
            "FastAPI",
            "AWS",
            "GCP",
            "CI/CD"
        ],
        "achievements": [
            "Reduced model inference latency by 4x and memory footprint by 2.5x for edge deployments via quantization and pruning.",
            "Delivered production recommendation system that increased CTR by 18% for a key product line.",
            "Co-authored a workshop paper on model pruning for edge devices (NeurIPS Workshop, 2019).",
            "Led cross-functional effort to deploy ML monitoring and rollback processes, eliminating extended outages from bad model rollouts."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Deep Learning Specialization (Coursera)",
                "date": 2020
            }
        ],
        "total_experience": 7,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on mentorship, continuous learning, and ethical AI practices",
        "contact": {
            "address": {
                "region": "Toronto, ON, Canada",
                "detail": "234 King St W, Apt 704"
            },
            "phone": "+1-647-555-2198",
            "email": "aisha.rahman@email.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 7+ years of experience building production ML systems and data products across finance and SaaS. Strong background in applied ML, time series forecasting, causal inference, and model interpretability. Proven track record delivering measurable business impact through end-to-end projects, automated pipelines, and cross-functional collaboration.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Sentience Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a cross-functional team to design and deploy a customer churn prediction pipeline that reduced churn by 18% within 9 months; improved model AUC from 0.72 to 0.86 using feature engineering and ensemble methods.",
                    "Built and maintained MLOps pipelines with CI/CD, automated data validation, model retraining, and monitoring (Seldon + Prometheus), reducing deployment time from weeks to days.",
                    "Introduced explainability (SHAP) and counterfactual analyses to support retention decisions; presented findings to executive leadership and product teams.",
                    "Mentored 4 junior data scientists and established best practices for code review, reproducibility, and model documentation."
                ]
            },
            {
                "name": "Data Scientist \u2014 FinTech Insights",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed real-time fraud detection models using streaming feature pipelines (Kafka + Flink) and gradient boosted trees, achieving a 42% reduction in false positives while maintaining high detection recall.",
                    "Collaborated with engineers to productionize models in AWS (ECS, Lambda), leading to 99.9% model availability and sub-second inference latency for prioritized flows.",
                    "Led A/B tests and causal impact analyses for pricing experiments, generating $1.3M incremental annualized revenue from optimized fee structures.",
                    "Standardized feature store design and implemented feature lineage tracking to accelerate model development across teams."
                ]
            },
            {
                "name": "Research Assistant \u2014 University of Toronto, Vector Institute Collaboration",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Researched time series forecasting and transfer learning for low-data domains; published results in a top-tier workshop and open-sourced reproducible notebooks.",
                    "Implemented probabilistic forecasting models (DeepAR, Prophet) and compared performance across hierarchical aggregation levels for retail datasets.",
                    "Supported grant proposals and supervised two undergraduate research projects."
                ]
            },
            {
                "name": "Data Analyst \u2014 MarketEdge Solutions",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "bullets": [
                    "Built ETL pipelines and dashboards (Tableau, Looker) to surface KPIs for client campaigns; reduced reporting lag from 5 days to daily refreshes.",
                    "Performed segmentation and uplift modeling to inform targeted marketing strategies, improving campaign ROI by 27%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Churn Prediction Platform",
                "description": "End-to-end platform for predicting and prioritizing at-risk customers. Includes feature store, model training, automated validation, deployable scoring service, and dashboard for retention actions.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Airflow",
                    "Seldon",
                    "Postgres",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Fraud Detection",
                "description": "Streaming pipeline for online fraud scoring integrating transactional features, behavioral signals, and ensemble models, with real-time alerts and feedback loop for model retraining.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "PySpark",
                    "LightGBM",
                    "AWS ECS"
                ],
                "year": 2020
            },
            {
                "name": "Customer Segmentation & Lifetime Value",
                "description": "Clustering and CLTV modeling to inform product bundling and personalized offers; led to targeted campaigns and a 12% increase in average customer lifetime value.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "pandas",
                    "SQL",
                    "Looker"
                ],
                "year": 2019
            },
            {
                "name": "Explainable ML Toolkit",
                "description": "Toolkit integrating feature importance, SHAP explanations, and automated counterfactual generation to increase model transparency for stakeholders.",
                "technologies": [
                    "SHAP",
                    "Alibi",
                    "Flask",
                    "Docker"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of Toronto",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "MSc, Data Science"
            },
            {
                "name": "University of Waterloo",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "BSc, Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PySpark",
            "scikit-learn",
            "TensorFlow",
            "XGBoost",
            "LightGBM",
            "MLOps (Airflow, Seldon, Docker)",
            "Time Series Forecasting",
            "Causal Inference",
            "Model Explainability (SHAP)",
            "AWS"
        ],
        "achievements": [
            "Delivered a churn-reduction program resulting in 18% lower churn within first 9 months of deployment.",
            "Built fraud detection system that reduced false positives by 42% and scaled to real-time production.",
            "Presented research at an international ML workshop and open-sourced reproducible experiments.",
            "Mentored junior team members; contributed to company-wide ML best practices and reproducibility standards."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven team that values experimentation, clear metrics, mentorship, and production-quality engineering.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala, Bengaluru, Karnataka"
            },
            "phone": "+91-98450-12345",
            "email": "maya.patel.ds@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-patel-ds",
            "github": "https://github.com/mayarp"
        },
        "summary": "Data scientist with 8+ years of experience building and productionizing ML systems for healthcare and fintech. Strong background in applied ML, time-series forecasting, NLP, and MLOps. Proven track record of improving business KPIs through robust modeling, A/B testing, and scalable data pipelines. Comfortable leading cross-functional teams and mentoring junior engineers.",
        "experience": [
            {
                "name": "Lead Data Scientist \u2014 Neurolytics AI",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led a team of 5 data scientists and ML engineers to develop diagnostic models for medical imaging and patient risk stratification; improved early-detection recall by 18% while reducing false positives by 12%.",
                    "Designed and rolled out a model governance pipeline (MLflow + Docker + Kubernetes) to automate model validation, CI/CD, and monitoring; reduced deployment time from weeks to <48 hours.",
                    "Partnered with clinical stakeholders to turn model outputs into actionable triage workflows, contributing to a 10% reduction in average patient wait time across pilot hospitals.",
                    "Implemented model drift detection and an automated retraining schedule using streaming feature stores (Feast) and scheduled pipelines (Airflow)."
                ]
            },
            {
                "name": "Senior Data Scientist \u2014 Skyline Health",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Built a multi-modal readmission risk model (EHR + notes) using gradient boosting and transformer-based embeddings; achieved AUC improvement from 0.72 to 0.81 versus baseline.",
                    "Led A/B testing and uplift modeling initiatives to prioritize high-impact interventions; demonstrated a 7% reduction in 30-day readmissions in the treatment cohort.",
                    "Optimized ETL and feature pipelines with Spark and Delta Lake, cutting daily pipeline runtime by 60% and improving data freshness SLA.",
                    "Mentored 3 junior data scientists; established code review and modeling standards that increased reproducibility and reduced model debugging time."
                ]
            },
            {
                "name": "Data Scientist \u2014 Finova Solutions",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Developed credit-scoring and fraud-detection models using tree ensembles and ensemble stacking; reduced default prediction error by 15% and detected anomalous transactions with 92% precision.",
                    "Deployed model inference service using Flask + Docker behind a K8s cluster, serving 200k+ requests/day with 120ms median latency.",
                    "Collaborated with product and legal teams to implement explainability (SHAP-based) and bias audits for regulatory compliance.",
                    "Automated monthly reporting and KPI dashboards in Tableau for stakeholders, saving ~30 hours/month of manual analysis."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Triage Assistant (Prod)",
                "description": "End-to-end system integrating imaging model outputs and EHR features to prioritize patients for specialist review. Includes model inference service, monitoring, and clinician-facing dashboard.",
                "technologies": [
                    "PyTorch",
                    "FastAPI",
                    "Docker",
                    "Kubernetes",
                    "MLflow",
                    "PostgreSQL",
                    "React"
                ],
                "year": 2024
            },
            {
                "name": "Patient Readmission Predictor",
                "description": "Hybrid model combining transformer embeddings of clinical notes with time-series EHR features to predict 30-day readmission risk. Included calibration, fairness checks, and an explainability layer.",
                "technologies": [
                    "scikit-learn",
                    "PyTorch",
                    "Spark",
                    "SHAP",
                    "Airflow"
                ],
                "year": 2021
            },
            {
                "name": "Real-time Fraud Detection Pipeline",
                "description": "Streaming anomaly detection and rule enrichment for payment transactions with online feature computation and low-latency scoring.",
                "technologies": [
                    "Kafka",
                    "Spark Streaming",
                    "XGBoost",
                    "Redis",
                    "Docker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Science (IISc), Bangalore",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.Tech, Computer Science (Data Science specialization)"
            },
            {
                "name": "Birla Institute of Technology and Science (BITS), Pilani",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.E., Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Apache Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS (S3, SageMaker, Lambda)",
            "NLP (transformers)",
            "Time-series forecasting",
            "Causal inference",
            "Model explainability (SHAP)",
            "Data visualization (Tableau, matplotlib)"
        ],
        "achievements": [
            "Published a first-author paper on transformer-based clinical note representations at a peer-reviewed healthcare ML conference (2023).",
            "Instrumental in delivering a production triage model that reduced patient wait time by 10% during hospital pilot (2023).",
            "Reduced end-to-end model delivery time across teams from 4 weeks to under 48 hours via standardized CI/CD and model governance.",
            "Mentored 6+ interns and junior hires; two mentees promoted to senior roles within 18 months."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Aisha K. Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth-oriented environment with clear mentorship, code review, and emphasis on reproducible research and product impact.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Based in San Francisco, CA, USA"
            },
            "phone": "+1-415-555-0132",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aishark"
        },
        "summary": "Data Scientist with 8+ years of experience building production ML systems and analytics platforms for fintech and e-commerce. Strong background in applied machine learning, causal inference, and scalable data engineering. Proven record of driving revenue impact through predictive models, experimentation, and automated pipelines.",
        "experience": [
            {
                "name": "Acme Analytics \u2014 Senior Data Scientist (Product ML)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a customer churn prediction system that reduced monthly churn by 18% through targeted retention campaigns; model operates in production scoring 10M+ customers weekly.",
                    "Designed and owned an end-to-end ML pipeline (Airflow, Spark, Docker) enabling 4x faster model iteration and reproducible training artifacts.",
                    "Partnered with product and growth teams to run 25+ A/B tests; applied causal inference methods to attribute revenue lift and optimize targeting rules, contributing $6M incremental ARR in first year.",
                    "Mentored 4 junior data scientists and established best practices for model validation, feature engineering, and monitoring (data drift, model performance)."
                ]
            },
            {
                "name": "NovaTech \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built a real-time recommendation engine (Spark Streaming, Kafka, Redis) that increased click-through rate by 32% and average order value by 12%.",
                    "Implemented tree-based ensemble models (XGBoost, LightGBM) and deep learning (PyTorch) for personalized ranking and fraud detection.",
                    "Reduced model training time by 60% via feature store adoption and optimized feature pipelines; automated model retraining triggered by data quality checks.",
                    "Collaborated with engineering to productionize models on AWS SageMaker and set up CI/CD for model deployments."
                ]
            },
            {
                "name": "CityBank \u2014 Data Analyst",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Performed cohort analysis and credit risk modeling to inform underwriting policy; improved approval accuracy while reducing default rates by 7%.",
                    "Automated monthly reporting (SQL, Tableau) saving 80+ analyst hours per month and enabling near-real-time business insights.",
                    "Developed explainable models and feature importance reports to satisfy compliance and stakeholder transparency requirements."
                ]
            }
        ],
        "projects": [
            {
                "name": "Customer Churn Predictor",
                "description": "End-to-end churn prediction system combining feature store, XGBoost models, and targeted campaign integration. Included data validation, model explainability, and online scoring endpoints.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Airflow",
                    "Spark",
                    "Docker",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Built a low-latency recommendation service using collaborative filtering and learning-to-rank models with streaming updates to capture user behavior in near real time.",
                "technologies": [
                    "Spark Streaming",
                    "Kafka",
                    "Redis",
                    "PyTorch",
                    "Scala"
                ],
                "year": 2022
            },
            {
                "name": "Automated ML Pipeline & Feature Store",
                "description": "Designed and implemented a reusable feature store and automated training pipeline to standardize features across teams and accelerate model experimentation.",
                "technologies": [
                    "Feast",
                    "Airflow",
                    "SQL",
                    "Docker",
                    "S3"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Tableau",
            "Causal inference",
            "A/B testing",
            "Feature engineering",
            "Model monitoring"
        ],
        "achievements": [
            "Reduced customer churn by 18% through predictive modeling and targeted interventions, adding $6M ARR.",
            "Delivered a real-time recommendation system that increased CTR by 32% and AOV by 12%.",
            "Published a workshop paper on scalable feature stores (MLSys workshop, 2021).",
            "Mentored and scaled a data science team from 2 to 6 contributors while establishing reproducible ML best practices."
        ],
        "certifications": [
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Jordan Lee",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, outcome-driven teams with strong engineering practices, emphasis on code review, reproducibility, and continuous learning.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Based in Seattle metropolitan area"
            },
            "phone": "+1-206-555-0183",
            "email": "jordan.lee.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/jordan-lee-ai",
            "github": "https://github.com/jordanlee-ai"
        },
        "summary": "AI Engineer with 7+ years building and shipping production machine learning systems and applied deep learning models. Experienced across the ML lifecycle: data pipelines, model training, deployment, monitoring, and MLOps automation. Strong background in NLP (transformers), recommendation systems, and scalable model serving.",
        "experience": [
            {
                "name": "Senior AI Engineer, InsightStream Inc.",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multimodal recommendation model (text + behavioral signals) that increased click-through rate by 16% and revenue-per-user by 9%.",
                    "Built end-to-end ML pipelines using Airflow, Kafka, and Spark for streaming feature computation and near-real-time scoring at 100k+ requests/minute.",
                    "Designed containerized model serving stack (KServe + Kubernetes) to host transformer-based ranking models with A/B testing and canary rollout; reduced inference latency by 35% via optimized batching and model quantization.",
                    "Implemented model monitoring (Prometheus + Grafana) and drift detection; automated retraining triggers and rollback procedures to maintain production model quality."
                ]
            },
            {
                "name": "Machine Learning Engineer, NovaHealth Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed NLP pipelines for clinical text extraction and entity normalization using spaCy and fine-tuned BERT variants on domain-specific corpora, improving entity F1 by 12 points.",
                    "Collaborated with data engineers to architect ETL processes and data schemas in Snowflake, enabling reproducible feature stores for multiple ML teams.",
                    "Introduced CI/CD for ML using GitLab CI and Terraform for infrastructure as code, reducing deployment time from weeks to days.",
                    "Mentored junior engineers on productionization best practices and model interpretability techniques (SHAP)."
                ]
            },
            {
                "name": "Data Scientist, BrightMetrics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built predictive models for customer churn and lifetime value using gradient boosting (XGBoost) and feature engineering; improved churn prediction AUC by 0.07.",
                    "Deployed RESTful microservices for model inference in Flask, integrated with company analytics dashboards to support operations.",
                    "Conducted statistical experiments and analyzed A/B tests to guide product decisions and prioritize feature development."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Personalized Content Ranker",
                "description": "End-to-end system that combines user behavior, content embeddings, and contextual features to produce personalized ranking scores in real time. Implemented streaming feature joins, a candidate generation stage, and a neural ranker with late interaction.",
                "technologies": [
                    "TensorFlow",
                    "PyTorch",
                    "Kafka",
                    "Spark Streaming",
                    "Kubernetes",
                    "Redis"
                ],
                "year": 2022
            },
            {
                "name": "Domain-adapted Clinical BERT",
                "description": "Fine-tuned and distilled a BERT model on proprietary clinical notes, applied knowledge distillation and pruning to create a low-latency model for on-premise inference while retaining 94% of the larger model's performance.",
                "technologies": [
                    "Hugging Face Transformers",
                    "ONNX Runtime",
                    "Knowledge Distillation",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Automated ML Retraining Pipeline",
                "description": "Automated retraining pipeline with data validation, model training, evaluation, and deployment. Integrated dataset versioning and model lineage to ensure reproducibility and compliance.",
                "technologies": [
                    "Airflow",
                    "MLflow",
                    "Great Expectations",
                    "Terraform"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Computer Science (Machine Learning specialization)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Electrical Engineering and Computer Sciences"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face",
            "MLOps",
            "Kubernetes",
            "Docker",
            "Spark",
            "SQL",
            "Airflow",
            "MLflow",
            "Model Monitoring",
            "NLP",
            "Distributed Systems"
        ],
        "achievements": [
            "Published an internal whitepaper on scalable transformer serving that reduced CPU usage by 40% across production clusters.",
            "Speaker at two industry workshops on productionizing NLP models (2021, 2023).",
            "Mentored interns and junior engineers; two mentees promoted to mid-level engineer within a year."
        ],
        "certifications": [
            {
                "name": "Google Cloud Professional Machine Learning Engineer",
                "date": 2019
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2020
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on mentorship, continuous learning, and responsible/ethical AI.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "SOMA neighborhood"
            },
            "phone": "+1 (415) 555-0137",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "AI Engineer with 8+ years building and deploying production ML systems in healthcare and adtech. Strong background in NLP and recommendation systems, production MLOps, and optimizing model performance for latency and cost. Experienced in leading small engineering teams, designing monitoring and CI/CD for models, and driving demonstrable business impact.",
        "experience": [
            {
                "name": "Senior AI Engineer, Nimbus Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of clinical NLP pipelines (triage and note summarization) used by hospital partners; improved automated triage accuracy by 22%.",
                    "Reduced inference latency 3x and memory footprint 4x through model distillation and quantization, enabling on-prem GPU and edge deployments.",
                    "Designed feature-store-backed data pipelines and real-time scoring service (FastAPI + Redis) handling 200k requests/day with <120ms P95 latency.",
                    "Implemented CI/CD for models using MLflow + GitHub Actions and established model performance monitoring with Prometheus and custom drift alerts.",
                    "Mentored and grew a cross-functional team of 4 ML engineers and data scientists; coordinated with clinical stakeholders for validation and compliance."
                ]
            },
            {
                "name": "AI Engineer, Luma Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built ranking and personalized recommendation systems that increased click-through rate by 18% and contributed to a 12% lift in revenue for key customers.",
                    "Implemented real-time feature pipelines with Kafka and Apache Flink for user-level scoring, lowering model serving latency by 60%.",
                    "Led A/B experimentation for model launches, defining metrics, and instrumenting telemetry to measure online impact and guardrails.",
                    "Collaborated with backend and frontend teams to integrate model APIs and produced lightweight models for mobile inference."
                ]
            },
            {
                "name": "Machine Learning Engineer, DataSpring",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed computer vision models for product image classification; created a labeling pipeline and curated a 50k-image dataset.",
                    "Improved top-1 classification accuracy from 82% to 91% through architecture tuning, transfer learning, and systematic augmentation.",
                    "Automated scheduled retraining and evaluation workflows using Airflow, reducing manual retrain effort by 70%."
                ]
            },
            {
                "name": "Research Intern, UC Berkeley AI Lab",
                "date": {
                    "start": 2014,
                    "end": 2015
                },
                "bullets": [
                    "Researched sequence-to-sequence models for summarization; contributed to a paper on attention mechanisms for long documents.",
                    "Implemented experiments in PyTorch and prepared reproducible notebooks and scripts for lab use."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Note Summarizer",
                "description": "End-to-end system to extract and summarize key information from clinical notes using a combination of transformer-based extractive and abstractive models. Integrated with hospital EHR APIs and on-prem deployment options.",
                "technologies": [
                    "PyTorch",
                    "HuggingFace",
                    "FastAPI",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Low-latency personalized ranking system built for streaming user interactions with feature enrichment via Kafka and Flink, deployed with model versioning and online A/B testing.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "Flink",
                    "TensorFlow",
                    "MLflow"
                ],
                "year": 2020
            },
            {
                "name": "On-device Model Compression Toolkit",
                "description": "Toolkit for distillation, quantization, and pruning of transformer models to meet mobile/edge constraints; produced automated pipelines and benchmark suite.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "Quantization",
                    "NumPy"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "Georgia Institute of Technology",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "HuggingFace",
            "scikit-learn",
            "SQL",
            "Spark",
            "Kafka",
            "Flink",
            "Docker",
            "Kubernetes",
            "MLflow",
            "FastAPI",
            "Feature Stores",
            "MLOps",
            "Model Monitoring",
            "NLP",
            "Computer Vision",
            "Model Compression",
            "A/B Testing"
        ],
        "achievements": [
            "Reduced production model inference latency by 3x and memory footprint by 4x via distillation and quantization.",
            "Delivered a recommendation system that produced an 18% lift in CTR and 12% revenue increase for key clients.",
            "Published research on attention mechanisms for long-document summarization (co-author).",
            "Established CI/CD + monitoring workflows that cut model rollback time by 50% and improved reliability."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Alex Chen",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused, learning-first; values code reviews, reproducible experiments, and blameless postmortems.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0183",
            "email": "alex.chen18@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-chen18",
            "github": "https://github.com/alex-chen18"
        },
        "summary": "AI Engineer with 7+ years building and productionizing machine learning systems for personalization, NLP, and time-series forecasting. Strong background in deep learning (PyTorch/TensorFlow), MLOps, model optimization, and scalable data pipelines. Proven track record delivering measurable product impact and reducing inference cost/latency in production environments.",
        "experience": [
            {
                "name": "Senior AI Engineer, Nexa Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time personalization engine that increased click-through rate by 18% and revenue per user by 7%.",
                    "Built end-to-end ML pipelines with Kubeflow, Kafka, and Spark for streaming feature computation and model retraining; reduced model retrain time from 6 hours to 45 minutes.",
                    "Optimized transformer-based ranking models with distillation and quantization, cutting inference latency by 40% and serving costs by 30%.",
                    "Implemented CI/CD for models (unit tests for data/metrics, canary rollout, drift detection) and authored runbooks for model incidents.",
                    "Mentored 4 junior ML engineers and led knowledge-sharing sessions on MLOps best practices."
                ]
            },
            {
                "name": "Machine Learning Engineer, DataWave Inc.",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built an NLP pipeline for intent classification and entity extraction serving 10M+ requests/month; improved macro F1 from 0.72 to 0.86.",
                    "Productionized TensorFlow models with TF Serving and Docker; integrated autoscaling and A/B experiments to evaluate model variants.",
                    "Designed ETL pipelines (Airflow + BigQuery) for feature engineering and training data management, reducing data preparation overhead by 60%.",
                    "Collaborated with product and data teams to prioritize model improvements that led to a 12% lift in user retention for targeted cohorts."
                ]
            },
            {
                "name": "Research Assistant, CMU Language Technologies Institute",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Conducted research on sequence-to-sequence models for low-resource machine translation; co-authored 1 conference paper.",
                    "Implemented novel data augmentation strategies that improved BLEU by 3-5 points on multiple low-resource language pairs.",
                    "Built reproducible experiment pipelines and maintained shared model checkpoints and evaluation scripts for the lab."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Personalization Engine",
                "description": "End-to-end system for real-time feature ingestion, online ranking with a distilled transformer, and adaptive exploration using contextual bandits.",
                "technologies": [
                    "PyTorch",
                    "Kafka",
                    "Kubeflow",
                    "Redis",
                    "Docker",
                    "Kubernetes",
                    "Prometheus"
                ],
                "year": 2023
            },
            {
                "name": "TorchTimeSeries (open-source)",
                "description": "A lightweight PyTorch library for time-series forecasting with modular datasets, encoders/decoders, and training utilities. Focused on ease of use for practitioners.",
                "technologies": [
                    "PyTorch",
                    "Python",
                    "pytest",
                    "GitHub Actions"
                ],
                "year": 2020
            },
            {
                "name": "Customer Intent Classifier",
                "description": "Production NLP service for intent classification and entity extraction deployed with TF Serving and a scalable feature store.",
                "technologies": [
                    "TensorFlow",
                    "TF Serving",
                    "Airflow",
                    "BigQuery"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Carnegie Mellon University",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S., Computer Science"
            }
        ],
        "skills": [
            "Machine Learning",
            "Deep Learning",
            "NLP",
            "PyTorch",
            "TensorFlow",
            "MLOps",
            "Kubeflow",
            "Docker",
            "Kubernetes",
            "Kafka",
            "Spark",
            "SQL",
            "BigQuery",
            "AWS",
            "GCP",
            "Model Optimization (distillation, quantization)",
            "Python"
        ],
        "achievements": [
            "Increased product CTR by 18% with a deployed personalization model at Nexa Labs.",
            "Reduced model inference latency by 40% and serving cost by 30% through distillation and quantization.",
            "Open-source contributor: TorchTimeSeries adopted by community projects and 150+ stars on GitHub.",
            "Co-authored a conference paper on low-resource machine translation."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Khan",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and product-focused; values code review, reproducible experiments, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Mission Bay, 94107"
            },
            "phone": "+1 (415) 555-0138",
            "email": "aisha.khan@example.com",
            "linkedin": "https://www.linkedin.com/in/aishakhan",
            "github": "https://github.com/aishakhan"
        },
        "summary": "Data Scientist with 9+ years building and deploying ML systems in healthcare and fintech. Strong background in statistical modeling, deep learning, and production ML engineering. Proven track record delivering models that improve business KPIs, reduce latency, and scale to millions of users.",
        "experience": [
            {
                "name": "NovaHealth Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Lead data scientist responsible for a team of 4 engineers and data scientists; set technical roadmap and mentored junior staff.",
                    "Designed and productionized patient-risk models (gradient-boosted & deep learning ensembles) that increased 30-day engagement by 18% and reduced avoidable readmissions by 12%, contributing to an estimated $8M annualized savings.",
                    "Built CI/CD for ML using Airflow, MLflow, Docker and Kubernetes; automated model monitoring and drift alerts, reducing incident response time by 70%.",
                    "Optimized inference pipeline, reducing latency from 450ms to 120ms through model quantization and feature caching.",
                    "Collaborated with product and clinical teams to deploy A/B tests and interpret causal impact using uplift modeling and difference-in-differences analyses."
                ]
            },
            {
                "name": "BrightMetrics",
                "date": {
                    "start": 2017,
                    "end": 2021
                },
                "bullets": [
                    "Built fraud and churn detection systems using XGBoost and deep learning; delivered a precision uplift of 24% over prior rule-based system.",
                    "Led design of data platform pipelines with BigQuery and Airflow, enabling near-real-time feature pipelines for streaming scoring.",
                    "Introduced model explainability (SHAP) to product dashboards, improving stakeholder trust and adoption of ML-driven recommendations.",
                    "Published internal best-practices for feature engineering and model lifecycle; reduced time-to-production for new models by 40%."
                ]
            },
            {
                "name": "Stanford NLP Lab",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Research assistant focused on clinical NLP and entity extraction; implemented sequence-to-sequence models and transfer learning approaches.",
                    "Co-authored two peer-reviewed papers on clinical entity normalization and low-resource domain adaptation.",
                    "Built data annotation pipeline and managed crowd annotation, achieving 92% inter-annotator agreement on key labels."
                ]
            }
        ],
        "projects": [
            {
                "name": "PredictiveCare Risk Engine",
                "description": "End-to-end risk prediction system for hospital readmission that integrates EHR and claims data; includes feature store, model registry, and real-time scoring service.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "TensorFlow",
                    "BigQuery",
                    "Airflow",
                    "MLflow",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Fraud Detector",
                "description": "Streaming fraud detection pipeline using feature enrichment, Spark streaming, and a light-weight neural scoring model deployed in Kubernetes for sub-second decisions.",
                "technologies": [
                    "Python",
                    "Spark",
                    "Kafka",
                    "Docker",
                    "Kubernetes",
                    "AWS"
                ],
                "year": 2022
            },
            {
                "name": "Adaptive Dialogue Agent (clinical)",
                "description": "Fine-tuned transformer-based dialogue agent for clinician-patient triage in low-resource settings; includes response ranking and safety filters.",
                "technologies": [
                    "PyTorch",
                    "HuggingFace Transformers",
                    "Docker",
                    "Kubernetes",
                    "NumPy"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "MS in Computer Science (AI specialization)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "BS in Electrical Engineering & Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "SQL",
            "BigQuery",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "MLflow",
            "Model Monitoring",
            "Causal Inference",
            "NLP",
            "Computer Vision",
            "A/B Testing",
            "Feature Engineering"
        ],
        "achievements": [
            "Delivered production models that generated ~$8M in annualized cost savings for healthcare customers.",
            "Reduced inference latency by 60% through model optimization and engineering improvements.",
            "Co-authored 4 peer-reviewed papers in clinical NLP and ML applications.",
            "Mentored and coached 8+ junior engineers and data scientists; established onboarding curriculum and best practices.",
            "Open-sourced a feature-engineering library used by internal teams to standardize pipelines."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Coursera: Advanced Machine Learning Specialization",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on mentorship, experimentation, and continuous learning",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-510-555-4821",
            "email": "maya.patel@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-patel-ds",
            "github": "https://github.com/mayapatel"
        },
        "summary": "Data Scientist with 9+ years of experience building and productionizing ML systems for fintech and SaaS. Strong background in supervised learning, time-series forecasting, causal inference, and MLOps. Skilled in turning ambiguous business problems into measurable ML solutions, mentoring teams, and delivering scalable model pipelines in cloud environments.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 BrightWave Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a customer churn model (XGBoost + calibrated probabilities) that reduced monthly churn by 18% and increased ARR by 7% through targeted retention campaigns.",
                    "Built end-to-end model pipelines using Airflow, Docker, and AWS SageMaker to automate feature generation, training, validation, and deployment, reducing model release time from 6 weeks to 10 days.",
                    "Implemented monitoring and drift detection (KS-stat, PSI) and automated retraining triggers, reducing model degradation incidents by 80%.",
                    "Mentored a team of 4 data scientists and ran weekly code reviews and model validation sessions to raise model quality and reproducibility standards."
                ]
            },
            {
                "name": "Data Scientist \u2014 FinNova Labs",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Designed a real-time fraud detection pipeline using streaming feature stores and LightGBM, cutting fraud losses by 37% and false positive rates by 22% through better feature engineering and cost-aware thresholds.",
                    "Led A/B tests and applied causal inference techniques to quantify impact of pricing and feature changes; provided recommendations that increased conversion by 4.3%.",
                    "Collaborated with engineers to containerize models and integrate them into low-latency microservices (avg inference latency < 120ms)."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 NovaTech Solutions",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built and productionized forecasting models (Prophet, LSTM) for demand prediction, improving forecast accuracy (MAPE) by 25% over baseline heuristics.",
                    "Implemented scalable Spark ETL jobs and established best-practice feature stores used across multiple product teams.",
                    "Introduced unit testing and CI for model training code, reducing production incidents related to data pipeline breaks."
                ]
            }
        ],
        "projects": [
            {
                "name": "Customer Churn Prediction & Retention Engine",
                "description": "End-to-end system to predict churn risk and generate prioritized retention treatment lists. Integrated propensity scores with business rules to produce targeted campaigns.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Airflow",
                    "AWS SageMaker",
                    "Postgres"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Fraud Detection",
                "description": "Stream-based fraud scoring service using feature store, LightGBM models, and Kafka for event ingestion; included model explainability dashboards for analysts.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "LightGBM",
                    "Docker",
                    "AWS Lambda"
                ],
                "year": 2022
            },
            {
                "name": "NLP Summarizer for Customer Support",
                "description": "Extractive-abstractive pipeline to summarize long support threads and auto-generate suggested replies, cutting average handle time by 15%.",
                "technologies": [
                    "Python",
                    "spaCy",
                    "Hugging Face Transformers",
                    "FastAPI"
                ],
                "year": 2020
            },
            {
                "name": "A/B Experimentation Platform",
                "description": "Built internal experimentation framework with automated metric calculation, sample size estimation, and sequential testing controls to standardize release experiments.",
                "technologies": [
                    "SQL",
                    "Python",
                    "Jupyter",
                    "Looker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Michigan \u2014 B.S. Statistics",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "pandas",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "PyTorch",
            "TensorFlow",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, S3, Lambda)",
            "GCP",
            "MLflow",
            "Time-series forecasting",
            "Causal inference",
            "A/B testing",
            "NLP",
            "Data visualization (Tableau, Looker)"
        ],
        "achievements": [
            "Delivered a churn reduction program that increased ARR by 7% within 6 months of deployment.",
            "Reduced model inference latency 5x by optimizing feature pipelines and containerization.",
            "Presented a case study on production ML monitoring at PyData 2022.",
            "Led hiring and onboarding for a 4-person data science team, decreasing ramp time by 30%."
        ],
        "certifications": [
            {
                "name": "Google Professional Machine Learning Engineer",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Databricks Certified Data Engineer Associate",
                "date": 2021
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on continuous learning, mentoring, and shipping production ML systems.",
        "contact": {
            "address": {
                "region": "Cambridge, MA, USA",
                "detail": "Near Kendall Square"
            },
            "phone": "+1-617-555-0123",
            "email": "aisha.rahman@example.com",
            "linkedin": "linkedin.com/in/aisharahman",
            "github": "github.com/aisharahman"
        },
        "summary": "AI Engineer with 8+ years building and shipping production ML systems, recommendation engines, and LLM-based solutions. Strong track record in model deployment, MLOps, and cross-functional collaboration to deliver measurable business outcomes. Comfortable designing end-to-end pipelines, optimizing latency and cost, and mentoring engineers.",
        "experience": [
            {
                "name": "Senior AI Engineer, Lumina Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of a hospital readmission risk model that reduced 30-day readmissions by 18% after deployment (served via REST + gRPC).",
                    "Designed and owned MLOps stack (Kubernetes, Kubeflow, ArgoCD, Docker) for continuous training and deployment; reduced model deployment time from weeks to hours.",
                    "Implemented feature store using Feast and optimized feature retrieval, cutting inference latency by 35% and improving model throughput.",
                    "Built privacy-preserving POC using federated learning for cross-hospital model training; collaborated with security and compliance teams to produce risk assessment."
                ]
            },
            {
                "name": "Machine Learning Engineer, Nova Retail",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed personalized product recommendation system (hybrid matrix factorization + content embeddings) increasing CTR by 18% and average order value by 9%.",
                    "Created real-time feature pipelines and streaming inference (Kafka, Flink) supporting 5k TPS with 99th percentile latency under 120ms.",
                    "Introduced model monitoring and automated rollback based on drift detection and business KPIs, reducing live incident rate by 40%.",
                    "Partnered with data engineering to migrate models to a standardized inference platform, saving ~30% on compute costs through improved batching and model quantization."
                ]
            },
            {
                "name": "Data Scientist, Beacon Analytics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built customer segmentation and churn prediction models used by marketing to tailor campaigns, improving retention lift by 12%.",
                    "Performed A/B testing and causal analysis to evaluate pricing experiments; documented data-driven recommendations that increased revenue per user.",
                    "Implemented ETL and feature engineering pipelines in Python and SQL to accelerate model iteration time for the analytics team."
                ]
            }
        ],
        "projects": [
            {
                "name": "Retrieval-Augmented Customer Support Agent",
                "description": "Developed a production RAG system for customer support combining a semantic search index with an LLM to answer product queries. Integrated vector store, document chunking, and context filtering to improve answer accuracy and reduce hallucinations.",
                "technologies": [
                    "LangChain",
                    "OpenAI API",
                    "FAISS",
                    "Postgres",
                    "Docker",
                    "FastAPI"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Personalization Engine",
                "description": "Built a low-latency personalization service that served recommendations in under 120ms using streaming features and embeddng similarity. Deployed as autoscaling microservices with multi-region support.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "TensorFlow",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Hospital Readmission Risk Model (Proof-of-Concept)",
                "description": "Created an explainable gradient-boosted model with integrated SHAP explanations to help clinicians understand drivers of readmission risk; delivered dashboards and inference APIs.",
                "technologies": [
                    "XGBoost",
                    "SHAP",
                    "Python",
                    "Flask",
                    "Postgres"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "Northeastern University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "University of Dhaka",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "LangChain",
            "OpenAI / LLM APIs",
            "MLOps (Kubeflow, ArgoCD)",
            "Kubernetes",
            "Docker",
            "Kafka",
            "Flink",
            "Feast (feature store)",
            "SQL",
            "Model monitoring & observability",
            "AWS (S3, SageMaker, EKS)"
        ],
        "achievements": [
            "Published workshop paper on federated learning applications in healthcare (NeurIPS Workshop, 2021).",
            "Led cross-functional migration that reduced annual inference infrastructure costs by ~30%.",
            "Mentored 6+ junior engineers and interns; organized internal ML best-practices brown-bag series."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Google Cloud Professional Machine Learning Engineer",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Asha R. Menon",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, outcome-driven teams that prioritize reproducible code, peer review, and mentorship; values user-centered product thinking and measurable impact.",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "Seattle, WA, USA"
            },
            "phone": "+1-425-555-0147",
            "email": "asha.menon@example.com",
            "linkedin": "https://www.linkedin.com/in/asharmenon",
            "github": "https://github.com/ashamenon"
        },
        "summary": "Data Scientist with 7+ years of applied experience building production ML systems for healthcare and retail. Skilled in end-to-end model development, feature engineering, MLOps, and scalable data pipelines. Strong track record delivering measurable business impact (revenue uplift, cost reduction, and operational automation) and mentoring cross-functional teams.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Arcadia Health Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a risk stratification model for chronic disease patients using electronic health record and claims data; improved high-risk patient identification precision by 34% and helped reduce avoidable admissions by 12% in pilot.",
                    "Designed and implemented a Kubeflow-based training and CI/CD pipeline, reducing model retrain time from 3 days to 6 hours and enabling weekly automated re-training.",
                    "Partnered with clinicians and product managers to translate model outputs into care pathways, contributing to a 15% increase in care management program enrollment.",
                    "Mentored 4 data scientists and established coding standards, unit test coverage for model code, and reproducible experiment tracking using MLflow."
                ]
            },
            {
                "name": "Data Scientist \u2014 Quantix Retail Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built ensemble demand-forecasting models (gradient boosting + Prophet) for 200+ SKUs, cutting inventory stockouts by 28% and reducing overstock by 18%\u2014estimated annual savings $1.2M for a major client.",
                    "Implemented a feature store and daily ETL pipeline using Airflow and Spark, enabling consistent feature reuse and eliminating data leakage across experiments.",
                    "Developed a sales uplift causal model to measure promo effectiveness; findings informed pricing strategy that increased promotional ROI by 22%.",
                    "Worked closely with engineering to containerize models and expose REST endpoints with Flask and Docker for A/B testing."
                ]
            },
            {
                "name": "Data Science Intern \u2014 NovaTech",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Prototype NLP pipeline for automated customer feedback classification using spaCy and BERT embeddings, achieving 87% F1 on labeled set and reducing manual triage by 40%.",
                    "Conducted exploratory analyses and built dashboards (Tableau) to surface key product metrics and user sentiment trends for stakeholders."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Clinical Deterioration Detector",
                "description": "Production-grade streaming anomaly detection model to identify early signs of patient deterioration using vital signs and lab results; integrates with hospital alerting workflows.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Kafka",
                    "Kubernetes",
                    "Prometheus"
                ],
                "year": 2023
            },
            {
                "name": "Customer Churn Prediction & Retention Engine",
                "description": "End-to-end pipeline and model to predict churn and generate personalized retention actions; includes uplift modeling to prioritize highest-ROI interventions.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "MLflow",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Sales Forecasting Pipeline",
                "description": "Automated forecasting stack combining feature engineering, ensembling, and probabilistic forecasts for weekly demand planning across retail stores.",
                "technologies": [
                    "Spark",
                    "Prophet",
                    "LightGBM",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Model Monitoring & Drift Detection Toolkit",
                "description": "Toolset to monitor model performance, data drift, and feature distributions in production; includes alerting and automated dataset snapshotting for retraining triggers.",
                "technologies": [
                    "Pandas",
                    "Great Expectations",
                    "Grafana",
                    "MLflow"
                ],
                "year": 2024
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Delhi",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "TensorFlow",
            "PyTorch",
            "XGBoost",
            "LightGBM",
            "Spark",
            "Airflow",
            "Kubernetes",
            "Docker",
            "MLflow",
            "Feature Engineering",
            "Time Series Forecasting",
            "Causal Inference",
            "Model Monitoring"
        ],
        "achievements": [
            "Improved predictive model precision by 34% for patient risk stratification leading to measurable reductions in hospital readmissions.",
            "Designed CI/CD pipelines that cut model deployment time by >70% across teams.",
            "Authored a peer-reviewed conference paper on time-series ensembling methods (presented at a regional ML workshop)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Data Scientist (CDS)",
                "date": 2019
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, learning-focused \u2014 values code review, shared ownership, and clear product metrics.",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "1201 Elliott Ave W, Apt 4B"
            },
            "phone": "+1-206-555-0143",
            "email": "maya.patel23@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-patel",
            "github": "https://github.com/mayarpatel"
        },
        "summary": "Data Scientist with 7+ years of experience applying statistical modeling, ML, and product analytics to drive revenue growth and operational efficiency. Strong background building end-to-end ML features in production, experiment design, and communicating results to cross-functional partners. Comfortable in cloud-native stacks (AWS/GCP), Python, and SQL.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Aurelius Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led modeling efforts for a patient risk-scoring pipeline used by care teams; deployed real-time model in production reducing 30-day readmissions by 12% (A/B test, p < 0.01).",
                    "Built feature store and standardized data infra (Airflow + S3), reducing model retraining time from 3 hours to 25 minutes and cutting infra costs by 18%.",
                    "Partnered with product and clinical teams to design experiments and KPIs; translated technical findings into actionable product roadmaps adopted across 20+ clinics.",
                    "Mentored 4 junior data scientists; introduced model validation checklists and CI tests for data drift monitoring."
                ]
            },
            {
                "name": "Data Scientist \u2014 Nimble Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Designed and deployed recommendation models (matrix factorization + gradient boosting) that increased engagement by 22% and monthly revenue per user by 9%.",
                    "Developed end-to-end ETL and feature pipelines using BigQuery and dbt; reduced query costs 35% via denormalization and partitioning.",
                    "Led A/B testing and causal analysis for pricing experiments, providing executive-level summaries and statistical guidance for product launches.",
                    "Created interactive dashboards (Looker) for marketing and growth teams enabling self-serve analysis and decreasing reporting requests by 40%."
                ]
            },
            {
                "name": "Data Analyst \u2014 MetroRetail",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built forecasting models for inventory planning improving stock availability by 8% while lowering overstock by 11%.",
                    "Automated BI reports and SQL ETL jobs; saved ~10 hours/week across the analytics team and standardized KPIs for store ops.",
                    "Performed cohort and funnel analyses to uncover retention drivers used to inform email campaigns with a 15% lift in 30-day retention."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Deterioration Early Warning System",
                "description": "Prototype real-time model combining EHR vitals, labs, and NLP from clinician notes to flag patients at high risk of deterioration. Delivered model API and a dashboard for clinical workflows.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "FastAPI",
                    "Postgres",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Personalized Product Recommendations",
                "description": "Built hybrid recommendation engine using collaborative filtering and content-based features; integrated with product catalog and A/B tested variants for ranking.",
                "technologies": [
                    "Spark",
                    "TensorFlow",
                    "BigQuery",
                    "Airflow"
                ],
                "year": 2020
            },
            {
                "name": "Customer Churn Dashboard & Prediction",
                "description": "End-to-end churn prediction with feature engineering, survival analysis, and a Looker dashboard enabling targeted retention campaigns.",
                "technologies": [
                    "Python",
                    "lifelines",
                    "Looker",
                    "SQL"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington \u2014 M.S., Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Data Science"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S., Statistics",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "Pandas",
            "BigQuery",
            "AWS (S3, Lambda)",
            "GCP",
            "dbt",
            "Airflow",
            "Experiment Design",
            "Causal Inference",
            "Product Analytics",
            "Data Visualization (Looker, Tableau)"
        ],
        "achievements": [
            "Published conference poster on time-series feature engineering at ML4Health 2022.",
            "Delivered a production model that contributed to a 12% reduction in 30-day readmissions at Aurelius Health.",
            "Organized monthly internal ML brown-bag series and increased cross-team attendance by 3x."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Alex R. Moreno",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and engineering-first with strong emphasis on reproducibility and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0124",
            "email": "alex.moreno@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-r-moreno",
            "github": "https://github.com/armoreno"
        },
        "summary": "AI Engineer with 9+ years building production ML systems and deploying large-scale deep learning models. Strong background in model engineering, MLOps, and inference optimization for transformer-based architectures. Experienced in designing reproducible pipelines, CI/CD for models, and cross-functional collaboration to deliver business impact.",
        "experience": [
            {
                "name": "Senior AI Engineer, Nimbus AI (Hybrid)",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multi-tenant LLM inference platform using Kubernetes, KServe and NVIDIA Triton; supported 50+ production endpoints with autoscaling and A/B rollouts.",
                    "Reduced inference cost by 62% via mixed-precision conversion, batch scheduling, and ONNX export for transformer models (BERT/OPT family).",
                    "Built CI/CD model pipelines with GitHub Actions, MLflow, and TFX enabling reproducible training, automated validation, and one-click promotion to staging/production.",
                    "Collaborated with product and privacy teams to implement differential privacy controls and secure model access for customer data.",
                    "Mentored 4 junior engineers; established best practices for model card documentation and monitoring SLAs."
                ]
            },
            {
                "name": "AI Engineer, Horizon Data Systems (On-site)",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed end-to-end pipelines (Airflow, Spark, BigQuery) for feature engineering and model training used by fraud detection and personalization teams.",
                    "Deployed real-time scoring service (gRPC) and reduced prediction latency from 180ms to 45ms through model quantization and optimized feature lookups.",
                    "Implemented model monitoring (prometheus + Grafana + custom drift detectors) and automated rollback procedures for performance regressions.",
                    "Introduced model explainability tooling (SHAP integration) into production dashboards to support compliance and stakeholder reviews."
                ]
            },
            {
                "name": "Machine Learning Engineer, OpenRetail (On-site)",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Built customer churn and demand forecasting models (XGBoost, LSTM) that improved retention targeting and reduced churn by 8% year-over-year.",
                    "Packaged models as Dockerized services and partnered with DevOps to standardize deployment templates across teams.",
                    "Established unit and integration tests for model training code, increasing reproducibility and reducing training failures in CI by 70%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Prod-Scale LLM Serving Platform",
                "description": "Designed and implemented a production LLM hosting platform supporting multiple transformer backbones with dynamic batching, autoscaling, model sharding, and cost-aware dispatching. Integrated A/B experimentation and online feedback loop for continual tuning.",
                "technologies": [
                    "Kubernetes",
                    "Triton",
                    "KServe",
                    "PyTorch",
                    "ONNX",
                    "Redis",
                    "Prometheus"
                ],
                "year": 2023
            },
            {
                "name": "Model Monitoring & Drift Detection",
                "description": "Built a monitoring pipeline to detect data and concept drift using statistical tests and embeddings-based similarity. Automated alerts and model rollback workflows linked to CI/CD.",
                "technologies": [
                    "MLflow",
                    "Airflow",
                    "Kafka",
                    "Pandas",
                    "scikit-learn"
                ],
                "year": 2021
            },
            {
                "name": "Realtime Recommendation Engine",
                "description": "Implemented a hybrid retrieval and ranking recommendation system that combined approximate nearest neighbors with a learned reranker to increase click-through by 12%.",
                "technologies": [
                    "Faiss",
                    "PyTorch",
                    "FastAPI",
                    "Docker"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "Stanford University \u2014 M.S., Computer Science (AI Specialization)",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S., Electrical Engineering & Computer Sciences",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "JAX",
            "Transformers (Hugging Face)",
            "MLOps (MLflow, TFX)",
            "Kubernetes",
            "Docker",
            "Triton",
            "ONNX",
            "AWS (SageMaker, EC2, S3)",
            "GCP (BigQuery, Dataflow)",
            "Airflow",
            "Spark",
            "SQL",
            "Model optimization & quantization",
            "CI/CD for ML",
            "Monitoring & observability"
        ],
        "achievements": [
            "Cut inference cost for a flagship product by 62% while improving P99 latency via model optimization and dynamic batching.",
            "Delivered a production LLM platform that scaled to support 100k requests/day across 50+ endpoints.",
            "Invited speaker at two industry conferences on MLOps and inference optimization (2022, 2024).",
            "Mentored and helped onboard 8 engineers into ML production best practices; established team-wide model governance."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Kubernetes Administrator (CKA)",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Arjun Rao",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, feedback-oriented, and growth-focused",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala 2nd Block"
            },
            "phone": "+91-9876543210",
            "email": "arjun.rao25@example.com",
            "linkedin": "https://www.linkedin.com/in/arjun-rao25",
            "github": "https://github.com/arjunrao25"
        },
        "summary": "Data Scientist with 7+ years of experience building production ML systems for fintech and analytics products. Strong background in feature engineering, end-to-end model deployment, and A/B testing. Skilled at translating business problems into scalable data solutions and driving measurable impact through improved models and instrumentation.",
        "experience": [
            {
                "name": "Zentri Analytics \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a customer-churn prediction pipeline that reduced churn by 12% quarter-over-quarter; responsible for feature engineering, model selection (XGBoost + LightGBM ensembles) and CI/CD for model serving.",
                    "Designed a real-time scoring service (FastAPI + Docker + AWS ECS) and optimized latency by 40% through model quantization and feature caching.",
                    "Partnered with product and growth teams to define experiments; implemented instrumentation and analytics that increased trial-to-paid conversion by 8%.",
                    "Mentored 4 junior data scientists, introduced code review standards, and established reproducible modeling templates used across the analytics org."
                ]
            },
            {
                "name": "Finova Labs \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built credit-risk scoring models using logistic regression, gradient boosting, and custom scorecards; decreased default rates in pilot by 9% while maintaining approval volume.",
                    "Implemented feature stores (Delta Lake on Databricks) and standardized pipelines using Airflow, reducing feature development time by 30%.",
                    "Conducted causal analysis and designed A/B tests for pricing changes; results informed a pricing strategy that improved margin by 3 percentage points.",
                    "Automated model monitoring and drift detection using statistical tests and alerting; reduced silent model degradation incidents by 70%."
                ]
            },
            {
                "name": "CortexAI \u2014 ML Engineer Intern",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Implemented NLP preprocessing and intent-classification prototypes using spaCy and TensorFlow for a conversational assistant.",
                    "Developed evaluation dashboards to compare model candidates and track precision/recall tradeoffs across intents.",
                    "Contributed to productionizing models with Docker and CI pipelines for staged deployment."
                ]
            }
        ],
        "projects": [
            {
                "name": "Credit-Optimizer (internal toolkit)",
                "description": "A modular pipeline for credit-scoring experiments that integrates data ingestion, feature store, model training, automated hyperparameter tuning, and deployment. Enables rapid A/B testing of model variants with built-in fairness checks.",
                "technologies": [
                    "Python",
                    "Spark",
                    "LightGBM",
                    "MLflow",
                    "Airflow",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Fraud Scoring",
                "description": "Low-latency fraud scoring service combining stream processing and lightweight ML models to flag suspicious transactions in under 50ms, with a follow-up offline ensemble for investigative prioritization.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "FastAPI",
                    "ONNX",
                    "Postgres"
                ],
                "year": 2022
            },
            {
                "name": "Open-Source Feature Tools",
                "description": "Published a Python library for standardized feature validation and drift detection used by internal teams; includes utilities for missingness checks, distribution comparisons, and alerting hooks.",
                "technologies": [
                    "Python",
                    "pandas",
                    "pytest"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Science, Bengaluru \u2014 M.S. in Computer Science (Machine Learning)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "Master of Science"
            },
            {
                "name": "University of Mumbai \u2014 B.Sc. Computer Science",
                "date": {
                    "start": 2012,
                    "end": 2015
                },
                "degree": "Bachelor of Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Spark",
            "scikit-learn",
            "LightGBM",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "MLflow",
            "Airflow",
            "Docker",
            "FastAPI",
            "Kafka",
            "A/B testing",
            "Feature engineering",
            "Model monitoring"
        ],
        "achievements": [
            "Delivered a churn-reduction model that decreased monthly churn by 12%, contributing to a projected $1.2M ARR uplift.",
            "Open-sourced a feature-validation library adopted by 3 teams internally and 400+ stars on GitHub.",
            "Presented work on model monitoring at the 2023 Data & ML Ops Summit."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Data Scientist (DASCA)",
                "date": 2019
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Maya R. Singh",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, product-focused teams that prioritize experimentation, mentorship, and clear impact measurement.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0198",
            "email": "maya.singh@example.com",
            "linkedin": "https://www.linkedin.com/in/mayarisingh",
            "github": "https://github.com/mayarisingh"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems and analytics platforms for e-commerce and health domains. Strong background in time-series forecasting, recommender systems, experimentation, and scalable ML pipelines. Experienced in leading cross-functional teams to deliver measurable product impact.",
        "experience": [
            {
                "name": "Senior Data Scientist, InsightAnalytics Inc.",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a team of 4 data scientists and ML engineers to deliver ML-driven personalization and forecasting features for a B2B analytics platform.",
                    "Designed and deployed a hierarchical demand-forecasting microservice (ensemble of LightGBM + LSTM) in Docker on AWS, reducing stockouts for customers by 18% and improving forecast accuracy (MAPE down 22%).",
                    "Implemented robust model CI/CD with automated retraining, monitoring (DataDog + custom drift detectors), and rollback, decreasing model incident MTTR by 60%.",
                    "Partnered with product and engineering to run >50 A/B tests; instrumented metrics and established statistical significance workflows to attribute incremental revenue and guide roadmap decisions."
                ]
            },
            {
                "name": "Data Scientist, Shoply (e-commerce startup)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built real-time recommendation pipelines using matrix factorization and item/content embeddings serving personalized product suggestions across web and mobile.",
                    "Developed feature engineering workflows in Spark and Airflow, enabling fresh features to be computed hourly and improving CTR from recommendations by 28%.",
                    "Led exploratory analyses and causal inference studies to quantify promotions lift, influencing pricing and discount strategy that increased GMV by 9%.",
                    "Mentored junior data scientists and established code review and testing standards for ML notebooks and models."
                ]
            },
            {
                "name": "Data Analyst, City Health Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Created interactive dashboards and visualizations to support public health initiatives using R Shiny and Tableau.",
                    "Performed cohort analyses and survival models for clinical studies, producing reports used by stakeholders and grant proposals.",
                    "Standardized ETL pipelines and implemented reproducible analysis templates, reducing analysis turnaround time by 35%."
                ]
            }
        ],
        "projects": [
            {
                "name": "DemandSense (production forecasting microservice)",
                "description": "End-to-end forecasting service combining LightGBM and LSTM ensembles, automatic feature generation, and scheduled retraining. Packaged in Docker, deployed on AWS ECS with monitoring and alerting for drift.",
                "technologies": [
                    "Python",
                    "LightGBM",
                    "PyTorch",
                    "Docker",
                    "AWS (S3, ECS, Lambda)",
                    "Airflow"
                ],
                "year": 2023
            },
            {
                "name": "RecPlus (hybrid recommender)",
                "description": "Hybrid recommender combining matrix factorization with content-based embeddings and session-based re-ranking to serve personalized product suggestions with latency under 80ms.",
                "technologies": [
                    "Spark",
                    "scikit-learn",
                    "TensorFlow",
                    "Redis",
                    "Kafka"
                ],
                "year": 2019
            },
            {
                "name": "ClinicalDash (public health analytics dashboard)",
                "description": "Interactive R Shiny dashboard to visualize longitudinal public health metrics and clinical study outcomes; integrated ETL from clinical databases and automated report generation.",
                "technologies": [
                    "R",
                    "R Shiny",
                    "PostgreSQL",
                    "Docker"
                ],
                "year": 2017
            }
        ],
        "education": [
            {
                "name": "University of Washington \u2014 M.S., Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S., Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "numpy",
            "Spark",
            "Airflow",
            "Docker",
            "AWS",
            "A/B testing",
            "time-series forecasting",
            "recommendation systems",
            "model monitoring"
        ],
        "achievements": [
            "Reduced customer stockouts by 18% through a deployed forecasting system, resulting in measurable revenue gains for clients.",
            "Presented forecasting methodology and results at an industry workshop (Retail Analytics 2023).",
            "Mentored three junior data scientists who were promoted to mid-level roles within 18 months."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Ravi Menon",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and growth-oriented \u2014 values cross-functional teamwork, clear feedback loops, and production-quality engineering practices.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Somerville, MA"
            },
            "phone": "+1-617-555-4827",
            "email": "ravi.menon.datasci@gmail.com",
            "linkedin": "https://www.linkedin.com/in/ravimenon",
            "github": "https://github.com/ravimenon"
        },
        "summary": "Data Scientist with 8+ years of experience building and productionizing machine learning systems for healthcare and retail. Strong background in statistical modeling, applied deep learning (NLP & time series), and MLOps. Proven track record delivering measurable business impact by deploying robust models, automating pipelines, and mentoring cross-functional teams.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 BrightWave Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a patient no-show and cancellation prediction system that reduced no-show rates by 22% and recovered $1.1M annualized revenue through targeted outreach.",
                    "Designed a hybrid modeling stack (XGBoost + LSTM) for appointment-level forecasting; deployed models using Kubeflow Pipelines, achieving <24-hour retraining and 95% automated rollout coverage.",
                    "Built explainability and monitoring dashboards (SHAP, WhyLogs, Grafana) for clinicians and ops teams to increase model trust and reduce false-positive alerts by 18%.",
                    "Owned ML lifecycle: feature engineering, CI/CD for models (GitHub Actions + Docker), Kubernetes-based serving (KFServing), and A/B testing with clear KPI gating.",
                    "Mentored 4 junior data scientists and collaborated with product and engineering to translate clinical constraints into feasible model requirements."
                ]
            },
            {
                "name": "Data Scientist \u2014 MarketPulse Analytics",
                "date": {
                    "start": 2019,
                    "end": 2021
                },
                "bullets": [
                    "Built a real-time recommendation engine for e-commerce clients using matrix factorization and content-aware embeddings; increased click-through-rate by 14% and conversion by 9%.",
                    "Implemented time-series demand forecasting (Prophet + XGBoost ensembles) reducing inventory stockouts by 12% across pilot stores.",
                    "Developed NLP pipelines for customer feedback classification (BERT fine-tuning) and automated tagging, reducing manual triage time by 70%.",
                    "Containerized models and established reproducible experiment tracking with MLflow; improved latency and reproducibility for client deployments."
                ]
            },
            {
                "name": "Data Analyst \u2014 Axis Retail",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Performed exploratory analysis and built sales attribution models using SQL and Python to inform marketing spend; optimized campaigns and increased ROI by 17%.",
                    "Automated ETL workflows with Airflow and wrote unit-tested transformation code, cutting weekly report generation time from 6 hours to 30 minutes.",
                    "Collaborated with BI and engineering teams to deliver KPI dashboards (Looker) used by regional managers for inventory decisions."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Risk Score \u2014 No-show & Readmission Model",
                "description": "End-to-end system to predict patient no-shows and 30-day readmission risk. Combined structured EHR features, appointment metadata, and simple NLP signals from intake notes. Designed alerting workflows for care coordinators.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "PyTorch",
                    "pandas",
                    "Kubeflow",
                    "Docker",
                    "Postgres"
                ],
                "year": 2022
            },
            {
                "name": "Realtime Recommendation Engine",
                "description": "Online recommendation system for personalized product suggestions using hybrid embeddings and item co-visitation graphs. Integrated with client storefront via REST APIs for sub-100ms inference.",
                "technologies": [
                    "Spark",
                    "TensorFlow",
                    "Redis",
                    "Kafka",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Anomaly Detection for Transaction Fraud",
                "description": "Developed unsupervised anomaly detection pipeline leveraging autoencoders and isolation forests to detect fraudulent transactions. Created alert prioritization and review queues for fraud analysts.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "PyTorch",
                    "Airflow",
                    "S3"
                ],
                "year": 2021
            },
            {
                "name": "MLOps Reference Pipeline",
                "description": "Built a reusable CI/CD pipeline for model training, testing, and deployment with automated data and model validation; used as a template for cross-team adoption.",
                "technologies": [
                    "GitHub Actions",
                    "MLflow",
                    "Docker",
                    "Kubernetes",
                    "Terraform"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of Michigan \u2014 Ann Arbor",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "National Institute of Technology, Calicut",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.Tech in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "pandas",
            "scikit-learn",
            "PyTorch",
            "TensorFlow",
            "XGBoost",
            "NLP (BERT, transformers)",
            "Time series forecasting",
            "MLOps (Kubeflow, MLflow, Airflow)",
            "Model monitoring & explainability (SHAP, WhyLogs)",
            "Docker",
            "Kubernetes",
            "AWS (S3, SageMaker, Lambda)",
            "GCP",
            "Spark",
            "Data visualization (Looker, Tableau, Matplotlib)"
        ],
        "achievements": [
            "Reduced patient no-show rate by 22% through targeted predictive outreach, unlocking $1.1M annualized revenue at BrightWave Health.",
            "Delivered recommendation engine that increased client conversion by 9% and CTR by 14% for a major retail client.",
            "Presented applied NLP work at an industry workshop (ACL-affiliated) on lightweight model deployment for customer feedback.",
            "Mentored and grew a team of 4 junior data scientists; two promoted to mid-level roles within 12 months."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2023
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Arjun Mehta",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, learning-first team that values code quality, reproducibility, measurable impact, and cross-functional communication.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "123 Lakeview Ave, Apt 4B"
            },
            "phone": "+1-206-555-0142",
            "email": "arjun.mehta@example.com",
            "linkedin": "https://linkedin.com/in/arjun-mehta-ai",
            "github": "https://github.com/arjunm"
        },
        "summary": "AI Engineer with 7+ years of experience designing, training, and productionizing machine learning systems for recommendation, forecasting, and computer vision. Strong background in end-to-end ML lifecycle, feature engineering, MLOps, and scalable data pipelines on AWS and Kubernetes. Passionate about reliable model delivery, observability, and mentoring engineers.",
        "experience": [
            {
                "name": "WaveScale (AI product startup) \u2014 AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Designed and deployed a real-time recommendation microservice (PyTorch \u2192 TorchServe) on Kubernetes with autoscaling, reducing recommendation latency by 40% and increasing click-through by 12%.",
                    "Built streaming feature pipelines with Spark Structured Streaming and Kafka, enabling fresh feature availability (sub-minute) and cutting model staleness by 60%.",
                    "Implemented CI/CD for models using MLflow and GitHub Actions; automated validation and canary rollout, reducing model deployment time from days to hours.",
                    "Collaborated with product and analytics to instrument model metrics and slice-based monitoring; caught a data-drift incident that prevented a 6% revenue regression."
                ]
            },
            {
                "name": "Nordic Analytics \u2014 ML Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed demand-forecasting models (LSTM + Temporal Fusion Transformer) that reduced RMSE by 35% vs. baseline and improved inventory allocation, saving an estimated $800k annually.",
                    "Built a reusable feature store and ETL pipelines (Airflow, Spark) that reduced feature development time by 50% and standardized feature lineage and testing.",
                    "Led efforts to containerize training workflows and migrate training to AWS Sagemaker, enabling distributed training and reducing training time by 3x."
                ]
            },
            {
                "name": "Pacific Health Systems \u2014 Data Scientist (Contract)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Prototyped an NLP triage classifier for incoming patient notes achieving 0.88 F1, improving triage throughput by 25% in pilot.",
                    "Constructed dashboards and automated ETL jobs for clinical datasets (SQL, Python) to support cross-team research and model validation.",
                    "Performed feature importance and SHAP-based interpretability analyses to validate model recommendations with clinical stakeholders."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeVision \u2014 On-device Object Detection",
                "description": "Built a quantized MobileNetV3-based pipeline with pruning and post-training quantization to run 30+ FPS on ARM devices. Implemented a lightweight telemetry pipeline to collect inference metrics and device health.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "Quantization",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "RevenueSense \u2014 Demand Forecasting Platform",
                "description": "End-to-end forecasting platform using Temporal Fusion Transformers, automated backtesting, and a model registry. Integrated forecasts into inventory planning, reducing stockouts by 18%.",
                "technologies": [
                    "TensorFlow",
                    "PyTorch",
                    "Airflow",
                    "AWS SageMaker",
                    "MLflow"
                ],
                "year": 2020
            },
            {
                "name": "FeatureFlow \u2014 Feature Store and Pipelines",
                "description": "Implemented a centralized feature store and standardized ingestion pipeline (Spark, Delta Lake) with feature validation and lineage, enabling reproducible experiments across teams.",
                "technologies": [
                    "Spark",
                    "Delta Lake",
                    "Kafka",
                    "Python"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science"
            },
            {
                "name": "University of Mumbai",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Computer Engineering"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, EKS, S3)",
            "MLflow",
            "Feature stores",
            "Model interpretability (SHAP, LIME)",
            "NLP",
            "Computer Vision",
            "Distributed training",
            "MLOps"
        ],
        "achievements": [
            "Delivered production recommendation system at WaveScale that increased CTR by 12% within first quarter of rollout.",
            "Reduced model training time by 3x by moving to distributed training and optimized data pipelines.",
            "Authored internal best-practices for model monitoring and CI/CD that were adopted company-wide.",
            "Mentored 6 junior engineers and ran a quarterly ML brown-bag series."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Alex Martin",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, fast-moving team that values mentorship, ownership, and production-ready ML systems.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "1234 Market St, Apt 8B"
            },
            "phone": "+1-415-555-0129",
            "email": "alex.martin29@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-martin29",
            "github": "https://github.com/amartin29"
        },
        "summary": "Data Scientist with 8+ years building and productionizing ML solutions in healthcare and retail. Experienced in end-to-end model development, MLOps, and cross-functional delivery. Strong quantitative background, pragmatic engineering focus, and history of improving business metrics through scalable models.",
        "experience": [
            {
                "name": "Senior Data Scientist, NexaHealth",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a clinical risk stratification model that increased early-detection interventions by 22% and improved 6-month readmission AUC from 0.72 to 0.83.",
                    "Built CI/CD pipelines for model retraining and deployment using Terraform, Docker, and AWS SageMaker; reduced deployment time from weeks to under 2 hours.",
                    "Designed feature store and standardized data contracts, decreasing feature engineering time across teams by 35%.",
                    "Mentored a team of 4 data scientists and introduced rigorous model validation and documentation practices."
                ]
            },
            {
                "name": "Data Scientist, Quantum Analytics",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed customer lifetime value and propensity models used to personalize promotions, generating a 12% lift in average revenue per user.",
                    "Implemented XGBoost and deep-learning hybrid models with hyperparameter optimization (Optuna), improving model accuracy by 9% vs baseline.",
                    "Partnered with engineering to productionize models via Kubernetes and Flask APIs, supporting 100k+ daily predictions with <200ms latency.",
                    "Conducted A/B tests and causal analysis to measure model-driven campaign performance, informing product roadmap decisions."
                ]
            },
            {
                "name": "ML Engineer, OpenRetail Labs",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Built recommendation systems and real-time scoring pipelines using Spark, Redis, and Kafka; increased click-through-rate by 8%.",
                    "Automated model monitoring and drift detection pipelines resulting in alerting and automatic retraining triggers.",
                    "Collaborated with product and design to translate business needs into measurable ML objectives and KPIs."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Risk Score Platform",
                "description": "End-to-end risk scoring system for predicting patient deterioration using EHR data. Included feature engineering, model training, validation, and deployment in AWS SageMaker with streaming inference.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "AWS SageMaker",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2024
            },
            {
                "name": "Customer Churn Ensemble",
                "description": "Ensemble model combining gradient boosting and neural nets to predict churn. Integrated with marketing workflow to target high-risk users with personalized offers.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "XGBoost",
                    "Airflow",
                    "Postgres"
                ],
                "year": 2021
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Low-latency recommendation service using collaborative filtering and session-based contextual signals; deployed with Kafka for streaming updates.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "Redis",
                    "Scala",
                    "Docker"
                ],
                "year": 2018
            },
            {
                "name": "Automated Model Monitoring & Retraining",
                "description": "Platform for monitoring model performance and data drift with automatic retraining pipelines and alerting; reduced manual intervention by 70%.",
                "technologies": [
                    "Prometheus",
                    "Grafana",
                    "MLflow",
                    "Airflow",
                    "Python"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. in Computer Science (Machine Learning focus)"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "TensorFlow",
            "PyTorch",
            "XGBoost",
            "Spark",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, EC2, S3)",
            "Airflow",
            "MLflow",
            "Data engineering",
            "A/B testing",
            "Feature engineering",
            "Model monitoring"
        ],
        "achievements": [
            "Published a co-authored paper on deployment strategies for clinical ML models at a peer-reviewed conference (2023).",
            "Reduced prediction latency of core scoring service by 60% through system redesign and optimized feature pipelines.",
            "Built production ML infrastructure that supported 100k+ daily predictions with 99.9% uptime.",
            "Regular speaker at local ML meetup groups and organized internal brown-bag sessions on MLOps best practices."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2023
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (CDS)",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, customer-focused; values experimentation, clear communication, and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Bay Area, United States"
            },
            "phone": "+1-415-555-0130",
            "email": "maya.patel@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-patel",
            "github": "https://github.com/mayarp"
        },
        "summary": "Data scientist with 8+ years of experience building production ML systems, conducting causal and A/B analyses, and turning large-scale data into actionable insights for product and operations. Strong background in Python, SQL, and cloud platforms; experienced in cross-functional collaboration and mentoring junior team members.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Aurora Health Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a clinical risk scoring model (XGBoost) that improved early-detection sensitivity by 22% and reduced false positives by 15% in production EMR pipeline.",
                    "Built end-to-end ML pipelines on AWS (S3, Lambda, SageMaker) and orchestrated features with Spark; reduced model refresh time from weekly to daily.",
                    "Partnered with clinicians and product managers to design randomized evaluations; ran 12+ A/B tests informing triage workflow changes that increased appropriate referrals by 18%.",
                    "Coached and mentored three junior data scientists, establishing code review standards and a team onboarding curriculum."
                ]
            },
            {
                "name": "Data Scientist \u2014 BlueWave Retail",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Owned demand forecasting models (Prophet, LSTM prototypes) across 50+ SKUs, improving forecast accuracy (MAPE) by an average of 12% over baseline heuristics.",
                    "Designed and implemented customer lifetime value models using survival analysis and uplift modeling to prioritize retention campaigns; uplift campaigns recovered $1.2M incremental revenue in first year.",
                    "Built interactive dashboards in Tableau and Looker for merchandising and ops teams; reduced time-to-insight for key KPIs from days to minutes.",
                    "Worked with data engineering to migrate ETL to dbt + Snowflake, standardizing feature pipelines and enabling reproducible experiments."
                ]
            },
            {
                "name": "Data Analyst \u2014 Beacon Solutions",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Performed cohort and funnel analyses to identify product drop-off points; recommendations led to a 9% increase in 30-day retention.",
                    "Automated daily reporting pipelines using Python and SQL, saving ~10 analyst-hours per week.",
                    "Conducted pricing sensitivity studies and built segmentation models to inform targeted promotions."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Readmission Risk Monitor",
                "description": "Production service that scores in-hospital patients for 30-day readmission risk using EHR streams, with alerts routed to care managers to prioritize interventions.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "AWS SageMaker",
                    "Kafka",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Inventory Demand Forecasting Platform",
                "description": "End-to-end forecasting pipeline combining feature store, model training, and deployment to serve store-level forecasts used in replenishment decisions.",
                "technologies": [
                    "PySpark",
                    "Prophet",
                    "TensorFlow",
                    "Snowflake",
                    "dbt"
                ],
                "year": 2019
            },
            {
                "name": "Uplift Modeling for Retention Campaigns",
                "description": "Built and evaluated uplift models to target customers most likely to respond positively to retention offers, maximizing ROI under budget constraints.",
                "technologies": [
                    "Python",
                    "causalml",
                    "scikit-learn",
                    "SQL"
                ],
                "year": 2020
            },
            {
                "name": "Interactive Executive Dashboard",
                "description": "Designed and shipped a cross-functional dashboard integrating sales, marketing spend, and retention metrics with drill-down capabilities for executives.",
                "technologies": [
                    "Looker",
                    "Tableau",
                    "BigQuery",
                    "SQL"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "University of Washington \u2014 M.S. Data Science",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "Master of Science in Data Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign \u2014 B.S. Electrical Engineering",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "Bachelor of Science in Electrical Engineering"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PySpark",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "Prophet",
            "causal inference",
            "A/B testing",
            "AWS (S3, SageMaker)",
            "dbt",
            "Snowflake",
            "Docker",
            "Looker",
            "Tableau"
        ],
        "achievements": [
            "Delivered models and tooling that contributed to $1.2M incremental revenue through targeted campaigns.",
            "Improved production model performance (AUC/recall) leading to a 22% lift in early-detection sensitivity for clinical use case.",
            "Reduced model refresh time from weekly to daily via automated pipelines, increasing responsiveness to data drift.",
            "Authored an internal best-practices guide for feature engineering and model validation adopted across the analytics organization."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2014 Specialty",
                "date": 2020
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2022
            },
            {
                "name": "Certified Data Scientist (DASCA)",
                "date": 2017
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth-minded; values mentorship, experimentation, and production-focused ML.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA, USA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (510) 555-0123",
            "email": "maya.patel31@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-patel-31",
            "github": "https://github.com/mayapatel31"
        },
        "summary": "Data Scientist with 5+ years of applied experience building and deploying ML systems in healthcare and SaaS. Strong background in supervised learning, time-series modeling, feature engineering, and production ML pipelines. Proven track record of improving model performance and business KPIs while enabling reproducible, scalable data workflows.",
        "experience": [
            {
                "name": "Senior Data Scientist, EdgeScale Analytics",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of a real-time churn prediction engine powering personalized retention campaigns (10% lift in retention for targeted cohorts).",
                    "Designed feature store and end-to-end pipelines using Spark, Airflow, and Parquet, reducing feature retrieval latency by 60%.",
                    "Implemented model monitoring and drift detection (RUL metrics + automated retraining triggers) which reduced model degradation incidents by 75%.",
                    "Mentored 3 junior data scientists and coordinated cross-functional A/B tests with product and growth teams."
                ]
            },
            {
                "name": "Data Scientist, Nimbus Health",
                "date": {
                    "start": 2020,
                    "end": 2022
                },
                "bullets": [
                    "Built clinical risk stratification models (XGBoost, LightGBM) to prioritize patient outreach, increasing high-risk identification precision by 18%.",
                    "Collaborated with clinicians to translate domain knowledge into interpretable features and SHAP-based explanations for decisions presented in provider dashboards.",
                    "Reduced inference costs by 40% through model compression and optimized batching on GCP, enabling cost-effective nightly scoring for 1M+ patients.",
                    "Authored reproducible model cards and CI for model training and evaluation to satisfy regulatory and audit requirements."
                ]
            },
            {
                "name": "Data Science Intern, CityLabs AI",
                "date": {
                    "start": 2019,
                    "end": 2020
                },
                "bullets": [
                    "Developed a customer segmentation pipeline using clustering and dimensionality reduction to power targeted marketing experiments.",
                    "Automated ETL processes with Airflow and implemented unit tests for data validation, cutting manual data prep time by half.",
                    "Presented findings to stakeholders; recommendations were integrated into the retention playbook."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Churn Prediction Engine",
                "description": "End-to-end system for scoring users in near real-time and triggering personalized retention offers. Included feature engineering, streaming ingestion, model serving, and monitoring.",
                "technologies": [
                    "Python",
                    "Spark Structured Streaming",
                    "Kafka",
                    "Airflow",
                    "Docker",
                    "AWS Lambda"
                ],
                "year": 2023
            },
            {
                "name": "Clinical Risk Stratification Dashboard",
                "description": "Risk models for predicting 30-day readmission and high-utilization patients with explainability layers for clinicians and integration into EHR workflows.",
                "technologies": [
                    "XGBoost",
                    "scikit-learn",
                    "SHAP",
                    "BigQuery",
                    "Looker"
                ],
                "year": 2021
            },
            {
                "name": "Customer Segmentation Platform",
                "description": "Pipeline to generate behavioral segments using clustering, PCA, and automated feature pipelines for downstream marketing experiments.",
                "technologies": [
                    "pandas",
                    "scikit-learn",
                    "DBT",
                    "Postgres",
                    "Tableau"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "pandas",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "TensorFlow",
            "PyTorch",
            "Spark",
            "Airflow",
            "BigQuery",
            "AWS (S3, SageMaker)",
            "GCP",
            "Docker",
            "Kubernetes",
            "Model Monitoring",
            "A/B Testing",
            "Data Visualization (Looker, Tableau)",
            "Feature Engineering",
            "Experiment Design"
        ],
        "achievements": [
            "Delivered a churn model that enabled a 10% lift in retention for targeted cohorts, contributing directly to a $1.2M annual revenue improvement.",
            "Implemented model monitoring and automated retraining pipelines that reduced production incidents by 75%.",
            "Presented a poster on interpretable clinical models at a regional health-data conference (2021).",
            "Mentored and helped onboard 3 junior data scientists, establishing shared best practices and code templates."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 6,
        "availability": true
    },
    {
        "name": "Aisha Khan",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, cross-functional teams that value experimentation, mentorship, and clear product impact.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Cambridge, MA (willing to relocate within US)"
            },
            "phone": "+1-617-555-0143",
            "email": "aisha.khan32@example.com",
            "linkedin": "https://www.linkedin.com/in/aisha-khan32",
            "github": "https://github.com/aishak32"
        },
        "summary": "Data Scientist with 8+ years of experience building production ML systems and analytics solutions in healthcare and SaaS. Strong background in predictive modeling, time-series forecasting, causal inference, and MLOps. Proven track record delivering measurable product and business impact through data-driven experimentation and cross-functional partnerships.",
        "experience": [
            {
                "name": "Senior Data Scientist, Beacon Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development and deployment of a hospital readmission risk model using XGBoost and SHAP for explainability; integrated into EHR workflows to prioritize interventions, reducing 30-day readmission risk by 12%.",
                    "Designed and productionized ML pipelines with Airflow, Docker, and AWS SageMaker, cutting model retraining cycle from weeks to days.",
                    "Partnered with clinicians, product managers, and engineers to scope features and run sequential randomized trials; demonstrated 8% uplift in care intervention acceptance.",
                    "Mentored a team of 4 junior data scientists and established best practices for model validation, monitoring, and CI/CD."
                ]
            },
            {
                "name": "Data Scientist, Luma Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built customer lifetime value (LTV) and churn prediction models using survival analysis and gradient-boosted trees; enabled targeted retention campaigns that improved 6-month retention by 9%.",
                    "Implemented a real-time pricing optimization prototype combining contextual bandits and demand forecasting; increased average order value by 4%.",
                    "Established A/B testing framework and led experiment design for product features; trained product teams on statistical power and interpretation.",
                    "Worked with engineering to migrate batch scoring to Kafka streaming, reducing prediction latency from minutes to <200ms."
                ]
            },
            {
                "name": "Data Analyst, Metro Telecom",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed automated SQL reporting and KPI dashboards in Tableau to surface network performance and customer trends for stakeholders across ops and finance.",
                    "Performed root-cause analyses for customer outages using time-series decomposition and anomaly detection, reducing mean time-to-resolution by 18%.",
                    "Created feature engineering pipelines in Python and Spark for downstream predictive models; standardized data quality checks and documentation."
                ]
            }
        ],
        "projects": [
            {
                "name": "Hospital Readmission Risk Model",
                "description": "Production XGBoost model with SHAP-based explanations ingested into clinician workflow to prioritize post-discharge interventions.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "SHAP",
                    "AWS SageMaker",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Anomaly Detection for Network Metrics",
                "description": "Streaming anomaly detection pipeline using seasonal decomposition and online isolation forest to detect and alert on network degradations.",
                "technologies": [
                    "Kafka",
                    "Spark Streaming",
                    "scikit-learn",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Pricing Optimization Engine (Prototype)",
                "description": "Contextual bandit-based prototype integrated with demand forecasts to recommend personalized prices and promotions.",
                "technologies": [
                    "TensorFlow",
                    "Contextual Bandits",
                    "Postgres",
                    "Tableau"
                ],
                "year": 2019
            },
            {
                "name": "Customer Churn Dashboard",
                "description": "Interactive dashboard combining predictive churn scores, cohort analyses, and simulated impact of interventions for product stakeholders.",
                "technologies": [
                    "Tableau",
                    "Python",
                    "Pandas",
                    "SQL"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "Northeastern University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Toronto",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "Time-series forecasting",
            "Causal inference",
            "Experiment design / A/B testing",
            "Feature engineering",
            "MLOps (Airflow, Docker, SageMaker)",
            "Spark",
            "Kafka",
            "Tableau",
            "Pandas",
            "NumPy",
            "Model monitoring & explainability (SHAP)"
        ],
        "achievements": [
            "Deployed production ML systems serving 1M+ predictions per month with automated retraining and monitoring.",
            "Mentored and grew a team of 4 junior data scientists; established code review and model governance practices.",
            "Reduced model inference latency by 60% through streaming architecture and model optimizations.",
            "Authored internal playbook on experiment design adopted across product teams."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2021
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya R. Singh",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, fast-paced, data-driven environment with strong emphasis on reproducibility, mentorship, and cross-functional impact.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "94107"
            },
            "phone": "+1-415-555-2134",
            "email": "maya.singh@example.com",
            "linkedin": "https://www.linkedin.com/in/mayarisingh",
            "github": "https://github.com/mayarisingh"
        },
        "summary": "AI Engineer with 9+ years designing, building, and deploying production ML systems. Strong track record delivering end-to-end solutions (data pipelines, model training, deployment, monitoring) that improved product metrics and reduced latency. Comfortable leading cross-functional teams, implementing MLOps best practices, and optimizing models for scale.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 Aurelia Labs (product analytics / recommendations)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a hybrid deep-learning recommendation system (PyTorch) serving personalized content to 18M monthly users; increased click-through-rate by 12% and daily engagement by 9%.",
                    "Built scalable inference pipeline using Kubernetes, FastAPI, Redis caching, and gRPC to achieve 50ms median inference latency at peak traffic.",
                    "Implemented model CI/CD using GitHub Actions, MLflow, and Canary deployments; reduced time-to-production for models from weeks to days.",
                    "Introduced model monitoring (Prometheus + Grafana + custom drift detectors) and automated retraining triggers, lowering model degradation incidents by 80%."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 OptiScale (cloud optimization)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed time-series forecasting models and probabilistic demand estimators that reduced cloud waste by 18% across enterprise accounts.",
                    "Designed feature-store-backed ETL (Airflow + Spark) for consistent feature generation; improved training reproducibility and reduced feature-related bugs by 60%.",
                    "Optimized large models with quantization and distillation for edge deployments, cutting model size by 6x with <2% performance loss.",
                    "Collaborated with product and SRE teams to architect a multi-tenant inference platform with autoscaling and adaptive batching."
                ]
            },
            {
                "name": "Data Scientist \u2014 InMotion Health (digital therapeutics)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built predictive models for patient adherence and risk stratification that enabled targeted interventions and improved 30-day retention by 7%.",
                    "Conducted A/B tests and causal analyses to quantify product changes, defining experiment metrics and sample sizing.",
                    "Automated reporting dashboards (Looker) and ETL processes, reducing manual reporting time by 40%."
                ]
            },
            {
                "name": "Data Engineering Intern \u2014 Streamline Analytics",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Implemented data ingestion pipelines (Kafka -> HDFS) and lightweight transformation jobs to centralize event logs for analytics.",
                    "Collaborated with senior engineers to profile data quality and establish logging standards adopted company-wide."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Fraud Detection Engine",
                "description": "End-to-end streaming fraud detection system combining feature enrichment, LightGBM and PyTorch ensemble models, and real-time scoring with Kafka + Spark Structured Streaming. Deployed as a low-latency service with adaptive thresholds.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "PyTorch",
                    "LightGBM",
                    "Docker",
                    "Kubernetes",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "Personalized Content Recommender",
                "description": "Hybrid collaborative + content-based recommender using embeddings and session-aware transformers to surface personalized content. Focused on cold-start handling and online A/B validation.",
                "technologies": [
                    "PyTorch",
                    "TensorFlow",
                    "Redis",
                    "FastAPI",
                    "MLflow"
                ],
                "year": 2020
            },
            {
                "name": "Automated ML Pipeline (AutoML for Tabular)",
                "description": "Reusable AutoML pipeline for tabular data that handled feature engineering, model selection, hyperparameter tuning and deployment. Integrated with CI for scheduled retraining.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "Optuna",
                    "Airflow",
                    "Docker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of Michigan",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "LightGBM",
            "XGBoost",
            "Spark",
            "Kafka",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, EC2, Lambda)",
            "GCP",
            "SQL",
            "NoSQL",
            "Model monitoring",
            "MLOps",
            "CI/CD"
        ],
        "achievements": [
            "Scaled a recommendation system to 18M monthly users while improving CTR by 12% (Aurelia Labs).",
            "Reduced cloud cost waste by 18% through demand forecasting models (OptiScale).",
            "Presented work on model deployment and monitoring at a regional ML meetup (2022).",
            "Mentored 6 junior engineers and interns; two promoted to mid-level roles within a year."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Databricks Certified Data Engineer Associate",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Ethan Park",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented teams that prioritize strong engineering practices (code review, testing), reproducible research, and clear product impact. Values mentorship, cross-functional ownership, and data-informed decisions.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "1234 Market St, Apt 501"
            },
            "phone": "+1-415-555-0143",
            "email": "ethan.park34@example.com",
            "linkedin": "https://www.linkedin.com/in/ethan-park-ai",
            "github": "https://github.com/ethanpark34"
        },
        "summary": "AI Engineer with 8+ years delivering production ML systems and end-to-end ML platforms. Experienced in model development, MLOps, and scaling deep learning for recommendation, NLP, and time-series applications. Strong background in software engineering, cloud infrastructure, and leading cross-functional projects from research prototypes to serving at scale.",
        "experience": [
            {
                "name": "Quantica Labs \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time recommendation pipeline using transformer-based models, increasing click-through rate by 12% while reducing 95th-percentile inference latency by 40% via model distillation and optimized batching.",
                    "Built scalable inference stack on Kubernetes with KFServing and custom autoscaling policies; reduced serving costs by 30% through dynamic batching and mixed-precision inference.",
                    "Implemented CI/CD for ML (GitHub Actions + Terraform + ArgoCD), enabling safe canary rollouts and automated rollback for model releases.",
                    "Mentored a team of 4 engineers and established code-review and model validation standards that reduced model-regression incidents by 50%."
                ]
            },
            {
                "name": "NeuroScale \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed a hybrid CNN-RNN architecture for time-series anomaly detection used in monitoring pipelines, improving early anomaly detection F1 by 18%.",
                    "Created a feature-store-backed training pipeline (Spark + Parquet + Feast) to ensure feature parity between training and serving environments.",
                    "Collaborated with product and data teams to translate business requirements into ML metrics and SLAs; led A/B tests and statistical analyses for model evaluation.",
                    "Authored internal tooling for model explainability (SHAP-based dashboards) used by support and product teams to reduce investigation time by 25%."
                ]
            },
            {
                "name": "CloudScale Inc. \u2014 ML Engineer",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Implemented end-to-end supervised learning pipelines for customer churn prediction; model uplift resulted in a targeted retention campaign with a 9% lift in retention.",
                    "Optimized feature engineering workflows using Airflow and Spark, cutting model training time by 60% through better partitioning and incremental joins.",
                    "Packaged models as microservices (Docker, Flask) and instrumented monitoring (Prometheus + Grafana) for model performance and data drift detection."
                ]
            },
            {
                "name": "University Research Lab \u2014 Research Intern",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Researched representation learning techniques for low-resource speech recognition; contributed code and results to a published workshop paper.",
                    "Prototyped data augmentation strategies and evaluated robustness across noisy datasets."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeML Inference Pipeline",
                "description": "Designed and implemented an optimized inference pipeline for on-device deployment of distilled vision and speech models, including quantization-aware training and a lightweight runtime for ARM devices.",
                "technologies": [
                    "TensorFlow Lite",
                    "PyTorch",
                    "ONNX",
                    "C++",
                    "Edge TPU"
                ],
                "year": 2023
            },
            {
                "name": "Customer Churn Predictor",
                "description": "End-to-end churn prediction system with feature store integration, automated retraining, and explainability dashboards used by retention teams.",
                "technologies": [
                    "Spark",
                    "Feast",
                    "Scikit-learn",
                    "MLflow",
                    "AWS (S3, SageMaker)"
                ],
                "year": 2020
            },
            {
                "name": "Contrastive Audio Embeddings",
                "description": "Research and production pipeline for learning robust audio embeddings using contrastive loss; improved search and retrieval relevance for a voice search product.",
                "technologies": [
                    "PyTorch",
                    "Librosa",
                    "Faiss",
                    "Kubernetes"
                ],
                "year": 2019
            },
            {
                "name": "AutoML Hyperparameter Tuner",
                "description": "Built a distributed hyperparameter tuning service leveraging population-based training and Bayesian optimization to accelerate model selection and improve final model accuracy.",
                "technologies": [
                    "Ray Tune",
                    "Docker",
                    "GCP",
                    "Keras"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science (Machine Learning)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. Electrical Engineering & Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "MLOps",
            "Kubernetes",
            "Docker",
            "AWS",
            "GCP",
            "Spark",
            "Feast",
            "MLflow",
            "ONNX",
            "SQL",
            "Scikit-learn",
            "Model Compression",
            "Distributed Training",
            "Monitoring & Observability"
        ],
        "achievements": [
            "Published workshop paper on representation learning for low-resource speech (2016).",
            "Speaker at Bay Area ML Meetup on model distillation and serving (2022).",
            "Reduced production inference costs at Quantica Labs by 30% through system and model optimizations.",
            "Established company-wide ML testing and CI standards, lowering rollback incidents by 50%."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2020
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Asha Kapoor",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven, and product-minded teams that prioritize experimentation, reproducibility, and impact",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Currently based in Seattle; open to US-based hybrid roles"
            },
            "phone": "+1-206-555-0147",
            "email": "asha.kapoor@example.com",
            "linkedin": "https://www.linkedin.com/in/ashakapoor",
            "github": "https://github.com/ashakapoor"
        },
        "summary": "AI Engineer with 7+ years building production ML systems and scalable model infra. Strong background in deep learning, retrieval, and model optimization for latency-sensitive applications. Experienced in end-to-end ML lifecycle: data pipelines, model training, deployment, monitoring, and MLOps automation.",
        "experience": [
            {
                "name": "Senior AI Engineer, Sentinel Labs",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time anomaly detection pipeline for telemetry streams, achieving 3x faster detection and reducing false positives by 28% through ensemble models and streaming feature stores.",
                    "Built a horizontally scalable TensorFlow Serving + Kubernetes inference platform supporting 500+ models with automated canary rollouts, A/B testing, and rollback.",
                    "Implemented model quantization and pruning workflows that reduced CPU inference latency by 60% for edge deployments while maintaining <1.5% accuracy loss.",
                    "Collaborated with product and SRE teams to introduce monitoring (Prometheus/Grafana) and drift detection alerts, cutting incident response time by 40%."
                ]
            },
            {
                "name": "AI Engineer, Volt Analytics",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed multimodal retrieval system combining text and image embeddings using contrastive learning; improved retrieval relevance by 18% versus baseline.",
                    "Authored data augmentation and curriculum learning strategies that improved downstream classification robustness on noisy inputs.",
                    "Built model training pipelines (Airflow + Kubernetes) and integrated experiment tracking (MLflow) to standardize reproducible training across teams.",
                    "Mentored junior engineers; introduced code review patterns and unit testing for model code to reduce deployment defects."
                ]
            },
            {
                "name": "Data Scientist (Intern \u2192 Associate), EdgeHive",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Prototyped lightweight CNNs and distillation pipelines for on-device image classification; achieved 2.5x smaller models with minimal accuracy loss.",
                    "Worked on feature engineering and classical ML baselines to rapidly validate product ideas before deep learning investments.",
                    "Presented findings to stakeholders and helped translate models into product experiments that informed roadmap decisions."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Anomaly Detection",
                "description": "End-to-end streaming pipeline for anomaly detection on high-throughput telemetry. Ingested data via Kafka, computed online features, and served predictions with <200ms tail latency. Included drift detection and automated retraining triggers.",
                "technologies": [
                    "Kafka",
                    "Spark Structured Streaming",
                    "TensorFlow",
                    "Kubernetes",
                    "Prometheus",
                    "Seldon Core"
                ],
                "year": 2023
            },
            {
                "name": "Multimodal Retrieval Engine",
                "description": "Contrastive learning-based retrieval service combining image and text embeddings. Deployed approximate nearest neighbor indexing with real-time updates and performed relevance A/B tests.",
                "technologies": [
                    "PyTorch",
                    "FAISS",
                    "Hugging Face Transformers",
                    "Docker",
                    "FastAPI"
                ],
                "year": 2021
            },
            {
                "name": "Knowledge Distillation Toolkit",
                "description": "Open-source toolkit to automate teacher-student distillation workflows, including layer mapping, loss scheduling, and quantization-aware training.",
                "technologies": [
                    "TensorFlow",
                    "Keras",
                    "ONNX",
                    "NumPy"
                ],
                "year": 2020
            },
            {
                "name": "Edge-optimized Model Serving",
                "description": "Pipeline to convert trained models into optimized runtime artifacts for edge devices using pruning, quantization, and TFLite conversion, integrated with CI for automated builds.",
                "technologies": [
                    "TensorFlow Lite",
                    "TFLite Model Maker",
                    "Bazel",
                    "CI/CD"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington \u2014 M.S. Computer Science",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "Master of Science, Computer Science (Machine Learning Track)"
            },
            {
                "name": "IIT Delhi \u2014 B.Tech Computer Science",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "Bachelor of Technology, Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "MLflow",
            "Airflow",
            "Kubernetes",
            "Docker",
            "FAISS",
            "SQL",
            "Spark",
            "Distributed systems",
            "Model optimization (quantization, pruning, distillation)",
            "MLOps",
            "Experiment design",
            "Approximate Nearest Neighbor"
        ],
        "achievements": [
            "Reduced inference latency 60% for core product by implementing quantization and optimized serving.",
            "Improved retrieval relevance by 18% through a multimodal contrastive training approach.",
            "Presented work on efficient on-device models at regional ML meetup; open-sourced distillation toolkit adopted by multiple teams.",
            "Established company-wide model monitoring standards, decreasing production incidents related to model drift by 40%."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "DeepLearning.AI Natural Language Processing Specialization",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and learning-oriented \u2014 values cross-functional partnership and clear product impact.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Seattle, WA"
            },
            "phone": "+1-206-555-0143",
            "email": "maya.patel.ds@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-patel",
            "github": "https://github.com/mayarp"
        },
        "summary": "Data Scientist with 7+ years applying machine learning and statistical methods to drive product and business decisions. Experienced in end-to-end model development, production ML pipelines, experimentation, and stakeholder communication. Strong background in NLP, time series forecasting, and scalable analytics on cloud platforms.",
        "experience": [
            {
                "name": "Senior Data Scientist, Novus Analytics (Hybrid)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led model development for personalized recommendations driving a 12% increase in weekly retention and a 9% lift in ARPU through online A/B tests.",
                    "Built and productionized a real-time feature pipeline (Kafka -> Spark Structured Streaming -> BigQuery) reducing feature latency from hours to <30s.",
                    "Mentored a team of 3 junior DS/ML engineers; established code review and model validation standards that reduced incidents by 40%.",
                    "Collaborated with product and engineering to design metrics, ran experimentation analysis for 50+ tests, and communicated results to executives."
                ]
            },
            {
                "name": "Data Scientist, Helix Health Technologies (On-site)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed NLP pipelines for clinical note classification achieving 0.89 macro F1; integrated model into EHR workflow to prioritize cases.",
                    "Implemented time-series forecasting models (Prophet, LSTM) for resource planning, improving capacity utilization by 7%.",
                    "Owned ETL and analytical dashboards (Looker) for clinical operations and product teams, shortening reporting time from days to hours.",
                    "Presented results to stakeholders, translating complex model behavior and uncertainty into actionable recommendations."
                ]
            },
            {
                "name": "Data Analyst, Bluebridge Retail (On-site)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Designed and executed A/B tests for pricing and promotion strategies; contributed to a 5% uplift in seasonal campaign revenue.",
                    "Automated weekly sales and inventory reporting using SQL and Python, cutting manual preparation time by 80%.",
                    "Performed cohort analysis and customer segmentation used to tailor marketing campaigns and reduce churn."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Recommendation Engine",
                "description": "End-to-end system for streaming user signals to generate personalized item recommendations with online feature computation and model scoring.",
                "technologies": [
                    "Python",
                    "Spark Structured Streaming",
                    "Kafka",
                    "TensorFlow",
                    "Docker",
                    "BigQuery"
                ],
                "year": 2022
            },
            {
                "name": "Clinical Note Classifier",
                "description": "NLP pipeline using pre-trained transformers fine-tuned on domain data to classify clinical notes into triage categories; integrated into provider workflow.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "scikit-learn",
                    "AWS S3"
                ],
                "year": 2019
            },
            {
                "name": "Demand Forecasting Platform",
                "description": "Hybrid approach combining gradient boosted trees and LSTM ensembles for store-level demand forecasting; automated retraining and model selection.",
                "technologies": [
                    "XGBoost",
                    "Keras",
                    "Airflow",
                    "Postgres"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Deep Learning",
            "NLP",
            "Time Series Forecasting",
            "A/B Testing",
            "Spark",
            "BigQuery",
            "AWS",
            "Docker",
            "Airflow",
            "Model Monitoring",
            "Data Visualization (Looker, Tableau)"
        ],
        "achievements": [
            "Deployed recommendation model that increased weekly retention by 12% (measured via randomized experiments).",
            "Reduced feature pipeline latency from hours to under 30 seconds, enabling near real-time personalization.",
            "Published a conference poster on transformer adaptation for clinical notes (ACL Workshop, 2019)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Ravi Kapoor",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused teams that prioritize clarity, continuous learning, and measurable impact. Values code review, reproducible experiments, and cross-functional communication.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala"
            },
            "phone": "+91-98765-43210",
            "email": "ravi.kapoor37@example.com",
            "linkedin": "https://www.linkedin.com/in/ravi-kapoor-37",
            "github": "https://github.com/ravikapoor37"
        },
        "summary": "AI Engineer with 7+ years building and deploying production ML systems at scale. Strong background in deep learning, model optimization, and MLOps; experienced across cloud platforms (AWS/GCP), containerized deployment, and end-to-end ML pipelines. Focused on reducing inference latency and improving model robustness for real-time applications.",
        "experience": [
            {
                "name": "Astra Labs \u2014 Senior AI Engineer",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time recommendation engine serving 2M+ users; reduced average inference latency from 320ms to 90ms through model distillation, pruning, and optimized ONNX runtime.",
                    "Built end-to-end CI/CD for models using Terraform, Docker, Kubernetes, and GitOps; cut model release time from weeks to under 48 hours.",
                    "Implemented monitoring and drift-detection pipelines (Prometheus + Kafka + Airflow) enabling automated rollback for degraded models, decreasing post-deploy incidents by 75%.",
                    "Mentored a team of 4 ML engineers on production best practices, code review, and performance profiling."
                ]
            },
            {
                "name": "OptiHealth \u2014 Data Scientist",
                "date": {
                    "start": 2017,
                    "end": 2020
                },
                "bullets": [
                    "Developed predictive models for patient readmission risk using gradient-boosted trees and deep survival models; improved early-identification recall by 18%, contributing to targeted intervention programs.",
                    "Deployed transfer-learning based imaging pipeline (PyTorch) for diagnostic assistance, achieving AUC 0.92 on holdout test sets and reducing manual review workload by 35%.",
                    "Partnered with product and clinical teams to translate model outputs into interpretable dashboards and decision support tools."
                ]
            },
            {
                "name": "Freelance \u2014 ML Engineer / Consultant",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Delivered end-to-end ML solutions for startups, including fraud-detection classifier and demand-forecasting models; responsibilities spanned data pipeline design, feature engineering, and containerized deployment.",
                    "Authored reproducible experiment templates (DVC + MLflow) adopted by clients to standardize model tracking and versioning."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Recommendation Engine",
                "description": "Hybrid candidate retrieval + re-ranking system combining approximate nearest neighbors (FAISS) with a light-weight neural re-ranker. Focused on latency optimization, A/B testing, and scalable feature stores.",
                "technologies": [
                    "PyTorch",
                    "FAISS",
                    "Redis",
                    "Kubernetes",
                    "AWS Lambda"
                ],
                "year": 2022
            },
            {
                "name": "Anomaly Detection for Streaming Metrics",
                "description": "Streaming anomaly detection service using LSTM-autoencoders and statistical detectors; integrated with Kafka and Prometheus to surface incidents and trigger automated remediation.",
                "technologies": [
                    "TensorFlow",
                    "Kafka",
                    "Prometheus",
                    "Airflow"
                ],
                "year": 2021
            },
            {
                "name": "fast-bert-serving (open-source)",
                "description": "Created an optimized inference wrapper for BERT models enabling sub-100ms batch-inference for common sentence-pair tasks via ONNX export and quantization strategies.",
                "technologies": [
                    "ONNX",
                    "PyTorch",
                    "Quantization",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Kaggle \u2014 Retail Demand Forecasting (Top 1%)",
                "description": "Applied feature engineering, hierarchical time-series models, and blending of XGBoost and LSTM models to achieve top 1% leaderboard rank.",
                "technologies": [
                    "XGBoost",
                    "Keras",
                    "Pandas",
                    "LightGBM"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "University of California, San Diego \u2014 M.S. Computer Science (Machine Learning)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "Master of Science"
            },
            {
                "name": "University of Delhi \u2014 B.Tech. Computer Science",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "Bachelor of Technology"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "ONNX",
            "Scikit-learn",
            "FAISS",
            "Kubernetes",
            "Docker",
            "Airflow",
            "AWS (S3, SageMaker, EKS)",
            "GCP",
            "SQL",
            "MLflow",
            "DVC",
            "Model Optimization (quantization, pruning, distillation)"
        ],
        "achievements": [
            "Reduced production inference latency 3.5x for recommendation pipeline while maintaining >98% of base model accuracy.",
            "Decreased post-deploy model incidents by 75% through automated monitoring and rollback processes.",
            "Top 1% on a global Kaggle forecasting competition (2018).",
            "Authored an open-source inference wrapper adopted by multiple small teams to speed BERT serving."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2020
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya Chen",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that prioritize cross-functional ownership, continuous learning, and pragmatic experimentation.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-4823",
            "email": "maya.chen.ds@example.com",
            "linkedin": "https://www.linkedin.com/in/mayachen-ds",
            "github": "https://github.com/mayachen-ds"
        },
        "summary": "Data scientist with 6+ years of experience building production ML systems and analytics platforms. Strong background in applied machine learning, experimental design, feature engineering, and scalable data pipelines. Proven track record delivering revenue-impacting models and dashboards for product and growth teams.",
        "experience": [
            {
                "name": "Senior Data Scientist, Recommendation Systems \u2014 Veridian Commerce",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a personalized recommendation pipeline (content + collaborative filtering hybrid) that increased click-through rate by 18% and incremental revenue by 9% over 6 months.",
                    "Designed offline A/B testing framework and observed-signals pipeline to accelerate experiment iteration time by 40%; implemented pragmatic bucketing and instrumentation for multi-arm experiments.",
                    "Built feature store components (Redis + Parquet-based batch store) enabling consistent features across training and serving; reduced training-serving skew incidents by 70%.",
                    "Mentored 3 junior data scientists and coordinated cross-functional work with engineering and product to prioritize model improvements and monitoring."
                ]
            },
            {
                "name": "Data Scientist \u2014 Growth & Retention, Lumina Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed user lifetime value (LTV) and churn models using survival analysis and gradient boosted trees; informed pricing and acquisition spend, increasing ROI on paid channels by 24%.",
                    "Automated ETL pipelines in Airflow to aggregate event data from multiple sources into a unified analytics table, reducing manual reporting time by 60%.",
                    "Partnered with product managers to design propensity modeling experiments; deployed propensity-based nudges that improved 30-day retention by 7 percentage points.",
                    "Implemented model monitoring dashboards (prometheus + Grafana) for data drift and population shift alerts, establishing SLAs for retraining."
                ]
            },
            {
                "name": "Data Analyst \u2014 Business Intelligence, Nova Retail",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built interactive dashboards (Tableau) and SQL-based ETL to support merchandising and pricing decisions across 200+ SKUs.",
                    "Performed cohort analysis and funnel diagnostics that identified a checkout friction point; collaborated with UX to reduce checkout abandonment by 12%.",
                    "Introduced statistical process for identifying significant metric changes, reducing false positive alerts by 45%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Fraud Scoring Service",
                "description": "Designed and deployed a low-latency fraud scoring microservice using streaming features and an ensemble of tree and logistic models; integrated with gateway to block high-risk transactions in <100ms.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Kafka",
                    "Docker",
                    "Redis"
                ],
                "year": 2023
            },
            {
                "name": "Customer Lifetime Value Dashboard",
                "description": "Built an end-to-end LTV pipeline (data ingestion, modeling, visualization) to segment customers and guide acquisition spend. Provided automated weekly reports and custom cohorts for marketing.",
                "technologies": [
                    "SQL",
                    "Airflow",
                    "PyMC3",
                    "Tableau",
                    "Pandas"
                ],
                "year": 2020
            },
            {
                "name": "Image-based Similarity Search",
                "description": "Implemented a deep-learning based feature extractor and approximate nearest neighbor index to enable visually similar product search; improved add-to-cart from visual search by 32%.",
                "technologies": [
                    "PyTorch",
                    "FAISS",
                    "Docker",
                    "AWS S3"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "Master of Science in Data Science"
            },
            {
                "name": "University of California, San Diego \u2014 B.S. Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "Bachelor of Science in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "XGBoost",
            "PyTorch",
            "Experimentation / A/B testing",
            "Feature engineering",
            "Data pipelines (Airflow, Kafka)",
            "Model monitoring",
            "Tableau / Looker",
            "Cloud (AWS)"
        ],
        "achievements": [
            "Delivered recommendation system that increased platform revenue by 9% within first 6 months of production.",
            "Reduced experiment iteration time by 40% by developing reusable offline evaluation tooling.",
            "Published internal technical playbook on feature store design adopted across two business units."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "AWS Certified Data Analytics \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Professional Certificate in Applied Data Science (Coursera)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Asha R. Mehta",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth mindset; values cross-functional communication and experiment-driven decisions",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "123 Market St, Apt 45"
            },
            "phone": "+1-415-555-7823",
            "email": "asha.mehta@example.com",
            "linkedin": "https://www.linkedin.com/in/asharmehta",
            "github": "https://github.com/ashamehta"
        },
        "summary": "Data Scientist with 7+ years building production ML systems and analytics platforms in healthcare and fintech. Experienced in end-to-end model development, causal inference, A/B testing, and deploying scalable pipelines. Strong background in Python, ML engineering, and communicating insights to stakeholders to drive product impact.",
        "experience": [
            {
                "name": "Senior Data Scientist, NovaHealth",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a patient-readmission risk model that reduced 30-day readmissions by 12% and saved an estimated $2.1M annually.",
                    "Built end-to-end ML pipelines (data ingestion \u2192 feature store \u2192 model training \u2192 model serving) using Airflow, Feast, and KFServing; reduced model retraining time from days to hours.",
                    "Partnered with clinicians and product managers to translate business needs into measurable ML experiments; ran 8 A/B tests, 6 of which showed statistically significant improvement in clinical outcomes.",
                    "Implemented explainability tooling (SHAP) for production models and created dashboards that improved clinician trust and model adoption."
                ]
            },
            {
                "name": "Data Scientist, ClearLedger (Fintech)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed credit-risk scoring models using tree ensembles and gradient boosting that decreased default rates by 18% for targeted cohorts.",
                    "Designed a feature engineering framework and automated feature validation, reducing manual feature engineering effort by 40%.",
                    "Collaborated with engineering to productionize fraud detection pipeline using Kafka and Spark Streaming, achieving <200ms inference latency and blocking $3.2M in fraudulent transactions annually.",
                    "Coached junior data scientists and ran monthly brown-bag sessions on MLOps best practices."
                ]
            },
            {
                "name": "Data Analyst, BrightMetrics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Performed cohort analysis and built dashboards (Looker, Tableau) to guide retention strategies that increased 90-day user retention by 9%.",
                    "Implemented SQL-driven ETL processes and standardized reporting templates, reducing reporting cycle time by 60%.",
                    "Supported product A/B testing and designed experiment metrics and analysis plans."
                ]
            }
        ],
        "projects": [
            {
                "name": "Personalized Care Recommendation Engine",
                "description": "Developed a recommendation pipeline that suggests personalized care plans using patient history, social determinants, and clustering to improve adherence. Integrated with EHR and generated clinician-facing explanations.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Docker",
                    "PostgreSQL",
                    "SHAP"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Fraud Detection Stream",
                "description": "Built a low-latency fraud detection system processing transactions in real-time with feature enrichment and model scoring, deployed to production using Kafka and Spark Streaming.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "Python",
                    "TensorFlow",
                    "AWS"
                ],
                "year": 2020
            },
            {
                "name": "Automated Feature Store",
                "description": "Designed and implemented a Feature Store for shared, validated features across ML teams, supporting reproducible training and online serving.",
                "technologies": [
                    "Feast",
                    "Airflow",
                    "Kubernetes",
                    "BigQuery"
                ],
                "year": 2022
            },
            {
                "name": "Causal Analysis of Outreach Programs",
                "description": "Led causal inference study using propensity score matching and uplift modeling to evaluate outreach program effectiveness, influencing reallocation of marketing spend.",
                "technologies": [
                    "R",
                    "Python",
                    "CausalImpact",
                    "Pandas"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. Computer Science (Machine Learning)"
            },
            {
                "name": "University of Pune",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.Sc. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "Spark",
            "Airflow",
            "Feast",
            "Docker",
            "Kubernetes",
            "A/B testing",
            "Causal inference",
            "Model interpretability",
            "Data visualization (Looker, Tableau)"
        ],
        "achievements": [
            "Reduced patient 30-day readmissions by 12% through predictive modelling and care-path optimization.",
            "Blocked $3.2M in fraudulent transactions annually by productionizing real-time detection.",
            "Authored internal MLOps best-practices guide adopted across the data org."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya Thompson",
        "title": "Data Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and impact-focused. Values mentorship, cross-functional partnership, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0198",
            "email": "maya.thompson@example.com",
            "linkedin": "https://linkedin.com/in/mayathompson",
            "github": "https://github.com/mayathompson"
        },
        "summary": "Data engineer with 9+ years building scalable data platforms and production ML pipelines. Experienced in distributed systems (Spark, Kafka), modern data warehouses (Snowflake, Redshift), cloud infrastructure (AWS, GCP), and MLOps practices to accelerate model delivery and monitoring. Focused on transforming analytics into reliable production data products that drive business outcomes.",
        "experience": [
            {
                "name": "Senior Data Engineer \u2014 Nimbus Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Designed and led migration of legacy ETL to Spark-on-Kubernetes and Airflow, reducing pipeline runtime by 65% and operational costs by 30%.",
                    "Built event-driven ingestion using Kafka and AWS Kinesis to support near-real-time analytics for customer-facing dashboards.",
                    "Implemented a feature store (Feast) integrated with S3 and Snowflake to standardize features for ML teams, reducing model training time by 40%.",
                    "Developed CI/CD for data pipelines with Terraform, GitHub Actions, and automated end-to-end tests; decreased deployment incidents by 70%.",
                    "Instrumented monitoring and alerting (Prometheus, Grafana, Datadog) for data SLAs and pipeline health."
                ]
            },
            {
                "name": "Data Scientist \u2014 BrightWave Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built and productionized patient risk scoring models (XGBoost, LightGBM) running on AWS SageMaker; improved early-detection recall by 18%.",
                    "Collaborated with engineering to convert notebooks into reproducible pipelines using Docker, Airflow, and S3-backed artifacts.",
                    "Led A/B testing and experiment analysis for clinical decision support features; provided statistical analysis and instrumentation guidance.",
                    "Optimized SQL and Spark queries, enabling daily aggregate jobs to scale to 10x data volumes with minimal performance impact."
                ]
            },
            {
                "name": "ML Engineer \u2014 OpenArc Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed end-to-end deep learning prototypes (TensorFlow, Keras) for computer vision and NLP use cases; deployed model APIs with TensorFlow Serving.",
                    "Implemented model versioning and simple model registry patterns to track experiments and deployments.",
                    "Worked with product teams to translate research prototypes into maintainable services and instrumented performance monitoring."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Pricing Engine",
                "description": "Designed a real-time pricing pipeline to compute dynamic prices using streaming features and models. Ingested clickstream and transaction streams, computed features in stream, and served scores to online systems with sub-second latency.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "Redis",
                    "AWS",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2024
            },
            {
                "name": "Snowflake Warehouse Modernization",
                "description": "Led migration from on-premise Hadoop to Snowflake. Rewrote batch ETL to use Snowpipe and dbt for transformations, implemented role-based access and cost controls.",
                "technologies": [
                    "Snowflake",
                    "dbt",
                    "Airflow",
                    "Terraform",
                    "Python"
                ],
                "year": 2022
            },
            {
                "name": "Feature Store & MLOps Automation",
                "description": "Built an internal feature store and standardized model CI/CD to automate training, validation, and deployment with canary rollouts and monitoring.",
                "technologies": [
                    "Feast",
                    "SageMaker",
                    "GitHub Actions",
                    "Prometheus",
                    "Grafana"
                ],
                "year": 2021
            },
            {
                "name": "Clinical Risk Prediction Prototype",
                "description": "Prototype for early patient risk detection using EHR data; included feature engineering pipelines, interpretable model outputs, and dashboarding for clinicians.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Pandas",
                    "Tableau"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Master of Science, Data Science \u2014 University of Washington",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "Bachelor of Science, Computer Science \u2014 University of California, Berkeley",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Apache Spark",
            "Kafka",
            "Airflow",
            "Snowflake",
            "dbt",
            "AWS (S3, EMR, Lambda, SageMaker)",
            "GCP",
            "Kubernetes",
            "Docker",
            "Terraform",
            "MLflow",
            "Feast",
            "TensorFlow",
            "PyTorch",
            "Data Modeling",
            "ETL/ELT",
            "Monitoring & Observability"
        ],
        "achievements": [
            "Reduced ETL pipeline runtime by 65% and cut operational costs by 30% during a multi-stage migration to Spark-on-Kubernetes.",
            "Delivered a feature store and CI/CD workflow that accelerated ML model release cadence by 3x.",
            "Improved patient risk model recall by 18% through feature redesign and model optimization, leading to better clinical outcomes.",
            "Published internal playbook for productionizing ML that became standard onboarding material for new ML engineers."
        ],
        "certifications": [
            {
                "name": "Databricks Certified Professional Data Engineer",
                "date": 2023
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, inclusive, impact-driven team that values experimentation, clear metrics, and mentorship.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Somerville-based; authorized to work in the U.S."
            },
            "phone": "+1-617-555-0141",
            "email": "aisha.rahman@gmail.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisha-rahman"
        },
        "summary": "Data scientist with 7+ years building production ML systems and analytics pipelines for healthcare and fintech. Strong background in supervised learning, causal A/B testing, feature engineering, and MLOps. Experienced delivering measurable product impact by translating business problems into robust data solutions and production models.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 EchoHealth (digital health startup)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a 30-day hospital readmission risk model used in clinician workflows; improved early identification recall by 22% and reduced avoidable readmissions by an estimated 7% in pilot hospitals.",
                    "Designed and executed A/B tests for care-team interventions; established standardized metric definitions and experiment pipelines, accelerating decision cycles from weeks to days.",
                    "Built automated ML pipelines (Airflow, Snowflake, dbt) to refresh features and models daily; reduced model retrain-to-deploy time from 3 weeks to 48 hours.",
                    "Mentored 4 junior data scientists and collaborated with product and clinical teams to prioritize metrics and model interpretability requirements."
                ]
            },
            {
                "name": "Data Scientist \u2014 FinAssist (payments & lending)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed credit scoring and fraud-detection models (XGBoost, LightGBM) that increased approval precision and decreased chargeback loss by 12% year-over-year.",
                    "Implemented real-time scoring service using TensorFlow Serving and a lightweight gRPC API; integrated model into production payment flow with sub-100ms latency SLA.",
                    "Performed cohort and retention analyses to inform pricing strategies; work contributed to a 9% lift in monthly active users for targeted segments.",
                    "Created feature store patterns and automated feature validation tests to catch data drift before model degradation."
                ]
            },
            {
                "name": "Data Analyst \u2014 RetailCo (national retail chain)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built SQL-based ETL and reporting pipelines consolidating POS, CRM, and web analytics for executive dashboards used in merchandising decisions.",
                    "Performed RFM and cohort analyses that identified high-value customer segments, informing targeted promotions that improved repeat purchase rate by 6%.",
                    "Automated weekly KPI reports and anomaly detection alerts, reducing manual reporting time by 60%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Deterioration Early Warning System",
                "description": "Prototype and productionized predictive model that aggregates vitals, labs, and notes embeddings to provide 6\u201312 hour early warnings for patient deterioration. Focused on interpretability and clinician feedback loop.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "PyTorch",
                    "spaCy",
                    "Airflow",
                    "Snowflake"
                ],
                "year": 2024
            },
            {
                "name": "Real-time Credit Risk Scoring",
                "description": "End-to-end system for online credit scoring with feature pipelines, online model serving, and monitoring dashboards. Reduced decision latency and enabled dynamic pricing.",
                "technologies": [
                    "TensorFlow",
                    "gRPC",
                    "Kubernetes",
                    "Redis",
                    "BigQuery"
                ],
                "year": 2020
            },
            {
                "name": "Customer Churn Prediction & Retention Playbook",
                "description": "Combined survival analysis and gradient-boosted models to predict churn risk and recommend personalized retention offers; integrated into marketing automation.",
                "technologies": [
                    "XGBoost",
                    "Python",
                    "SQL",
                    "Looker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Northeastern University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "Feature engineering",
            "A/B testing & causal inference",
            "Airflow",
            "dbt",
            "Snowflake",
            "Kubernetes",
            "Model monitoring"
        ],
        "achievements": [
            "Published internal whitepaper on model monitoring and drift detection adopted company-wide at EchoHealth.",
            "Speaker: \"Operationalizing Clinical ML\" \u2014 Health AI Summit 2023.",
            "Mentored 5 interns and junior hires; two promoted to intermediate data scientist roles within 18 months."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2022
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth mindset with emphasis on cross-functional communication and mentorship.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Based in Cambridge; open to US relocation"
            },
            "phone": "+1 (617) 555-0123",
            "email": "aisha.rahman42@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman42",
            "github": "https://github.com/aishar42"
        },
        "summary": "Data Scientist with 10+ years of experience building production ML systems for healthcare and fintech. Strong background in statistical modeling, ML engineering, and end-to-end deployment. Proven track record delivering actionable insights, improving model performance, and partnering with product and engineering teams to ship scalable solutions.",
        "experience": [
            {
                "name": "Senior Data Scientist, Beacon Health Analytics",
                "date": {
                    "start": 2019,
                    "end": null
                },
                "bullets": [
                    "Led development and productionization of a patient risk stratification model that reduced 30-day readmission rates by 14% and saved an estimated $2.1M annually.",
                    "Designed and maintained scalable feature pipelines using Airflow, dbt and Spark enabling daily model retraining across 1M+ patient records.",
                    "Built interpretable models (GBM + SHAP) to provide clinicians with clear action items, increasing clinician adoption of AI recommendations by 40%.",
                    "Established MLOps best practices (CI/CD for models, model monitoring, automated drift detection) reducing model rollback incidents by 80%.",
                    "Mentored a team of 4 data scientists and collaborated with engineering to migrate services to Kubernetes and AWS EKS."
                ]
            },
            {
                "name": "Data Scientist, Skyline AI Solutions",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Developed credit risk scoring models using ensemble methods and neural networks, improving default prediction AUC from 0.72 to 0.84.",
                    "Led A/B testing and causal analysis to measure product experiments; recommended feature changes that increased conversion by 9%.",
                    "Implemented feature stores and feature versioning to accelerate experimentation and ensure reproducibility.",
                    "Collaborated with product and compliance teams to ensure models met regulatory requirements and auditability standards."
                ]
            },
            {
                "name": "Machine Learning Engineer, OpenMentor Labs",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "bullets": [
                    "Built NLP pipelines for resume parsing and candidate matching using spaCy and gensim, increasing match precision by 35%.",
                    "Deployed RESTful model services with Docker and Flask, enabling integration with partner platforms.",
                    "Automated ETL processes and improved data quality checks, reducing data-related incidents by 60%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Sepsis Early Warning System",
                "description": "End-to-end pipeline detecting early signs of sepsis in ICU patients using time-series modeling and streaming inference; delivered alerts to clinicians with confidence scores and explanation cards.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Kafka",
                    "Spark",
                    "Docker",
                    "AWS"
                ],
                "year": 2021
            },
            {
                "name": "Personalized Loan Recommendation Engine",
                "description": "Hybrid collaborative + content-based recommender providing personalized loan offers; optimized for both conversion and risk exposure.",
                "technologies": [
                    "XGBoost",
                    "LightGBM",
                    "scikit-learn",
                    "PostgreSQL",
                    "dbt"
                ],
                "year": 2018
            },
            {
                "name": "Clinical Explainability Dashboard",
                "description": "Interactive dashboard integrating model explanations (SHAP), cohort performance, and monitoring metrics to support clinician review and model governance.",
                "technologies": [
                    "React",
                    "Flask",
                    "SHAP",
                    "Grafana"
                ],
                "year": 2022
            },
            {
                "name": "Resume Parsing and Candidate Matching API",
                "description": "NLP service that extracted structured entities from resumes and ranked candidates for roles; exposed as a scalable API for HR platforms.",
                "technologies": [
                    "spaCy",
                    "Docker",
                    "AWS Lambda",
                    "Elasticsearch"
                ],
                "year": 2015
            }
        ],
        "education": [
            {
                "name": "Massachusetts Institute of Technology (MIT)",
                "date": {
                    "start": 2012,
                    "end": 2014
                },
                "degree": "MEng, Electrical Engineering & Computer Science"
            },
            {
                "name": "University of Toronto",
                "date": {
                    "start": 2008,
                    "end": 2012
                },
                "degree": "BSc, Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "dbt",
            "Feature Engineering",
            "Model Interpretability",
            "A/B Testing",
            "Time Series Modeling",
            "NLP"
        ],
        "achievements": [
            "Reduced model inference latency by 70% through model distillation and optimized serving infrastructure.",
            "Delivered solutions that contributed to >$5M in measured business impact across roles.",
            "Published technical blog and internal playbook on model monitoring adopted company-wide.",
            "Presented sepsis early warning results at a healthcare ML symposium (2022).",
            "Built and scaled a feature store that shortened experiment cycle time by 40%."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "Certified Data Scientist (DataCamp)",
                "date": 2020
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Priya Raman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, product-focused with emphasis on reproducible ML and cross-functional communication",
        "contact": {
            "address": {
                "region": "Karnataka, India",
                "detail": "Jayanagar, Bengaluru"
            },
            "phone": "+91-9880123456",
            "email": "priya.raman@example.com",
            "linkedin": "https://www.linkedin.com/in/priyaraman",
            "github": "https://github.com/priyaraman"
        },
        "summary": "AI Engineer with 6+ years building and shipping production ML systems across healthcare and fintech domains. Strong background in deep learning, MLOps, and model optimization; experienced in end-to-end model development from research prototypes to scalable production services.",
        "experience": [
            {
                "name": "NexaHealth AI \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development of DiagNet, a multi-class medical image segmentation pipeline using U-Net variants and mixed precision training; improved Dice score by 9% and reduced inference latency by 3.8x through model pruning and TensorRT.",
                    "Designed and implemented model CI/CD with MLflow, DVC, and Kubernetes resulting in automated validation and canary rollout for models across 10+ endpoints.",
                    "Built ONNX/TensorRT-based microservices and reduced GPU cost per inference by 45% while maintaining clinical accuracy thresholds.",
                    "Mentored a team of 4 ML engineers, established code review and reproducible experiment practices, and presented quarterly production metrics to stakeholders."
                ]
            },
            {
                "name": "Quantify Labs \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Delivered SmartPredict, a probabilistic time-series forecasting system for demand planning (Prophet + LSTM hybrid), improving forecast accuracy (MAPE) by 18% over baseline.",
                    "Implemented scalable feature pipelines with Spark and Airflow processing 5TB/month; introduced feature store patterns to reduce feature leakage and accelerate model development.",
                    "Collaborated with product and engineering to deploy models as REST services using Docker and AWS ECS; set up monitoring dashboards (Prometheus + Grafana) for drift and SLOs."
                ]
            },
            {
                "name": "DataWave \u2014 ML Engineer Intern",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Prototyped customer churn classification solutions using XGBoost and LightGBM; optimized feature set and hyperparameters to increase ROC-AUC from 0.72 to 0.81.",
                    "Built data validation scripts and unit tests for preprocessing steps, reducing pipeline failures by 30% in staging."
                ]
            }
        ],
        "projects": [
            {
                "name": "DiagNet \u2014 Medical Image Segmentation",
                "description": "End-to-end segmentation system for multi-modal scans. Included preprocessing, augmentation, ensemble of U-Net models, post-processing, and production deployment with TensorRT.",
                "technologies": [
                    "PyTorch",
                    "MONAI",
                    "TensorRT",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Embeddings Search \u2014 Semantic Retrieval",
                "description": "Built a production vector-search service using sentence-transformers and FAISS for fast semantic retrieval; integrated with existing product recommendations pipeline.",
                "technologies": [
                    "PyTorch",
                    "sentence-transformers",
                    "FAISS",
                    "FastAPI"
                ],
                "year": 2022
            },
            {
                "name": "SmartPredict \u2014 Probabilistic Forecasting",
                "description": "Hybrid forecasting model combining Prophet for seasonality and LSTM for residual patterns to provide probabilistic demand forecasts with uncertainty estimates.",
                "technologies": [
                    "TensorFlow",
                    "Spark",
                    "Airflow"
                ],
                "year": 2020
            },
            {
                "name": "Customer Churn Predictor",
                "description": "Feature-engineered classification pipeline using LightGBM with SHAP explainability to identify at-risk customers and recommend retention actions.",
                "technologies": [
                    "LightGBM",
                    "scikit-learn",
                    "SHAP"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Technology Madras",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.Tech, Computer Science"
            },
            {
                "name": "Bangalore Institute of Technology",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.E., Electronics & Communication"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Apache Spark",
            "Docker",
            "Kubernetes",
            "MLflow",
            "MLOps",
            "NLP",
            "Computer Vision"
        ],
        "achievements": [
            "Published workshop paper on efficient medical image segmentation at a major ML conference (2022).",
            "Reduced production inference cost by 45% via model optimization and accelerated runtime.",
            "Improved forecasting MAPE by 18% for enterprise demand-planning product.",
            "Mentored and coached 5 junior engineers; led internal ML best-practices initiatives."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Deep Learning Specialization (Coursera)",
                "date": 2019
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2023
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, impact-driven teams that prioritize production-quality ML, strong engineering practices, and customer-focused product iterations.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "SOMA neighborhood; willing to relocate within US"
            },
            "phone": "+1-415-555-0144",
            "email": "maya.patel.ai@gmail.com",
            "linkedin": "https://www.linkedin.com/in/maya-patel-ai",
            "github": "https://github.com/mayapatel-ai"
        },
        "summary": "AI Engineer with 6+ years building and deploying production ML systems for recommendation, anomaly detection, and computer vision. Strong background in end-to-end ML lifecycle: data engineering, model development, model ops, and monitoring. Proven track record improving model performance and reducing inference cost while enabling cross-functional teams to ship features quickly.",
        "experience": [
            {
                "name": "Senior AI Engineer, Nimbus Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of a hybrid recommendation system (collaborative + content) that increased click-through rate by 18% and revenue per user by 12% across A/B tests.",
                    "Built a scalable feature-store-backed training pipeline (Airflow + Spark + Feast) that reduced model retraining time from 12 hours to 2 hours and improved feature consistency between training and serving.",
                    "Optimized model inference stack using TensorRT and model distillation, cutting per-request latency by 60% and inference cost by 45% on AWS SageMaker endpoints.",
                    "Mentored 4 ML engineers and established unit/integration testing standards for model code, improving deployment success rate and reducing rollbacks by 35%."
                ]
            },
            {
                "name": "Data Scientist, EdgeMetrics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed an anomaly detection system for IoT sensor streams using a combination of LSTM autoencoders and probabilistic thresholding, reducing false positive alerts by 30%.",
                    "Created scalable ETL pipelines (Kafka + Spark) to process ~200M daily events and join with device metadata, enabling near real-time analytics for product teams.",
                    "Collaborated with product and backend teams to A/B test personalization features; implemented logging and counterfactual analysis to attribute impact to model changes.",
                    "Authored model explainability dashboards (SHAP-based) that improved stakeholder trust and sped up model sign-off cycles."
                ]
            },
            {
                "name": "ML Intern, VisionSense",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Implemented transfer-learning pipelines for object detection (Faster R-CNN, EfficientDet) and tuned augmentation strategies, improving mean average precision by 9% on custom dataset.",
                    "Automated data labeling quality checks and reduced noisy labels by introducing programmatic checks and review prioritization heuristics."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Fraud Scoring Service",
                "description": "Designed and deployed a low-latency fraud scoring microservice combining gradient boosted trees and a lightweight neural network ensemble. Integrated feature caching and async enrichment for sub-50ms response times.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "PyTorch",
                    "Redis",
                    "Kubernetes",
                    "FastAPI"
                ],
                "year": 2024
            },
            {
                "name": "Featurization & Serving Platform (internal)",
                "description": "Built a centralized feature store and serving layer using Feast; standardized feature contracts, lineage, and monitoring, enabling multiple teams to reuse features and reducing duplicated engineering effort.",
                "technologies": [
                    "Feast",
                    "Spark",
                    "GCS",
                    "Airflow",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "On-device Model Compression Toolkit",
                "description": "Developed a toolkit for pruning and quantizing models for edge deployment. Achieved 4x model size reduction with <2% accuracy loss on key vision tasks.",
                "technologies": [
                    "TensorFlow",
                    "TensorFlow Lite",
                    "ONNX",
                    "NumPy"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Computer Science (AI)"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "XGBoost",
            "Spark",
            "SQL",
            "Kubernetes",
            "AWS (SageMaker, S3, Lambda)",
            "Feast",
            "Airflow",
            "Docker",
            "Model Monitoring",
            "MLOps",
            "REST APIs"
        ],
        "achievements": [
            "Published internal whitepaper on feature-store best practices adopted company-wide, reducing duplicated feature engineering by 40%.",
            "Speaker at ML Infra Summit 2023 on production model optimization techniques.",
            "Mentored 2 interns who continued into full-time ML roles."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2023
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2022
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Asha Kapoor",
        "title": "AI Engineer",
        "work_type": "Remote",
        "prefer_culture": "Collaborative, learning-first, impact-driven. Prefers cross-functional teams that value reproducibility, monitoring, and fast iteration.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0145",
            "email": "asha.kapoor@example.com",
            "linkedin": "https://www.linkedin.com/in/ashakapoor",
            "github": "https://github.com/ashakapoor"
        },
        "summary": "AI Engineer with 7+ years building and deploying production ML systems, specializing in deep learning, model optimization, and MLOps. Proven track record delivering end-to-end solutions (data pipelines, training, CI/CD, monitoring) that improved model throughput and business KPIs. Comfortable collaborating with product, infra, and research teams to ship reliable, interpretable models.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 VertexAI Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development and deployment of a multimodal recommendation model (text+image) serving 50M monthly active users; increased CTR by 12% and revenue per user by 8%.",
                    "Built scalable training pipelines on AWS using SageMaker, Spot instances, and S3-backed datasets, reducing training costs by ~35%.",
                    "Implemented model optimization (quantization + distillation) reducing inference latency by 4x and memory footprint by 60% for edge deployment.",
                    "Designed robust monitoring and drift-detection dashboards (Prometheus + Grafana + custom alerts) and automated retraining triggers based on data drift signals.",
                    "Mentored 4 junior engineers, introduced best practices for reproducible experiments (DVC + MLflow) and CI for model artifacts."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 Cyclone Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed and productionized NLP models for intent classification and entity extraction used in customer support automation; reduced average handle time by 25%.",
                    "Built feature engineering pipelines with Airflow and Spark, processing >1TB/week of event data with 99.9% job success rate.",
                    "Collaborated with data scientists to convert research prototypes into production-ready microservices (FastAPI + Docker + Kubernetes).",
                    "Introduced A/B testing framework for model rollouts that improved model evaluation fidelity and decreased rollback frequency."
                ]
            },
            {
                "name": "ML Research Intern \u2014 OpenVision Labs",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Researched few-shot learning approaches for visual classification and implemented prototype networks evaluated on internal datasets.",
                    "Published experimental results and contributed to open-source evaluation scripts used by the team."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Edge OCR Pipeline",
                "description": "Designed and deployed an optimized OCR pipeline for mobile devices combining a lightweight CNN text detector and an attention-based recognizer. Integrated quantized model and on-device caching to support offline inference.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TFLite",
                    "Android"
                ],
                "year": 2023
            },
            {
                "name": "Multimodal Recommendation Prototype",
                "description": "Prototyped a multimodal ranking model that fuses image embeddings with text and user signals using cross-attention layers. Validated improvement in personalization via offline and online experiments.",
                "technologies": [
                    "TensorFlow",
                    "BERT",
                    "ResNet",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "Model CI/CD Framework",
                "description": "Built a reusable CI/CD framework for models that automates training, unit tests for data/schema changes, artifact signing, and canary rollouts to production.",
                "technologies": [
                    "GitHub Actions",
                    "Docker",
                    "MLflow",
                    "Airflow"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "MS, Computer Science (Artificial Intelligence)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "BS, Electrical Engineering & Computer Science"
            }
        ],
        "skills": [
            "Deep Learning (CNNs, Transformers)",
            "NLP",
            "Multimodal Models",
            "PyTorch",
            "TensorFlow",
            "ML Ops (Airflow, MLflow, DVC)",
            "Cloud (AWS, GCP)",
            "Kubernetes & Docker",
            "Model Optimization (quantization, pruning, distillation)",
            "Data Engineering (Spark, SQL)",
            "Python"
        ],
        "achievements": [
            "Deployed production models serving 50M MAU with 99.95% uptime.",
            "Reduced model inference latency by 4x through optimization and distillation.",
            "Speaker at NeurIPS workshop on practical MLOps (2022).",
            "Authored an open-source toolkit for model benchmarking used by partner teams."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2019
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented, data-driven; emphasis on mentorship, reproducibility, and iterative experimentation.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0198",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "AI Engineer with 9+ years building and productionizing machine learning systems across healthcare, logistics, and retail. Strong background in deep learning, time-series forecasting, and MLOps \u2014 designing reproducible pipelines, optimizing inference at scale, and delivering measurable business impact.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 NovaHealth AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a deep-learning triage model for radiology images reducing specialist review workload by 42% and improving positive predictive value by 18%.",
                    "Designed end-to-end CI/CD for models using MLflow, Docker, and Kubernetes; automated testing and canary rollout reduced rollback incidents by 75%.",
                    "Built real-time inference stack (gRPC + Redis caching) achieving 60% reduction in average latency (from 250ms to 100ms) while supporting 3x concurrent throughput.",
                    "Collaborated with clinicians to implement model monitoring and feedback loops (data drift detection, calibration checks), enabling monthly model retraining pipelines."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 FleetLogix",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed probabilistic demand-forecasting models (Prophet + LSTM ensembles) used for dynamic fleet allocation, increasing utilization by 14% and reducing idle time by 26%.",
                    "Migrated batch training to AWS SageMaker and implemented feature store patterns, reducing model refresh time from 24 hours to 2 hours.",
                    "Created streaming feature pipelines with Kafka + Spark Structured Streaming to enable near real-time decisioning for dispatching rules.",
                    "Instrumented A/B experiments and uplift analyses that informed product changes, contributing to a 9% YoY revenue increase."
                ]
            },
            {
                "name": "Data Scientist \u2014 OptiRetail",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built personalized recommendation engine (matrix factorization + side features) increasing click-through-rate by 12% and average order value by 6%.",
                    "Implemented uplift and causal inference experiments to prioritize promotional spend, improving campaign ROI by 30%.",
                    "Constructed ETL pipelines using Spark and Airflow to unify cross-channel user behavior data into a central analytics platform."
                ]
            },
            {
                "name": "Research Assistant \u2014 UC Berkeley AI Lab",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "bullets": [
                    "Conducted research on semi-supervised learning for image segmentation; co-authored paper presented at a major workshop.",
                    "Implemented experimental training pipelines in TensorFlow and contributed to open-source evaluation scripts used by the lab."
                ]
            }
        ],
        "projects": [
            {
                "name": "CT Triage \u2014 Real-time Medical Imaging Classifier",
                "description": "End-to-end system for detecting urgent findings in CT scans. Includes preprocessing, multi-stage CNN ensemble, model serving, and monitoring dashboard for clinicians.",
                "technologies": [
                    "PyTorch",
                    "FastAPI",
                    "Docker",
                    "Kubernetes",
                    "MLflow",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "Demand Forecasting Platform",
                "description": "Scalable forecasting pipeline combining classical time-series models and LSTM ensembles with automated feature engineering and backtesting; integrated with scheduling system for operations.",
                "technologies": [
                    "Spark",
                    "AWS SageMaker",
                    "Kafka",
                    "Airflow",
                    "scikit-learn"
                ],
                "year": 2019
            },
            {
                "name": "Personalized Recommendation Engine",
                "description": "Hybrid recommender combining collaborative filtering, content-based features, and real-time session signals; deployed as a microservice and A/B tested across web and mobile.",
                "technologies": [
                    "TensorFlow",
                    "Redis",
                    "Docker",
                    "Postgres"
                ],
                "year": 2017
            },
            {
                "name": "Model Explainability Toolkit",
                "description": "Internal toolkit to generate SHAP-based explanations, counterfactual examples, and automated summary reports for stakeholders; integrated into model review workflow.",
                "technologies": [
                    "Python",
                    "SHAP",
                    "Streamlit"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S., Computer Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "Master of Science, Computer Science"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S., Electrical Engineering & Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "Bachelor of Science, EECS"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "Spark",
            "SQL",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, S3, Lambda)",
            "GCP (BigQuery, AI Platform)",
            "MLflow",
            "Airflow",
            "Kafka",
            "Time-series forecasting",
            "Computer vision",
            "Model monitoring & explainability",
            "CI/CD for ML"
        ],
        "achievements": [
            "Reduced production inference latency by 60% through architecture redesign and optimized batching; improved user-facing performance SLAs.",
            "Delivered a forecast model that decreased operational costs by $1.2M annually through better resource allocation.",
            "Authored internal MLOps best-practices adopted across three engineering teams, shortening model deployment time by 50%.",
            "Co-author on workshop paper for semi-supervised image segmentation (2016)."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2023
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, product-focused teams with strong emphasis on reproducibility, model monitoring, and ethical ML practices.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (415) 555-0147",
            "email": "maya.patel47@example.com",
            "linkedin": "https://www.linkedin.com/in/mayarp47",
            "github": "https://github.com/mayarp47"
        },
        "summary": "Data Scientist with 10+ years of experience building and deploying predictive models and end-to-end ML systems for healthcare and SaaS products. Strong background in time-series forecasting, causal inference, and production MLOps. Proven track record of translating business goals into data-driven solutions that increase retention, reduce cost, and improve operational efficiency.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nova Diagnostics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of an automated diagnostic triage model that reduced false negatives by 28% and decreased manual review workload by 40%.",
                    "Built a real-time feature store and model-serving pipeline using Kafka, Airflow, MLflow, and Kubernetes; reduced model retraining-to-production time from 3 weeks to 48 hours.",
                    "Designed rigorous A/B testing and monitoring framework for model performance and data drift; implemented alerting and rollback policies that cut incident response time by 60%.",
                    "Mentored a team of 4 data scientists and cross-functional engineers; established best practices for reproducible experiments and model documentation."
                ]
            },
            {
                "name": "Data Scientist, ClearSight Analytics",
                "date": {
                    "start": 2017,
                    "end": 2021
                },
                "bullets": [
                    "Owned customer churn prediction and lifecycle analytics product, improving 90-day retention predictions (AUC) from 0.72 to 0.84 using feature engineering and ensemble models.",
                    "Implemented scalable time-series forecasting pipeline using Prophet and XGBoost on Spark for demand planning; improved forecast accuracy by 22% and reduced inventory costs.",
                    "Partnered with product and research teams to apply causal inference techniques (synthetic controls, propensity scoring) to evaluate feature impact and pricing experiments.",
                    "Built interactive dashboards in Tableau to surface actionable insights to stakeholders, leading to targeted interventions that increased ARPU."
                ]
            },
            {
                "name": "Data Analyst, BrightBridge Labs",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Developed ETL pipelines and exploratory analyses to support early-stage product decisions; reduced data processing time by 30% via optimized SQL and Spark jobs.",
                    "Executed A/B tests and cohort analyses to measure feature adoption and monetization strategies; presented results to executive team influencing roadmap priorities.",
                    "Automated recurring reports and data quality checks, improving reliability of KPIs used across marketing and operations teams."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Churn Prediction Service",
                "description": "End-to-end service for streaming ingestion, feature computation, and inference to score users in real time and trigger retention workflows.",
                "technologies": [
                    "Python",
                    "Kafka",
                    "Spark",
                    "MLflow",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "Automated MLOps Pipeline",
                "description": "Reusable CI/CD pipeline for model training, testing, validation, and deployment with automated data drift and performance monitoring.",
                "technologies": [
                    "Airflow",
                    "TensorFlow",
                    "PyTorch",
                    "MLflow",
                    "AWS (S3, EKS, Lambda)"
                ],
                "year": 2021
            },
            {
                "name": "Explainable Anomaly Detection",
                "description": "Interpretable unsupervised anomaly detection system for healthcare device telemetry with SHAP-based explanations for flagged events.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "SHAP",
                    "Pandas",
                    "FastAPI"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. in Statistics (Data Science)"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "NumPy",
            "scikit-learn",
            "XGBoost",
            "PyTorch",
            "TensorFlow",
            "Time Series Forecasting",
            "Causal Inference",
            "Experimentation / A/B Testing",
            "Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Tableau",
            "Model Monitoring"
        ],
        "achievements": [
            "Reduced customer churn by 18% through targeted ML-driven retention campaigns.",
            "Speaker at PyData SF 2022 on \"Practical MLOps for Mid-sized Teams\".",
            "Co-author on a peer-reviewed workshop paper about interpretable anomaly detection (NeurIPS Workshop, 2020).",
            "Implemented processes that decreased model incident rates by 60% through improved monitoring and rollback practices."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "Certified Scrum Product Owner (CSPO)",
                "date": 2018
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Alex Martin",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that emphasize code quality, continuous learning, mentorship, and pragmatic product impact.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0148",
            "email": "alex.martin48@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-martin-ai",
            "github": "https://github.com/alexmartin48"
        },
        "summary": "AI Engineer with 7+ years building and productionizing machine learning systems for search, recommendations, and NLP. Strong background in model engineering, MLOps, and deploying scalable end-to-end pipelines on cloud platforms. Passionate about turning research into reliable products and mentoring engineers.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 NexGen AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led model engineering for a multi-modal retrieval and ranking stack powering enterprise search (NDCG improved 12%, query latency reduced 40%).",
                    "Designed and implemented a production RAG pipeline using FAISS, vector DB, and a fine-tuned encoder; reduced average resolution time for customer queries by 3x.",
                    "Built CI/CD for model training and deployment with GitHub Actions, Terraform, and AWS SageMaker endpoints; decreased deployment time from days to hours.",
                    "Mentored 4 junior engineers; established model validation and monitoring practices (data drift, concept drift alerts) using Prometheus and custom evaluation jobs."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 Cerebra Labs",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed personalized recommendation models (hybrid collaborative + content embeddings) increasing click-through by 18% and revenue by 9%.",
                    "Implemented scalable ETL and feature pipelines with Airflow and Spark; reduced feature freshness from 24h to 2h for time-sensitive models.",
                    "Optimized model inference by quantization and batching; cut inference cost by 55% while maintaining target accuracy.",
                    "Collaborated with product and backend teams to integrate ML services as REST/GRPC microservices with thorough A/B testing."
                ]
            },
            {
                "name": "Research Assistant \u2014 University ML Lab",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Published and implemented experiments on transfer learning for low-resource NLP tasks; improved baseline F1 by 6 points on target tasks.",
                    "Built reproducible experiment pipelines and published code and dockerized environments for reproducibility.",
                    "Assisted in supervising undergraduate projects and taught weekly lab sessions on deep learning frameworks."
                ]
            }
        ],
        "projects": [
            {
                "name": "Enterprise Document QA (RAG)",
                "description": "Built a retrieval-augmented generation system to answer employee and customer queries over private documents. Combined document chunking, vector embeddings, and a fine-tuned decoder to produce concise, source-backed answers.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Hugging Face Transformers",
                    "FAISS",
                    "Postgres",
                    "AWS SageMaker"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Microservice",
                "description": "End-to-end recommendation system including feature store, real-time scoring service, and offline batch retraining. Achieved 18% lift in engagement through hybrid modeling and online feature usage.",
                "technologies": [
                    "Spark",
                    "Airflow",
                    "Redis",
                    "TensorFlow",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Anomaly Detection for Time-Series Metrics",
                "description": "Developed an ensemble of statistical and neural forecasting models to detect anomalies in monitoring signals. Reduced false positive rate by 30% compared to legacy heuristics.",
                "technologies": [
                    "Python",
                    "Prophet",
                    "LSTM",
                    "Prometheus",
                    "Grafana"
                ],
                "year": 2019
            },
            {
                "name": "Transfer Learning Toolkit for Low-Resource NLP",
                "description": "Toolkit and experiments for efficient fine-tuning of pre-trained language models on small datasets using adapters and parameter-efficient methods.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face",
                    "Adapters",
                    "Docker"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. Computer Science (Machine Learning)"
            },
            {
                "name": "State University",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "PyTorch",
            "TensorFlow",
            "Hugging Face",
            "Python",
            "SQL",
            "Spark",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, S3, ECS)",
            "MLOps",
            "Model Monitoring",
            "Feature Engineering",
            "NLP",
            "Recommendation Systems",
            "Vector Search (FAISS, Milvus)"
        ],
        "achievements": [
            "Deployed 15+ ML models to production across search, recommendations, and NLP with robust monitoring and rollback procedures.",
            "Improved search relevance (NDCG) by 12% and reduced inference latency by 40% for high-traffic endpoints.",
            "Published research on transfer learning methods for low-resource NLP tasks; open-sourced toolkit used by academic teams."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Hugging Face: Advanced Transformers Course",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Alex Martin",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, outcome-focused, and data-driven; values clear feedback loops, cross-functional partnership, and a strong emphasis on measurable impact.",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "Seattle, WA, USA"
            },
            "phone": "+1-206-555-0149",
            "email": "alex.martin49@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-martin49",
            "github": "https://github.com/alexmartin49"
        },
        "summary": "AI Engineer with 6+ years building production ML systems and deploying scalable deep learning models for recommendation, computer vision, and NLP. Strong background in model optimization, MLOps, and cross-functional product delivery. Skilled at translating research prototypes into robust services that meet latency, cost, and accuracy targets.",
        "experience": [
            {
                "name": "Senior AI Engineer, EchoRetail (AI-driven retail personalization)",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development of a multimodal personalization service (text + image) used by 120M monthly users; improved click-through rate by 12% and revenue-per-visit by 7%.",
                    "Designed model serving architecture using TorchServe and Kubernetes, achieving 85th-percentile latency of 95ms with autoscaling and SLO monitoring.",
                    "Introduced mixed-precision training and ONNX quantization, reducing GPU inference cost by 3x while maintaining <1% relative accuracy loss.",
                    "Partnered with data engineering and product teams to deploy A/B tests, establish data contracts, and iterate model features in weekly cycles."
                ]
            },
            {
                "name": "Machine Learning Engineer, ClearSight Analytics",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Built a real-time anomaly detection pipeline for streaming time-series data using Kafka, Flink, and PyTorch, reducing incident detection time from hours to under 2 minutes.",
                    "Architected feature stores and reproducible pipelines with MLflow and Airflow; cut model retrain-to-deploy time from 3 days to under 6 hours.",
                    "Implemented explainability tooling (SHAP-based) for stakeholders, improving trust and enabling model remediation workflows.",
                    "Mentored junior engineers and ran internal workshops on model reliability, unit-testing of ML code, and CI/CD best practices."
                ]
            },
            {
                "name": "Data Scientist, BrightMetrics",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Developed recommendation and ranking models (factorization machines, gradient-boosted trees) that increased user engagement by 9%.",
                    "Led end-to-end experiments including hypothesis design, metric instrumentation, and analysis for product A/B tests.",
                    "Automated model evaluation reports and established continuous monitoring dashboards for data drift and model performance."
                ]
            }
        ],
        "projects": [
            {
                "name": "ProdVision: Lightweight Object Detection for Edge",
                "description": "Designed and deployed a compact object-detection pipeline for edge devices using MobileNetV3 backbone, pruning, and 8-bit quantization; maintained 78% mAP on target classes while achieving 20 FPS on mid-tier SoC.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "Edge TPU",
                    "Quantization"
                ],
                "year": 2023
            },
            {
                "name": "PersonalizeX: Multimodal Recommender",
                "description": "Built a hybrid recommender combining embeddings from product images and descriptions with session-based transformers; deployed as a microservice with online A/B testing and cold-start strategies.",
                "technologies": [
                    "PyTorch",
                    "Transformers",
                    "Kafka",
                    "Kubernetes",
                    "Redis"
                ],
                "year": 2022
            },
            {
                "name": "StreamGuard: Real-time Anomaly Detection",
                "description": "Implemented streaming ML pipeline for anomaly detection on telemetry data with online model updates and alert prioritization, enabling faster incident response and lower false positives.",
                "technologies": [
                    "Apache Kafka",
                    "Apache Flink",
                    "scikit-learn",
                    "Prometheus"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. in Computer Science (Machine Learning specialization)"
            },
            {
                "name": "University of Michigan",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Deep Learning (CNNs, Transformers)",
            "PyTorch",
            "TensorFlow",
            "MLOps (Kubernetes, Docker, MLflow, Airflow)",
            "Model optimization (quantization, pruning, distillation)",
            "Programming: Python, SQL, Bash",
            "Distributed systems: Kafka, Redis",
            "Experimentation & A/B testing",
            "Monitoring & observability (Prometheus, Grafana)"
        ],
        "achievements": [
            "Reduced inference cost by 3x for a production recommendation model through mixed-precision training and optimized serving.",
            "Delivered a multimodal personalization product that increased CTR by 12% and revenue per visit by 7%.",
            "Authored internal best-practice playbook for model deployment and reliability adopted across engineering org."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Aisha K. Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that emphasize rigorous evaluation, reproducible engineering practices, and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "425 Mission St, Apt 12B"
            },
            "phone": "+1-415-555-7298",
            "email": "aisha.rahman@email.com",
            "linkedin": "https://www.linkedin.com/in/aishakrahman",
            "github": "https://github.com/aishak-ml"
        },
        "summary": "Data Scientist with 9+ years of applied machine learning and analytics experience building production ML systems in healthcare and SaaS. Strong background in predictive modeling, causal inference, and MLOps; experienced shipping end-to-end pipelines on AWS and Spark and mentoring cross-functional teams to adopt data-driven decision making.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nexus Health",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a readmission risk model for post-acute patients, improving early intervention targeting and reducing 30-day readmissions by 18%.",
                    "Designed an end-to-end ML pipeline (data validation, feature store, training, CI/CD) using AWS SageMaker, Step Functions, and Terraform; reduced model retraining cycle time from 3 weeks to 48 hours.",
                    "Established model monitoring and drift detection using Prometheus and custom explainability metrics; automated alerts cut incident response time by 60%.",
                    "Collaborated with clinical and product teams to translate model outputs into actionable workflows; contributed to 2 product launches that increased patient engagement metrics by 12%."
                ]
            },
            {
                "name": "Data Scientist, BrightScale Analytics",
                "date": {
                    "start": 2017,
                    "end": 2020
                },
                "bullets": [
                    "Built churn and CLTV models for multiple SaaS customers using survival analysis and gradient boosting (XGBoost), increasing retention campaign lift by 22%.",
                    "Implemented scalable feature engineering with Spark and Delta Lake, enabling nightly retraining across >50 customer datasets.",
                    "Introduced A/B testing best practices and Bayesian analysis to improve experiment sensitivity and reduce false positives.",
                    "Mentored junior data scientists; led brown-bag series on causal inference and interpretability."
                ]
            },
            {
                "name": "Machine Learning Engineer, OpenSignals",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Developed real-time signal processing and anomaly detection models for wearable sensor data using CNNs and temporal models, reducing false alarms by 30%.",
                    "Optimized model inference on edge devices and containerized pipelines using Docker, reducing latency by 40%.",
                    "Collaborated with hardware and firmware teams to instrument data collection and implement on-device data quality checks."
                ]
            },
            {
                "name": "Data Science Intern, City Labs",
                "date": {
                    "start": 2014,
                    "end": 2015
                },
                "bullets": [
                    "Conducted exploratory data analysis and prototype modeling for urban mobility datasets; produced insights that informed a pilot city transit optimization project.",
                    "Automated ETL workflows and produced dashboards to communicate findings to city planners."
                ]
            }
        ],
        "projects": [
            {
                "name": "Personalized Care Recommendation Engine",
                "description": "End-to-end system that recommends prioritized interventions for chronic disease patients by combining clinical risk models with cost-effectiveness heuristics.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "PyTorch",
                    "AWS SageMaker",
                    "PostgreSQL"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Anomaly Detection for Wearables",
                "description": "Lightweight CNN-LSTM model deployed on edge devices to detect abnormal physiologic patterns with on-device pre-filtering and cloud aggregation for alerts.",
                "technologies": [
                    "TensorFlow Lite",
                    "Docker",
                    "Kafka",
                    "Kubernetes"
                ],
                "year": 2017
            },
            {
                "name": "Customer Churn Attribution Toolkit",
                "description": "Toolkit combining uplift modeling and causal forests to identify interventions most likely to reduce churn; included automated reporting and experiment design templates.",
                "technologies": [
                    "R",
                    "causalForest",
                    "XGBoost",
                    "Spark"
                ],
                "year": 2019
            },
            {
                "name": "Open-source Feature Store Prototype",
                "description": "Prototype feature store for fast online lookups and consistent training features using Delta Lake and Redis-backed online store.",
                "technologies": [
                    "Delta Lake",
                    "Redis",
                    "Spark",
                    "Python"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of Michigan",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S., Statistics"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "Spark",
            "SQL",
            "AWS (SageMaker, S3, Lambda)",
            "Docker",
            "Kubernetes",
            "Feature Engineering",
            "Causal Inference",
            "A/B Testing",
            "MLOps",
            "Model Interpretability"
        ],
        "achievements": [
            "Reduced hospital 30-day readmission rates by 18% through deployed predictive modeling and care pathway integration.",
            "Improved retention campaign lift by 22% across multiple SaaS products through advanced churn modeling.",
            "Published a workshop paper on on-device time-series anomaly detection (NeurIPS workshop, 2018).",
            "Built and scaled ML pipelines handling >100M rows/night for customer analytics workloads."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Maya Thompson",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth-oriented with emphasis on mentorship and reproducible engineering practices.",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "1234 Pike St, Seattle, WA 98101"
            },
            "phone": "+1 (206) 555-0142",
            "email": "maya.thompson@example.com",
            "linkedin": "https://linkedin.com/in/mayathompson",
            "github": "https://github.com/mayathompson"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems and data products for healthcare and finance. Strong background in statistical modeling, time-series, and model deployment. Passionate about translating complex data into actionable insights and mentoring cross-functional teams.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Lumina Health",
                "date": {
                    "start": 2019,
                    "end": 2024
                },
                "bullets": [
                    "Led development and deployment of a patient-risk prediction platform that reduced 30-day readmissions by 18% through targeted interventions.",
                    "Designed end-to-end ML pipelines using Python, Airflow, and Docker; standardized model monitoring and retraining workflows reducing model drift incidents by 45%.",
                    "Collaborated with clinicians and product managers to prioritize features, resulting in a 22% increase in clinician adoption of predictive insights.",
                    "Mentored 4 junior data scientists and established best practices for code review, testing, and reproducible experiments."
                ]
            },
            {
                "name": "Data Scientist \u2014 Aegis Analytics",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Built real-time fraud detection models for payment streams using gradient boosting and online feature engineering, decreasing fraud loss by $1.2M annually.",
                    "Implemented feature stores and scalable ETL with Spark; cut feature retrieval latency by 60% and reduced pipeline failures by 35%.",
                    "Presented model results and A/B test outcomes to stakeholders; collaborated to deploy models to production with CI/CD pipelines."
                ]
            },
            {
                "name": "Machine Learning Engineer Intern \u2014 Veridian Labs",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Developed prototype time-series forecasting models (LSTM and ARIMA hybrids) for demand planning, improving forecast accuracy by 12%.",
                    "Wrote unit tests and documentation for model training scripts; contributed to open-source evaluation tooling used by the team."
                ]
            }
        ],
        "projects": [
            {
                "name": "PatientRisk ML Platform",
                "description": "End-to-end platform for predicting patient readmission risk, including feature engineering, model training, deployment, and dashboarding for clinicians.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Airflow",
                    "Docker",
                    "Postgres",
                    "Tableau"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Fraud Detection",
                "description": "Stream-processing pipeline with real-time scoring for fraud detection on payment events; combined supervised models with rule-based heuristics and alerting.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "Python",
                    "LightGBM",
                    "Redis"
                ],
                "year": 2018
            },
            {
                "name": "tskit: Open-source Time Series Toolkit",
                "description": "Maintained and contributed utilities for time-series feature extraction and evaluation; simplified adoption of common preprocessing patterns across teams.",
                "technologies": [
                    "Python",
                    "pandas",
                    "NumPy"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Machine Learning focus)"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "TensorFlow",
            "Spark",
            "SQL",
            "Airflow",
            "Docker",
            "AWS",
            "Model Monitoring",
            "Time Series Analysis",
            "A/B Testing",
            "Feature Engineering"
        ],
        "achievements": [
            "Reduced 30-day hospital readmissions by 18% through deployment of predictive interventions.",
            "Saved $1.2M annually by improving fraud detection accuracy and lowering false positives.",
            "Published internal best-practices for ML deployment adopted across three product teams."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (Professional Program)",
                "date": 2017
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Ari K. Morgan",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that emphasize ownership, reliable engineering practices, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "123 Market St, Apt 45"
            },
            "phone": "+1-415-555-0192",
            "email": "ari.morgan@example.com",
            "linkedin": "https://www.linkedin.com/in/arikmorgan",
            "github": "https://github.com/arikmorgan"
        },
        "summary": "AI Engineer with 9+ years building and productionizing machine learning systems for recommendation, computer vision, and edge inference. Experienced in end-to-end model development, MLOps, model optimization (quantization/pruning), and scalable inference infrastructure (Kubernetes, gRPC, TF Serving). Strong focus on reducing latency and cost while maintaining model quality.",
        "experience": [
            {
                "name": "Senior AI Engineer, NexaAI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led deployment of a real-time recommendation service serving 50M monthly active users; reduced 95th percentile latency from 220ms to 35ms through model distillation, optimized feature store, and gRPC-based inference.",
                    "Built CICD + MLOps pipelines using GitHub Actions, Terraform, and Argo Workflows to automate model training, validation, and canary rollout to production.",
                    "Implemented multi-tenant model serving on Kubernetes with autoscaling, improving GPU utilization by 3x and lowering monthly inference costs by 42%.",
                    "Collaborated with product and privacy teams to implement differential privacy for user-personalized models and A/B test framework for safe rollouts."
                ]
            },
            {
                "name": "ML Engineer, EdgeCloud Labs",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Designed and shipped an edge model orchestration system enabling model updates to 100k+ edge devices with rollback and staged rollout capabilities.",
                    "Optimized vision models for mobile deployment using post-training quantization and pruning; reduced model size by 8x with <1.5% accuracy loss.",
                    "Instrumented end-to-end monitoring (Prometheus, Grafana) and inference telemetry to detect model drift and trigger retraining pipelines.",
                    "Mentored junior engineers and established model evaluation standards and performance benchmarks across teams."
                ]
            },
            {
                "name": "Data Scientist, Insight Analytics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed personalized ranking models (gradient-boosted trees and neural rankers) that improved click-through-rate by 12% on targeted experiments.",
                    "Constructed feature engineering pipelines and production data validation checks using Spark and Great Expectations.",
                    "Built interpretable model diagnostics and counterfactual analysis tools to guide business decisions and reduce false positives."
                ]
            },
            {
                "name": "Research Intern, VisionLab (University Research)",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Implemented and benchmarked compact CNN architectures for low-power devices; results contributed to a workshop paper on efficient architectures.",
                    "Explored techniques for transfer learning and domain adaptation for small labeled datasets."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Recommendation Engine",
                "description": "Production recommendation system combining hybrid collaborative filtering and distillation-ready neural ranker. Handles feature enrichment, online serving, and A/B experimentation.",
                "technologies": [
                    "TensorFlow",
                    "gRPC",
                    "Kubernetes",
                    "Redis",
                    "Kafka"
                ],
                "year": 2023
            },
            {
                "name": "Edge Model Orchestrator",
                "description": "Platform to orchestrate model deployment, versioning, and rollback for thousands of edge devices with bandwidth-aware scheduling.",
                "technologies": [
                    "Go",
                    "Docker",
                    "Kubernetes",
                    "Protocol Buffers"
                ],
                "year": 2020
            },
            {
                "name": "AutoML Production Pipeline",
                "description": "Automated pipeline for model selection, hyperparameter search, and validation with integration to production CI for continuous retraining.",
                "technologies": [
                    "Argo Workflows",
                    "Kubeflow",
                    "Ray Tune",
                    "PyTorch"
                ],
                "year": 2019
            },
            {
                "name": "Open-source Quantization Toolkit",
                "description": "Library to apply post-training quantization and benchmarking utilities for image models targeting mobile/edge deployment.",
                "technologies": [
                    "TensorFlow Lite",
                    "NumPy",
                    "Docker"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science (AI)"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Model serving",
            "MLOps",
            "Model optimization (quantization/pruning/distillation)",
            "TensorFlow",
            "PyTorch",
            "Kubernetes",
            "gRPC",
            "Docker",
            "Spark",
            "Python",
            "Go",
            "Feature engineering",
            "A/B testing",
            "Monitoring & observability"
        ],
        "achievements": [
            "Reduced production inference latency 5-6x for high-traffic recommendation pipeline while maintaining business metrics.",
            "Cut inference infrastructure cost by 42% through autoscaling and GPU utilization improvements.",
            "Lead author on a workshop paper about efficient CNNs for low-power devices (2016).",
            "Maintainer of an open-source quantization toolkit (2k+ GitHub stars).",
            "Filed 1 patent on staged model rollout system for edge devices."
        ],
        "certifications": [
            {
                "name": "Google Professional Machine Learning Engineer",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2019
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2018
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on mentorship, reproducibility, and continuous learning.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Somerville, MA"
            },
            "phone": "+1-617-555-4821",
            "email": "aisha.rahman@email.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 6+ years applying machine learning, statistical modeling, and data engineering to deliver business impact in healthcare and fintech. Strong track record of productionizing models, improving decision-making pipelines, and mentoring cross-functional teams. Comfortable bridging product, engineering, and research to deploy robust, interpretable solutions.",
        "experience": [
            {
                "name": "Senior Data Scientist, Verity Health Analytics (Hybrid)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a patient-readmission risk model that reduced 30-day readmission by 12% across pilot hospitals; improved precision by 18% versus baseline using gradient boosting and calibration.",
                    "Built automated feature pipelines (Airflow, dbt) and monitoring dashboards (Prometheus + Grafana) to track data drift and model performance, reducing detection-to-remediation time from weeks to under 48 hours.",
                    "Partnered with clinicians and product managers to translate model outputs into actionable interventions, increasing care-team adoption to 75% in 6 months.",
                    "Mentored 4 junior data scientists and instituted code review and unit testing standards that increased reproducibility and reduced production incidents by 40%."
                ]
            },
            {
                "name": "Data Scientist, ClearFin Technologies (On-site)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Designed credit-risk scoring models using logistic regression, XGBoost, and calibration techniques; decreased default prediction error by 22% and enabled a 9% expansion in approved loan volume with maintained loss rates.",
                    "Implemented feature-store patterns and scalable ETL on Spark, cutting feature engineering runtime by 65% and enabling daily model retraining.",
                    "Collaborated with engineering to containerize models (Docker) and deploy via Kubernetes, establishing CI/CD pipelines for ML artifacts.",
                    "Conducted A/B tests and uplift modeling to quantify product changes, driving a 6% increase in conversion for targeted offers."
                ]
            },
            {
                "name": "Data Analyst / Junior ML Engineer, WellBridge Research (On-site)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Performed exploratory analysis and built prototypes for clinical signal detection using time-series models and NLP on EHR notes; prototypes prioritized for further research.",
                    "Automated reporting and data validation scripts that reduced monthly report generation time from 3 days to 4 hours.",
                    "Collaborated with senior researchers to prepare datasets and reproducible experiments, contributing to two internal whitepapers."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Sepsis Early Warning System",
                "description": "End-to-end system for early detection of sepsis using streaming EHR data. Included feature extraction, online model scoring, and alerting integration with clinician workflows.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Kafka",
                    "Docker",
                    "Kubernetes",
                    "PostgreSQL"
                ],
                "year": 2023
            },
            {
                "name": "Explainable Credit Scoring Dashboard",
                "description": "Interactive dashboard for loan officers showing model scores with SHAP explanations and counterfactual scenarios to support fair lending decisions.",
                "technologies": [
                    "Python",
                    "LightGBM",
                    "SHAP",
                    "Streamlit",
                    "AWS S3"
                ],
                "year": 2020
            },
            {
                "name": "Patient Readmission Risk Simulator",
                "description": "Simulation tool combining predictive models and operational constraints to evaluate intervention strategies and projected readmission reductions.",
                "technologies": [
                    "R",
                    "pandas",
                    "SimPy",
                    "SQL"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "Master of Science, Data Science \u2014 Northeastern University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "Bachelor of Science, Computer Science \u2014 University of Dhaka",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "TensorFlow",
            "Pandas",
            "Spark",
            "Docker",
            "Kubernetes",
            "Airflow",
            "dbt",
            "Model Monitoring",
            "A/B Testing",
            "SHAP / Explainability",
            "Time Series Analysis",
            "NLP"
        ],
        "achievements": [
            "Reduced production model incident rate by 40% through CI/CD, testing, and monitoring improvements.",
            "Authored internal best-practices for model governance adopted enterprise-wide.",
            "Presented work on readmission risk modeling at a national healthcare analytics conference (2023)."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "AWS Certified Data Analytics \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Certified Data Scientist (DASCA)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused, and data-driven; values clear metrics, fast iteration, and mentorship across teams.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0123",
            "email": "maya.patel.datasci@example.com",
            "linkedin": "https://www.linkedin.com/in/mayapatel-ds",
            "github": "https://github.com/mayapatelds"
        },
        "summary": "Data scientist with 8+ years building and productionizing ML systems for healthcare and e-commerce. Strong background in end-to-end model development (feature engineering, modeling, evaluation, deployment) and instrumentation for experimentation. Experienced with distributed data processing, model serving, and reducing inference latency in production environments.",
        "experience": [
            {
                "name": "NexaHealth (Senior Data Scientist)",
                "date": {
                    "start": 2021,
                    "end": 2024
                },
                "bullets": [
                    "Led development of a clinical risk stratification model (ensemble of gradient-boosted trees + neural network features) to predict 30-day readmission risk; integrated model into clinician workflows and reduced readmission-related costs by 12%.",
                    "Built end-to-end ML pipeline: feature stores (Spark + Delta Lake), model training with MLflow, and REST inference service (FastAPI + Docker) on AWS; reduced model retrain time from 6 hours to 45 minutes.",
                    "Designed AB tests and evaluation metrics with stakeholders; established alerting for performance drift and monthly retraining cadence.",
                    "Mentored 3 junior data scientists and interns; introduced code review and standardized model card practices to improve reproducibility."
                ]
            },
            {
                "name": "ShopLayer (Data Scientist)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Owned session-based recommender prototypes using implicit feedback and sequence models; productionized a hybrid recommender that increased CTR by 7% and revenue-per-session by 4%.",
                    "Implemented distributed feature processing with Spark and ingest pipelines using Kafka; reduced feature compute costs by 30% through feature reuse and caching (Redis).",
                    "Collaborated with product and engineering to instrument experiments; ran over 50 experiments per year and translated results into product changes."
                ]
            },
            {
                "name": "CityTransit Labs (Data Analyst \u2192 Junior Data Scientist)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built time-series demand forecasting models for transit load balancing using Prophet and gradient-boosted models; improved schedule adherence predictions and resource allocation.",
                    "Developed anomaly detection pipelines for streaming telemetry with thresholding and isolation forest models; automated incident triage workflows and reduced manual alerts by 40%.",
                    "Implemented ETL workflows (Airflow + PostgreSQL) and dashboards (Grafana) for operations teams."
                ]
            }
        ],
        "projects": [
            {
                "name": "PrescribeAI - Clinical Risk Platform",
                "description": "End-to-end platform for patient risk scoring and clinician-facing decision support. Includes feature extraction, model training, monitoring, and a FastAPI service for low-latency inference used by care teams.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "FastAPI",
                    "Docker",
                    "AWS (S3, ECS, RDS)",
                    "MLflow"
                ],
                "year": 2023
            },
            {
                "name": "Realtime Recommender",
                "description": "Session-aware recommender deploying a lightweight RNN-based model with fallback collaborative filtering. Powered online personalization with Kafka stream processing and Redis caching.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Spark",
                    "Kafka",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Demand Forecasting Platform",
                "description": "SKU-level forecasting pipeline for weekly demand planning. Combined time-series models (Prophet) with hierarchical reconciliation and automated reporting for supply chain teams.",
                "technologies": [
                    "R",
                    "Prophet",
                    "SQL",
                    "Airflow"
                ],
                "year": 2017
            },
            {
                "name": "Anomaly Detection Dashboard",
                "description": "Interactive monitoring dashboard that surfaces anomalies across key business metrics using isolation forest and seasonal decomposition; integrated alerting and root-cause links for rapid investigation.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "PostgreSQL",
                    "Grafana"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Michigan, Ann Arbor",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "A/B testing",
            "Time series forecasting",
            "Causal inference",
            "Data visualization"
        ],
        "achievements": [
            "Co-authored workshop paper on fairness-aware clinical models, presented at a major ML conference (2022).",
            "Delivered production model that reduced hospital readmission costs by 12% at NexaHealth.",
            "Introduced CI/CD for model deployment reducing manual release steps by 75%.",
            "Mentored interns and junior hires; two mentees promoted to mid-level data scientist roles."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Data Scientist (DASCA)",
                "date": 2018
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Alex Martin",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on measurable impact, continuous learning and knowledge sharing",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "1234 Market St, Apt 56"
            },
            "phone": "+1-415-555-0123",
            "email": "alex.martin55@example.com",
            "linkedin": "https://www.linkedin.com/in/alex-martin55",
            "github": "https://github.com/alex-martin55"
        },
        "summary": "AI Engineer with 8+ years building production ML systems and end-to-end MLOps pipelines. Experienced in deploying large-scale deep learning models for computer vision and time-series forecasting, optimizing inference for edge and cloud, and leading cross-functional teams to deliver measurable business impact.",
        "experience": [
            {
                "name": "Lead AI Engineer \u2014 Nimbus Health",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led design and production deployment of multi-modal diagnostic models (images + EHR) improving detection accuracy by 18% and reducing false positives by 27%.",
                    "Built and maintained CI/CD MLOps pipelines using GitHub Actions, Terraform, and Kubernetes, enabling weekly model releases and automated rollbacks.",
                    "Optimized model inference (quantization, pruning) and moved critical workloads to NVIDIA Triton, reducing latency by 60% and cloud inference cost by 40%.",
                    "Mentored a team of 5 ML engineers and data scientists, established code review and model validation standards, and championed reproducible experiments."
                ]
            },
            {
                "name": "AI Engineer \u2014 Radiant Analytics",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed time-series forecasting models (Transformer and probabilistic models) for demand prediction, improving forecast accuracy (MAPE) from 16% to 9%.",
                    "Implemented feature stores and automated model monitoring with Prometheus and Grafana, enabling early detection of data drift and concept drift.",
                    "Collaborated with backend teams to containerize models and deploy on AWS EKS; introduced autoscaling rules to handle burst traffic.",
                    "Authored technical designs and led cross-team integration with product and research stakeholders to prioritize model improvements."
                ]
            },
            {
                "name": "Data Scientist \u2014 Bright Labs",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Built recommendation and classification models using XGBoost and deep learning, leading to a 12% uplift in user engagement.",
                    "Designed and analyzed A/B tests to evaluate feature changes; provided statistically rigorous insights used to guide product decisions.",
                    "Automated ETL workflows with Airflow and optimized SQL pipelines to reduce ETL runtime by 45%."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeVision",
                "description": "Real-time object detection pipeline optimized for ARM-based edge devices. Implemented model quantization, pruning, and a custom scheduling layer to maximize throughput on limited hardware.",
                "technologies": [
                    "TensorFlow Lite",
                    "PyTorch",
                    "ONNX",
                    "C++",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "PredictRX",
                "description": "End-to-end readmission risk predictor for hospitals combining EHR time-series and imaging embeddings. Integrated model into clinician workflow with explainability features and threshold tuning for recall/precision trade-offs.",
                "technologies": [
                    "PyTorch",
                    "scikit-learn",
                    "FastAPI",
                    "Postgres",
                    "SHAP"
                ],
                "year": 2021
            },
            {
                "name": "AutoDeploy",
                "description": "Automated MLOps toolkit for training, versioning, and serving models. Includes experiment tracking, model registry, and automated canary deployments with rollback.",
                "technologies": [
                    "MLflow",
                    "Kubernetes",
                    "Terraform",
                    "GitHub Actions",
                    "Helm"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "Carnegie Mellon University \u2014 M.S. Computer Science",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "Master of Science in Computer Science (Machine Learning Track)"
            },
            {
                "name": "University of California, Berkeley \u2014 B.S. Electrical Engineering & Computer Science",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "Bachelor of Science in EECS"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "MLOps",
            "Kubernetes",
            "AWS (SageMaker, EKS)",
            "Docker",
            "SQL",
            "scikit-learn",
            "Triton Inference Server",
            "Model Monitoring",
            "Experiment Tracking"
        ],
        "achievements": [
            "Reduced inference latency by 60% and inference costs by 40% through model optimization and Triton integration.",
            "Led ML initiatives that contributed to $2M+ annualized revenue uplift via improved prediction accuracy and automation.",
            "Published a peer-reviewed paper on efficient on-device inference techniques (conference workshop, 2022)."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2021
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Elena M. Carter",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and impact-focused environment that encourages experimentation, mentorship, and clear product outcomes.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Mountain View, CA"
            },
            "phone": "+1-650-555-2410",
            "email": "elena.carter.data@gmail.com",
            "linkedin": "https://www.linkedin.com/in/elenamcarter",
            "github": "https://github.com/elenamcarter"
        },
        "summary": "Data scientist with 10+ years of experience building production ML systems, leading cross-functional analytics initiatives, and translating data into business impact. Strong background in predictive modeling, causal inference, and scalable data pipelines. Experienced mentor and stakeholder communicator who drives experiments and deploys models in cloud environments.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Aurora Health Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a team of 4 data scientists to develop risk-prediction models for hospital readmission using EHR and claims data, reducing readmission rates by 9% through targeted interventions.",
                    "Designed and deployed real-time inference pipelines on AWS (Sagemaker + Lambda + ECS) processing 500k+ patient records monthly.",
                    "Introduced causal uplift modeling for personalized care recommendations, increasing treatment effectiveness by 15% compared to baseline rules.",
                    "Established model monitoring and bias-detection framework using MLflow and custom fairness metrics; reduced model drift incidents by 70%."
                ]
            },
            {
                "name": "Data Scientist \u2014 NovaFintech",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built customer churn and lifetime value models (XGBoost & deep learning ensembles) that informed segmentation and retention campaigns, improving monthly revenue by 6%.",
                    "Spearheaded A/B testing roadmap and analysis platform, delivering automated experiment reports and sample size calculators used across product teams.",
                    "Optimized feature engineering and training workflows using Spark and Airflow, decreasing model training time by 4x.",
                    "Collaborated with product and engineering to productionize fraud-detection models with sub-second latency using Redis and microservices."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 EdgeVision Labs",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Developed computer vision pipelines for real-time object detection (SSD / YOLO variants) deployed on edge devices; improved inference throughput by 30%.",
                    "Implemented data augmentation and semi-supervised learning strategies to reduce labeled-data needs by 40%.",
                    "Authored internal libraries for model quantization and deployment, enabling model size reductions without significant accuracy loss."
                ]
            }
        ],
        "projects": [
            {
                "name": "Personalized Care Uplift Model",
                "description": "End-to-end uplift modeling pipeline to identify patients most likely to benefit from targeted interventions; included feature store, training, evaluation, and deployment with A/B testing support.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "CausalML",
                    "AWS SageMaker",
                    "MLflow",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Fraud Detection Service",
                "description": "Streaming fraud detection service combining gradient-boosted models and rule-based system, integrated into payment processing with <200ms latency.",
                "technologies": [
                    "Spark",
                    "XGBoost",
                    "Kafka",
                    "Redis",
                    "Flask",
                    "Kubernetes"
                ],
                "year": 2020
            },
            {
                "name": "Customer LTV Forecasting Suite",
                "description": "Multi-horizon LTV forecasting system using survival analysis and ensemble models to support acquisition spend optimization and cohort analysis.",
                "technologies": [
                    "Python",
                    "pandas",
                    "Prophet",
                    "LightGBM",
                    "Tableau"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S., Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "NumPy",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLflow",
            "XGBoost",
            "LightGBM",
            "NLP",
            "Computer Vision",
            "Causal Inference",
            "A/B Testing",
            "Feature Engineering",
            "Model Monitoring"
        ],
        "achievements": [
            "Reduced hospital readmission rates by 9% through risk models and targeted care interventions at Aurora Health Analytics.",
            "Increased monthly revenue by 6% at NovaFintech via improved churn prediction and retention strategies.",
            "Cut model training times 4x by redesigning ETL and training pipelines using Spark and Airflow.",
            "Published two peer-reviewed workshop papers on semi-supervised learning for computer vision (2017, 2018)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2019
            },
            {
                "name": "Certified ScrumMaster (CSM)",
                "date": 2017
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Arjun Mehta",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, metrics-driven team that values ownership, continuous learning, clear feedback, and pragmatic experimentation.",
        "contact": {
            "address": {
                "region": "Bengaluru, Karnataka, India",
                "detail": "Koramangala, Hosur Road"
            },
            "phone": "+91-9876543210",
            "email": "arjun.mehta@example.com",
            "linkedin": "https://www.linkedin.com/in/arjunmehta",
            "github": "https://github.com/arjunmehta"
        },
        "summary": "AI Engineer with 8+ years building and productionizing ML systems for search, recommendations, and real-time inference. Strong in model engineering, MLOps, and scalable architectures; experienced delivering measurable business impact through feature stores, CI/CD, and performance optimization.",
        "experience": [
            {
                "name": "Neurolytics Labs \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and production deployment of a retrieval-augmented generation (RAG) pipeline for enterprise document QA; integrated vector DB, dense retriever, and LLM; improved answer relevance by 38% (NDCG).",
                    "Built scalable model serving microservices with Kubernetes, KFServing, and Traefik; reduced 99th percentile latency from 1.2s to 600ms via batching and async prefetching.",
                    "Introduced model quantization and dynamic batching that cut GPU spend by ~30% while maintaining >95% of original accuracy.",
                    "Established CI/CD for models (Git, DVC, GitHub Actions) and monitoring (Prometheus, Grafana, Seldon), enabling safe daily model rollouts and automated drift alerts.",
                    "Mentored a team of 4 ML engineers and interns; instituted code review and reproducible experiment standards."
                ]
            },
            {
                "name": "CloudScale AI \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2017,
                    "end": 2021
                },
                "bullets": [
                    "Developed a real-time recommendation engine (streaming features, online model scoring) that increased CTR by 12% and contributed to a 6% uplift in monthly revenue.",
                    "Implemented a feature store using Feast and Spark, enabling consistent offline/online features and reducing feature-lookup mismatch incidents by 85%.",
                    "Authored end-to-end pipelines with Airflow and Spark for feature extraction and model training, decreasing retraining time from 8 hours to 90 minutes.",
                    "Ran A/B experiments and interpretable model analyses (SHAP) to guide product decisions and prioritized features with highest ROI."
                ]
            },
            {
                "name": "FinEdge Analytics \u2014 Data Science Intern",
                "date": {
                    "start": 2014,
                    "end": 2015
                },
                "bullets": [
                    "Built credit-risk scoring prototypes using gradient-boosted trees and logistic regression; improved default prediction accuracy by 9% vs baseline.",
                    "Automated ETL processes for financial datasets using Python and PostgreSQL, accelerating reporting cycles for analysts.",
                    "Collaborated with senior data scientists to prepare datasets for model validation and regulatory reporting."
                ]
            }
        ],
        "projects": [
            {
                "name": "Multi-Modal Document Understanding (RAG)",
                "description": "End-to-end system combining OCR, image-layout embeddings, dense retrieval, and LLM-based answer generation for enterprise document Q&A. Includes vector DB indexing, relevance tuning, and user feedback loop.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face",
                    "FAISS",
                    "Docker",
                    "Kubernetes",
                    "Postgres"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Low-latency recommendation service using streaming user events, online feature store, and lightweight neural ranking model for personalized feeds.",
                "technologies": [
                    "Kafka",
                    "Feast",
                    "TensorFlow",
                    "Redis",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Anomaly Detection Platform",
                "description": "Platform for detecting transaction anomalies in financial pipelines using ensemble models and streaming alerts; integrated with monitoring dashboards and incident workflows.",
                "technologies": [
                    "Spark",
                    "Scikit-learn",
                    "Elasticsearch",
                    "Prometheus"
                ],
                "year": 2020
            },
            {
                "name": "On-device Keyword Spotting",
                "description": "Lightweight on-device model for wake-word detection optimized for ARM CPUs; applied pruning and quantization to meet latency and memory constraints.",
                "technologies": [
                    "TensorFlow Lite",
                    "Keras",
                    "Edge Impulse"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Technology, Madras",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.Tech, Computer Science"
            },
            {
                "name": "RV College of Engineering",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.Tech, Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face",
            "ML Ops",
            "Kubernetes",
            "Docker",
            "FAISS",
            "Feast",
            "Spark",
            "Airflow",
            "SQL",
            "AWS",
            "GCP",
            "Model Optimization (quantization, pruning)",
            "Experimentation & A/B testing",
            "Software engineering best practices"
        ],
        "achievements": [
            "Published a workshop paper on efficient RAG pipelines (NeurIPS Workshop, 2022).",
            "Speaker at PyData Bengaluru 2023 on productionizing LLMs.",
            "Reduced production model inference costs by ~30%, saving an estimated $200k annually.",
            "Recipient of 'Engineer of the Quarter' at Neurolytics Labs (Q2 2022) for delivering high-impact production features."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Deep Learning Specialization (Coursera, deeplearning.ai)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Priya Malhotra",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven environment with strong engineering practices, emphasis on mentorship, reproducibility, and measurable business impact.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala, Bengaluru"
            },
            "phone": "+91-98765-43210",
            "email": "priya.malhotra@example.com",
            "linkedin": "https://www.linkedin.com/in/priyamalhotra-ds",
            "github": "https://github.com/priyamal"
        },
        "summary": "Data Scientist with 7+ years of experience building end-to-end ML solutions for finance and healthcare domains. Strong background in probabilistic modeling, forecasting, NLP, and production ML systems (MLOps). Proven track record of delivering models that drive measurable business impact and operationalize them using robust engineering practices.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Zeta Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a cross-functional team to design and deploy a customer churn prediction system that reduced monthly churn by 12% through targeted retention campaigns.",
                    "Built a probabilistic forecasting stack (Prophet + gradient boosting ensembles) for subscription revenue; improved 3-month forecast accuracy (MAPE) from 18% to 7%.",
                    "Designed and implemented MLOps pipeline (CI/CD, model registry, monitoring) using GitHub Actions, Docker, and AWS SageMaker, reducing model deployment time from weeks to hours.",
                    "Introduced model explainability (SHAP) and automated drift detection dashboards, enabling product owners to interpret and trust model outputs.",
                    "Mentored three junior data scientists and led weekly brown-bag sessions on ML best practices and performance optimization."
                ]
            },
            {
                "name": "Data Scientist \u2014 Innova Health Tech",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed a clinical risk prediction model (xgboost + feature engineering) for 30-day readmission with AUC improvement from 0.72 to 0.82 versus baseline.",
                    "Built an NLP pipeline to extract key clinical entities from unstructured notes using spaCy and custom CRF models, increasing structured data completeness by 40%.",
                    "Collaborated with clinicians to validate model outputs and integrated the model into the EHR workflow via a REST API, enabling live inference and clinician feedback.",
                    "Optimized heavy ETL jobs using Spark, cutting nightly processing time by 60% and enabling near-real-time feature updates."
                ]
            },
            {
                "name": "Data Science Intern \u2014 Flipkart",
                "date": {
                    "start": 2015,
                    "end": 2015
                },
                "bullets": [
                    "Implemented a demand forecasting prototype for select SKUs using time-series decomposition and boosting trees, reducing stockouts on pilot SKUs by 8%.",
                    "Automated data validation checks and created dashboards to monitor forecast performance for stakeholders."
                ]
            }
        ],
        "projects": [
            {
                "name": "Customer Churn Forecasting",
                "description": "End-to-end churn prediction pipeline for subscription product: feature store, model training, evaluation, and serving with explainability and monitoring.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "SHAP",
                    "AWS SageMaker",
                    "Docker",
                    "SQL"
                ],
                "year": 2022
            },
            {
                "name": "Automated MLOps Pipeline",
                "description": "Built CI/CD and deployment automation for ML models using GitHub Actions, Docker, Kubernetes, and MLflow; integrated model registry and canary deployments.",
                "technologies": [
                    "MLflow",
                    "Docker",
                    "Kubernetes",
                    "GitHub Actions",
                    "FastAPI"
                ],
                "year": 2023
            },
            {
                "name": "Clinical Notes NLP Extractor",
                "description": "NLP pipeline to extract diagnoses, medications, and procedures from unstructured clinical notes; combined rule-based and neural approaches to maximize precision.",
                "technologies": [
                    "spaCy",
                    "PyTorch",
                    "CRF",
                    "NLTK",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Sales Demand Forecasting for Retail",
                "description": "Multi-horizon forecasting system using hierarchical time-series models and LightGBM; incorporated promotions and external signals to improve forecasts for inventory planning.",
                "technologies": [
                    "Prophet",
                    "LightGBM",
                    "pandas",
                    "Spark",
                    "Airflow"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Science (IISc), Bengaluru",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "National Institute of Technology, Tiruchirappalli",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.Tech in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "pandas",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "PyTorch",
            "TensorFlow",
            "NLP (spaCy)",
            "Time-series forecasting",
            "MLOps (Docker, Kubernetes, MLflow)",
            "AWS (S3, SageMaker, Lambda)",
            "Spark",
            "Model monitoring & explainability"
        ],
        "achievements": [
            "Speaker at DS in Practice Track, KDD India (2023) on deploying interpretable forecasting systems",
            "Reduced production model latency by 65% through optimization and model distillation",
            "Mentored interns that produced two open-source utilities adopted by the team for feature validation"
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Deep Learning Specialization (Coursera)",
                "date": 2019
            }
        ],
        "total_experience": 7,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and inclusive. Prefers teams that value clear communication, reproducible practices, and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "San Francisco, CA"
            },
            "phone": "+1 (415) 555-0134",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aishar-dev"
        },
        "summary": "Data scientist with 8+ years of experience building and shipping ML systems for healthcare and e-commerce. Strong background in applied ML, production model deployment, MLOps, and cross-functional collaboration. Comfortable turning ambiguous product questions into measurable ML solutions and mentoring engineers and analysts.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nimbus Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a team of 4 data scientists and engineers to develop real-time demand forecasting models used by enterprise customers, improving forecast accuracy by 18% and reducing stockouts by 12%.",
                    "Designed and deployed a CI/CD-backed model lifecycle (Airflow + Docker + Kubernetes) that reduced time-to-production for models from 6 weeks to 10 days.",
                    "Implemented model monitoring and drift detection pipelines (Prometheus + Grafana + Great Expectations) that cut incident response time by 40%.",
                    "Partnered with product and sales to translate model outputs into actionable KPIs; contributed to $3M incremental ARR from features powered by ML."
                ]
            },
            {
                "name": "Data Scientist, PulseHealth",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built clinical risk stratification models (XGBoost, LightGBM) for chronic disease management with AUC improvements from 0.72 to 0.84 versus prior baselines.",
                    "Worked with clinicians to interpret model predictions and incorporated SHAP-based explainability into provider dashboards, improving clinician trust and adoption.",
                    "Containerized model inference services and integrated them into the EMR workflow using REST APIs and Kubernetes, handling >10k requests/day with 99.9% uptime.",
                    "Ran randomized A/B experiments to validate model-driven interventions; documented statistically significant reductions in readmission rates."
                ]
            },
            {
                "name": "Machine Learning Engineer, BrightRetail",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed recommendation and personalization systems (collaborative filtering + deep learning embeddings) that increased CTR by 12% and average order value by 6%.",
                    "Optimized feature pipelines using Spark, reducing nightly ETL runtime from 3 hours to 45 minutes.",
                    "Implemented offline evaluation pipelines and online A/B testing framework to ensure robust model selection and safe rollouts.",
                    "Collaborated with frontend and data engineering teams to integrate personalized features into web and mobile channels."
                ]
            },
            {
                "name": "ML Research Intern, DataLab Research",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Researched sequence models for time-series forecasting and produced a technical report on hybrid RNN-gradient boosting approaches.",
                    "Prototype code contributed to open-source evaluation notebooks and internal reproducible pipelines."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Demand Forecasting Platform",
                "description": "End-to-end forecasting platform delivering per-SKU, per-store demand predictions with automated retraining, monitoring, and alerting. Integrated feature store, batch and streaming inference, and dashboarding for business users.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Spark",
                    "Kafka",
                    "Docker",
                    "Kubernetes",
                    "Airflow"
                ],
                "year": 2022
            },
            {
                "name": "Clinical Risk Dashboard with Explainability",
                "description": "Built patient risk models and integrated SHAP explanations into a clinician-facing dashboard to drive prioritized outreach and care planning.",
                "technologies": [
                    "Python",
                    "LightGBM",
                    "Flask",
                    "React",
                    "SHAP",
                    "PostgreSQL"
                ],
                "year": 2019
            },
            {
                "name": "Personalized Recommendation Engine",
                "description": "Developed a hybrid recommendation engine combining matrix factorization and neural embeddings to personalize product suggestions across web and mobile, improving engagement metrics.",
                "technologies": [
                    "TensorFlow",
                    "Spark",
                    "HBase",
                    "AWS"
                ],
                "year": 2017
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign",
                "date": {
                    "start": 2008,
                    "end": 2012
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "TensorFlow",
            "PyTorch",
            "XGBoost",
            "LightGBM",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLOps",
            "Model monitoring",
            "Experimentation / A/B testing",
            "Model explainability (SHAP/LIME)",
            "Time-series forecasting",
            "NLP"
        ],
        "achievements": [
            "Led ML initiatives that generated $3M+ incremental ARR through product features and automation.",
            "Reduced inference latency by 40% and model deployment time by ~70% through CI/CD and containerization.",
            "Mentored 6+ junior data scientists and interns; established team best practices for reproducible modeling and code reviews."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2020
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2019
            },
            {
                "name": "Certified ScrumMaster (CSM)",
                "date": 2017
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, evidence-driven, mentorship-focused; values cross-functional communication and rigorous testing in production.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Based in SF Bay Area; open to relocation within the U.S."
            },
            "phone": "+1 (415) 555-0123",
            "email": "maya.patel.datasci@example.com",
            "linkedin": "https://www.linkedin.com/in/mayapatel-ds",
            "github": "https://github.com/mayapatel"
        },
        "summary": "Data scientist with 9+ years of experience designing and shipping machine learning solutions in healthcare and retail. Strong background in applied deep learning, time-series forecasting, and MLOps\u2014focused on production reliability, interpretable models, and measurable business impact. Proven track record mentoring teams and partnering with product and engineering to deliver scalable systems.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Aurora Health AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of an EHR-based readmission prediction model (NLP + structured features) that improved early-warning detection AUC by 0.07 and reduced 30-day readmissions in pilot hospitals.",
                    "Implemented model distillation and quantization to cut inference latency 4x and reduce serving cost by 60% while preserving performance.",
                    "Built CI/CD pipelines for models and data validation (Airflow, MLflow, Docker), enabling weekly safe model updates with automated regression tests.",
                    "Established monitoring dashboards (Prometheus, Grafana) and concept-drift alerts; reduced incident MTTR by 45%.",
                    "Mentored 4 junior data scientists and ran monthly brown-bag sessions on uncertainty estimation and production best practices."
                ]
            },
            {
                "name": "Data Scientist \u2014 Glide Retail",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed hybrid statistical + deep learning demand-forecasting models that increased forecast accuracy by 18% and reduced stockouts for top SKUs.",
                    "Designed a feature store and standardized feature computation pipelines (Airflow, Spark) to accelerate model development and reuse across teams.",
                    "Led A/B tests for pricing and promotion models; quantified uplift and recommended rollout strategies used company-wide.",
                    "Collaborated with engineering to productionize TensorFlow models using Kubernetes and TF Serving."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 OpenEdge Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built end-to-end ML pipelines for real-time analytics using Kafka, Spark Streaming, and Flask-based model serving.",
                    "Implemented automated data labeling workflows and optimized feature engineering, reducing training time by 35%.",
                    "Packaged models in Docker and deployed to Kubernetes clusters with monitoring and rolling updates."
                ]
            }
        ],
        "projects": [
            {
                "name": "EHR Readmission Predictor",
                "description": "Multi-modal model combining clinical notes (BERT) and structured features to predict 30-day readmission risk. Focused on interpretability (SHAP) and safe deployment in clinical settings.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Hugging Face Transformers",
                    "scikit-learn",
                    "FastAPI",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "Retail Demand Forecasting Platform",
                "description": "Scalable forecasting pipeline for SKU-level demand using time-series models and LSTM ensembles; integrated into inventory management to reduce stockouts.",
                "technologies": [
                    "TensorFlow",
                    "Prophet",
                    "Spark",
                    "AWS S3",
                    "Airflow"
                ],
                "year": 2020
            },
            {
                "name": "Real-time Anomaly Detection",
                "description": "Streaming anomaly detection system for transaction and telemetry data using Spark Streaming + isolation forests with alerting and automated triage.",
                "technologies": [
                    "Kafka",
                    "Spark Streaming",
                    "scikit-learn",
                    "Flask",
                    "Prometheus"
                ],
                "year": 2019
            },
            {
                "name": "Feature Store & Model Monitoring",
                "description": "Designed and implemented a centralized feature store (Feast) and monitoring stack (Prometheus/Grafana) to ensure feature consistency and model health in production.",
                "technologies": [
                    "Feast",
                    "Airflow",
                    "Prometheus",
                    "Grafana",
                    "Kubernetes"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S., Computer Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign \u2014 B.S., Electrical Engineering",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Electrical Engineering"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "MLOps",
            "Docker",
            "Kubernetes",
            "Airflow",
            "Feature Engineering",
            "Time Series Forecasting",
            "NLP",
            "Causal Inference",
            "Experimentation",
            "AWS",
            "GCP",
            "Snowflake"
        ],
        "achievements": [
            "Published workshop paper on clinical NLP at NeurIPS 2021",
            "Led model initiative that contributed to $4M incremental ARR through improved clinical decision support",
            "Reduced model-serving cost by 60% through distillation and optimized infra",
            "Recipient, Aurora Health AI 'Impact Award' (2022)"
        ],
        "certifications": [
            {
                "name": "Google Professional Data Engineer",
                "date": 2023
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven environment that values mentorship, reproducibility, and measurable business impact.",
        "contact": {
            "address": {
                "region": "Vancouver, Canada",
                "detail": "Gastown, Vancouver, BC"
            },
            "phone": "+1-604-555-0198",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aishar-ml"
        },
        "summary": "Data Scientist with 9+ years of experience building and shipping ML systems for healthcare and retail. Strong background in production ML, time series forecasting, causal inference, and MLOps. Proven track record of improving model performance and operational efficiency through robust feature engineering, scalable pipelines, and cross-functional collaboration.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 NexGen Health Analytics",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led a team of 4 data scientists to develop clinical risk-prediction models used by partner hospitals; production model reduced 30-day readmission rates by 12% (AUC improvement from 0.74 to 0.82).",
                    "Designed and implemented real-time inference pipeline using Kafka, Docker, and AWS Lambda, reducing prediction latency from 450ms to 120ms.",
                    "Established MLOps practices with MLflow and Terraform, enabling reproducible training, automated model registry, and CI/CD for model deployments.",
                    "Led A/B testing and monitoring framework (Prometheus + Grafana) for drift detection and automated rollback policies."
                ]
            },
            {
                "name": "Data Scientist \u2014 ClearSight Retail",
                "date": {
                    "start": 2018,
                    "end": 2022
                },
                "bullets": [
                    "Built hierarchical demand-forecasting system (Prophet + XGBoost ensemble) for 1,200+ SKUs, improving forecast accuracy by 28% and reducing stockouts by 18%.",
                    "Developed uplift models and personalized promotion strategies that increased campaign ROI by 22% and incremental sales by $3.1M/year.",
                    "Owned end-to-end ETL and feature-pipeline using Airflow and Spark; designed feature store to accelerate cross-team experimentation.",
                    "Mentored 3 junior data scientists and ran monthly technical brown-bag sessions on causal inference and time-series best practices."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 OpenGrid Energy",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed short-term load forecasting models (LSTM and gradient-boosted trees) that improved grid balancing prediction accuracy by 20%.",
                    "Implemented distributed training workflows with Horovod and Kubernetes; reduced model training time from 6 hours to 40 minutes.",
                    "Collaborated with data engineering to design incremental data pipelines and automated model retraining schedules."
                ]
            },
            {
                "name": "Research Assistant \u2014 UBC Machine Learning Lab",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Conducted research on interpretable ML methods for healthcare; contributed to a conference paper on feature-attribution techniques.",
                    "Prototyped experiments in PyTorch and scikit-learn, and assisted in dataset curation and experimental reproducibility."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Sepsis Early Warning System",
                "description": "End-to-end pipeline for early detection of sepsis from streaming EHR data, combining temporal feature engineering and a calibrated ensemble model deployed to production with automated alerts.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Kafka",
                    "Docker",
                    "AWS (EKS, Lambda)"
                ],
                "year": 2024
            },
            {
                "name": "Global Demand Forecasting Platform",
                "description": "Scalable forecasting platform supporting multiple time horizons and hierarchies; incorporated probabilistic forecasts and automated backtesting for continuous model selection.",
                "technologies": [
                    "Spark",
                    "XGBoost",
                    "Prophet",
                    "Airflow",
                    "MLflow"
                ],
                "year": 2021
            },
            {
                "name": "Open-source Feature Store Connector",
                "description": "Contributed connector and examples for a popular feature store enabling consistent feature retrieval and offline-online parity across teams.",
                "technologies": [
                    "Python",
                    "Redis",
                    "Postgres"
                ],
                "year": 2020
            },
            {
                "name": "Causal Uplift Modeling Toolkit",
                "description": "Toolkit to estimate treatment effect heterogeneity for marketing campaigns; includes reweighting, doubly-robust estimators, and uplift tree implementation.",
                "technologies": [
                    "R",
                    "scikit-learn",
                    "CausalForest"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of British Columbia",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Computer Science (Machine Learning)"
            },
            {
                "name": "University of Dhaka",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "R",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "MLflow",
            "Kubeflow",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Feature Engineering",
            "Time Series",
            "Causal Inference",
            "Experimentation & A/B Testing",
            "Model Monitoring"
        ],
        "achievements": [
            "Published peer-reviewed paper on interpretable ML methods for clinical decision support (ICML workshop, 2017).",
            "Reduced model inference cost by 45% through model quantization and endpoint consolidation at NexGen Health Analytics.",
            "Led a cross-functional initiative that delivered $3.1M in incremental yearly revenue through targeted uplift campaigns.",
            "Maintainer and contributor to two open-source ML tooling projects with 500+ stars combined."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya Thompson",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented team that values rigorous experimentation, code review, and clear communication. Prefers cross-functional pairing with product and engineering.",
        "contact": {
            "address": {
                "region": "California, USA",
                "detail": "San Francisco Bay Area"
            },
            "phone": "+1-415-555-0123",
            "email": "maya.thompson@example.com",
            "linkedin": "https://www.linkedin.com/in/mayathompson",
            "github": "https://github.com/mayathompson"
        },
        "summary": "AI Engineer with 9+ years building production ML systems and applied research for recommendation, computer vision, and time-series forecasting. Skilled in end-to-end model development, scalable data pipelines, and deploying ML services to cloud infrastructure. Strong emphasis on reproducible code, monitoring, and measurable business impact.",
        "experience": [
            {
                "name": "Arcadia AI \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a hybrid recommender combining deep learning and graph features, improving click-through rate by 17% and increasing weekly active users by 9%.",
                    "Built scalable inference pipelines (TF Serving & TorchServe) on Kubernetes with canary deploys and A/B testing; reduced model rollout time from 2 weeks to 48 hours.",
                    "Implemented monitoring and alerting for model drift and data quality using Prometheus and Great Expectations, preventing production degradation after two data-source changes.",
                    "Mentored 4 ML engineers, instituted unit testing for model components and CI for training reproducibility."
                ]
            },
            {
                "name": "Nimbus Health \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed time-series forecasting models for patient volume using LSTM and XGBoost ensembles, reducing scheduling shortfalls by 22%.",
                    "Architected ETL pipelines on Airflow and BigQuery to process streaming telemetry and EHR-derived features, cutting daily job runtime by 60%.",
                    "Collaborated with clinicians to translate model outputs into actionable alerts; led validation studies and documented model limitations for regulatory review.",
                    "Optimized inference latency via model quantization and pruning, enabling on-edge deployment for decentralized clinics."
                ]
            },
            {
                "name": "BrightData Labs \u2014 Data Scientist",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Designed computer vision pipelines for document parsing using OpenCV and CNNs; achieved 95% field extraction accuracy versus previous 78%.",
                    "Performed feature engineering and model selection for customer segmentation, increasing campaign conversion by 12%.",
                    "Automated reporting and dashboards in Looker to surface KPI trends and model performance to stakeholders."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Personalization Engine",
                "description": "End-to-end personalization service that scored and ranked content in real time using a hybrid model (deep & feature-based), integrated with streaming user events and a low-latency feature store.",
                "technologies": [
                    "TensorFlow",
                    "Redis",
                    "Kafka",
                    "Kubernetes",
                    "Go"
                ],
                "year": 2022
            },
            {
                "name": "Clinic Forecast Toolkit",
                "description": "Toolkit for short- and medium-term patient volume forecasting with a model selection dashboard, ensembling LSTM and gradient-boosted trees and automatic backtesting.",
                "technologies": [
                    "PyTorch",
                    "XGBoost",
                    "Airflow",
                    "BigQuery",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Document OCR & Field Extraction",
                "description": "Pipeline combining classical image processing and CNN-based OCR to extract structured fields from scanned forms with post-processing validation rules.",
                "technologies": [
                    "OpenCV",
                    "Tesseract",
                    "scikit-learn",
                    "AWS Lambda"
                ],
                "year": 2017
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Machine Learning)"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Applied Mathematics"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "SQL",
            "BigQuery",
            "Kafka",
            "Kubernetes",
            "Docker",
            "MLflow",
            "Feature stores",
            "Model monitoring",
            "A/B testing",
            "Cloud (AWS, GCP)"
        ],
        "achievements": [
            "Drove a product recommendation lift of 17% CTR at Arcadia AI through a hybrid model and feature store integration.",
            "Reduced scheduling shortfalls by 22% at Nimbus Health via improved forecasting models.",
            "Published internal reproducible training pipelines and CI practices adopted across three engineering teams."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, inclusive \u2014 values mentorship, cross-functional partnership, and measurable impact",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0136",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 8+ years building and shipping machine learning systems for forecasting, personalization, and healthcare analytics. Strong track record deploying models to production, reducing error and latency, and translating business requirements into robust, monitored solutions. Experienced mentoring teams and leading cross-functional initiatives.",
        "experience": [
            {
                "name": "Senior Data Scientist, OptiSense AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end delivery of a demand-forecasting pipeline (time-series + probabilistic models) serving weekly forecasts for 200+ SKUs; reduced MAPE by 28% vs previous baseline.",
                    "Designed and deployed model-serving stack using Docker, Kubernetes, MLflow and AWS SageMaker, achieving <150ms inference latency and 99.9% availability.",
                    "Implemented automated model monitoring (data drift, concept drift) and alerting, reducing model degradation incidents by 60%.",
                    "Coached and mentored a team of 4 junior data scientists; introduced standardized notebook-to-production templates and code review practices."
                ]
            },
            {
                "name": "Data Scientist, ClearWave Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built clinical-risk prediction models using EHR data (XGBoost, deep learning) to identify patients at high readmission risk; improved early-intervention triage precision by 22%.",
                    "Collaborated with clinicians and data engineers to create reproducible feature engineering pipelines using Airflow and Spark.",
                    "Performed causal impact analyses to evaluate new care pathways; findings directly influenced pilot rollout and resource allocation.",
                    "Presented results to executive and clinical stakeholders; created interactive dashboards in Tableau for operational teams."
                ]
            },
            {
                "name": "Data Analyst, CivicPulse",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed analytics and A/B testing frameworks for civic engagement products; standardized experiment metrics and analysis templates.",
                    "Built ETL pipelines and SQL models to synthesize disparate data sources, reducing monthly reporting time from 4 days to 1 day.",
                    "Worked closely with product and outreach teams to define KPIs and translate insights into feature prioritization."
                ]
            },
            {
                "name": "Research Intern, UC Berkeley AI Lab",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Conducted research on sequence modeling for irregularly sampled clinical time series; co-authored a workshop paper and open-sourced preprocessing code.",
                    "Explored attention-based architectures and time-embedding techniques for improved interpretability."
                ]
            }
        ],
        "projects": [
            {
                "name": "Probabilistic Inventory Forecasting",
                "description": "Built and deployed probabilistic forecasting models (DeepAR + Prophet ensembles) for SKU-level weekly demand forecasts with uncertainty bands, feeding downstream replenishment optimization.",
                "technologies": [
                    "Python",
                    "GluonTS",
                    "Prophet",
                    "AWS SageMaker",
                    "Docker",
                    "Kubernetes",
                    "MLflow"
                ],
                "year": 2024
            },
            {
                "name": "Clinical Readmission Risk Model",
                "description": "End-to-end model to predict 30-day hospital readmission using EHR features; included feature store integration, model explainability (SHAP), and clinician-facing dashboards.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Spark",
                    "Tableau",
                    "Airflow"
                ],
                "year": 2020
            },
            {
                "name": "Real-time Personalization Engine (Pilot)",
                "description": "Prototype for personalized content ranking using light-weight embedding models and online feature stores to improve engagement in low-latency environments.",
                "technologies": [
                    "PyTorch",
                    "Redis",
                    "Kafka",
                    "Docker"
                ],
                "year": 2019
            },
            {
                "name": "Time-series Imputation Library",
                "description": "Open-source utilities for imputing irregular clinical time series using interpolation and learned models; used in internal research and shared with the community.",
                "technologies": [
                    "Python",
                    "pandas",
                    "numpy"
                ],
                "year": 2016
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S., Computer Science (Data Science focus)",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign \u2014 B.S., Statistics & Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Statistics & Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "numpy",
            "Spark",
            "Airflow",
            "Kafka",
            "Docker",
            "Kubernetes",
            "MLflow",
            "AWS",
            "GCP",
            "Tableau",
            "Time Series",
            "Causal Inference",
            "Experimentation",
            "Model Monitoring"
        ],
        "achievements": [
            "Reduced demand-forecasting MAPE by 28% at OptiSense AI leading to a 12% reduction in stockouts during peak season.",
            "Cut monthly reporting time from 4 days to 1 day at CivicPulse by building automated ETL and reporting pipelines.",
            "Authored an open-source time-series imputation library used in multiple clinical research projects.",
            "Mentored 4 junior data scientists; two promoted to mid-level roles within 12 months."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified ScrumMaster (CSM)",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya R. Kapoor",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that prioritize experimentation, production-grade engineering, mentorship, and clear impact metrics. Prefers inclusive environments with cross-functional communication and strong emphasis on reproducibility and MLOps.",
        "contact": {
            "address": {
                "region": "California, USA",
                "detail": "San Francisco Bay Area"
            },
            "phone": "+1-415-555-0142",
            "email": "maya.kapoor@example.com",
            "linkedin": "https://linkedin.com/in/mayarkapoor",
            "github": "https://github.com/mayarkapoor"
        },
        "summary": "Data Scientist with 7+ years of experience building and deploying machine learning systems for e-commerce and healthcare. Strong background in forecasting, recommendation systems, causal inference, and production MLOps. Experienced in leading small teams, translating business problems into measurable models, and delivering scalable solutions that reduce cost and improve user engagement.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nimbus Analytics",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development and deployment of a churn-prediction pipeline (XGBoost + MLflow) that reduced voluntary churn by 12% and increased 12-month retention revenue by an estimated $3.1M.",
                    "Designed and owned feature store and CI/CD for models using Docker, Kubernetes, and GitHub Actions, cutting model release time from weeks to days.",
                    "Collaborated with product and engineering to roll out personalized lifecycle campaigns; A/B tests showed a 9% lift in retention for targeted cohorts.",
                    "Mentored 3 junior data scientists; instituted code review and unit-testing standards for model reproducibility."
                ]
            },
            {
                "name": "Data Scientist, Polaris Retail",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Built demand-forecasting models (hierarchical time series + Prophet ensemble) that improved forecast accuracy by 18%, enabling inventory reductions that saved ~$2M annually.",
                    "Developed uplift models to optimize promotional spend, increasing campaign ROI by 23%.",
                    "Implemented ETL pipelines in Airflow and optimized SQL data pipelines to reduce data latency from 24h to 2h.",
                    "Presented model findings to leadership and translated outputs into operational strategies for supply chain and merchandising teams."
                ]
            },
            {
                "name": "Machine Learning Engineer (contract), Horizon Health",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Prototyped clinical risk scoring models using EHR data; ensured HIPAA-compliant pipelines and data governance.",
                    "Built a triage-prioritization classifier that improved early-detection rates for high-risk patients by 14%.",
                    "Collaborated with clinicians to define evaluation metrics and deployed models to a secure serving environment using Docker and REST APIs."
                ]
            }
        ],
        "projects": [
            {
                "name": "Customer Churn Predictor",
                "description": "Production-ready churn prediction service with feature engineering, explainability, and automated retraining. Served predictions via REST API and integrated with marketing triggers.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "MLflow",
                    "Docker",
                    "AWS (S3, ECS)"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Streaming recommendation pipeline that combined collaborative filtering and content signals to deliver personalized recommendations with sub-second latency.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "TensorFlow",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2021
            },
            {
                "name": "Automated A/B Analysis Toolkit",
                "description": "Toolbox for standardized experiment analysis using frequentist and Bayesian approaches, automating significance checks, power calculations, and reporting.",
                "technologies": [
                    "R",
                    "Python",
                    "PyMC3",
                    "SQL",
                    "Git"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Michigan",
                "date": {
                    "start": 2013,
                    "end": 2017
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "R",
            "SQL",
            "Machine Learning",
            "Deep Learning",
            "Time Series Forecasting",
            "Causal Inference",
            "Feature Engineering",
            "MLOps (MLflow, Airflow, Docker, Kubernetes)",
            "AWS",
            "Spark",
            "Experimentation / A/B Testing",
            "Data Visualization"
        ],
        "achievements": [
            "Reduced annual operational costs by ~$2M through improved demand forecasting.",
            "Presented 'Scalable Churn Modeling' at Strata Data 2023.",
            "Maintainer of an open-source forecasting utilities library with 600+ stars.",
            "Published a peer-reviewed paper on hierarchical time-series forecasting (2020)."
        ],
        "certifications": [
            {
                "name": "Google Professional Data Engineer",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Jordan Rivera",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, experimentation-first culture with strong emphasis on mentorship, reproducibility, and measurable business impact.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "SoMa \u2014 near Oracle Park"
            },
            "phone": "+1-415-555-0182",
            "email": "jordan.rivera@example.com",
            "linkedin": "https://www.linkedin.com/in/jordan-rivera-ds",
            "github": "https://github.com/jordanrivera-ds"
        },
        "summary": "Data Scientist with 7+ years building production ML systems and analytics that drive product and operational decisions. Experienced across the ML lifecycle: problem framing, feature engineering, experimentation, model deployment, and monitoring. Strong background in healthcare analytics and personalization, with proven impact on revenue, engagement, and operational efficiency.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 NovaHealth",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led cross-functional initiative to build a risk-stratification model for chronic care management, increasing high-risk patient outreach efficiency by 38% and reducing 30-day readmission risk by 12%.",
                    "Designed and deployed a patient-level propensity model in production (TF + Docker + Kubernetes) serving 100k+ predictions/day with A/B-tested lift of +7% in targeted interventions.",
                    "Implemented feature store (Feast) integrations and CI/CD pipelines, reducing model deployment time from weeks to days and enabling reproducible experiments.",
                    "Mentored 4 junior data scientists and established team best practices for model evaluation, fairness checks, and production monitoring (Prometheus + Grafana)."
                ]
            },
            {
                "name": "Data Scientist \u2014 OptiTrack (ad-tech personalization)",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed real-time recommendation and bidding models that increased click-through-rate by 18% and improved ad revenue per mille (RPM) by 14%.",
                    "Built attribution models combining probabilistic and deterministic signals, improving campaign conversion measurement accuracy by 22%.",
                    "Optimized feature pipelines with Spark and Airflow, cutting daily ETL runtime by 60% and lowering infrastructure costs by 25%.",
                    "Collaborated with product and engineering to A/B test personalization features, driving a 9% uplift in retention among targeted cohorts."
                ]
            },
            {
                "name": "Machine Learning Engineer (Intern) \u2014 EdgeLabs",
                "date": {
                    "start": 2018,
                    "end": 2019
                },
                "bullets": [
                    "Implemented object detection prototype using YOLOv3 and custom augmentation, achieving 85% mAP on internal dataset for edge deployment.",
                    "Converted research models to TensorFlow Lite, enabling on-device inference with sub-150ms latency on target hardware.",
                    "Produced reproducible experiment notebooks and contributed to model benchmark suite used by engineering teams."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Clinical Deterioration Predictor",
                "description": "Production-grade model predicting patient deterioration within 48 hours using EHR time-series, vitals, and labs. Includes online inference API, drift detection, and clinician-facing explanations.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Kafka",
                    "Docker",
                    "Feast",
                    "SHAP"
                ],
                "year": 2024
            },
            {
                "name": "Personalized Content Ranking System",
                "description": "End-to-end personalization pipeline combining collaborative filtering and contextual bandits to optimize content ranking for engagement and lifetime value.",
                "technologies": [
                    "PyTorch",
                    "AWS Sagemaker",
                    "Airflow",
                    "Spark",
                    "Postgres"
                ],
                "year": 2021
            },
            {
                "name": "Cohort-based A/B Testing Platform",
                "description": "Built a lightweight experimentation platform to support feature flagging and cohort experiments with automated metric tracking and sample size calculators.",
                "technologies": [
                    "Python",
                    "Flask",
                    "Redis",
                    "Pandas",
                    "Grafana"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 Master of Information and Data Science",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "San Diego State University",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "Machine Learning",
            "Causal Inference",
            "Feature Engineering",
            "MLOps",
            "Docker",
            "Kubernetes",
            "Spark",
            "Airflow",
            "Experimentation / A/B testing",
            "Statistics"
        ],
        "achievements": [
            "Reduced data pipeline costs by 25% through optimization and migration to spot instances.",
            "Authored internal playbook for model validation and fairness checks adopted across two product teams.",
            "Presented work on patient risk modeling at the 2023 Healthcare AI Summit.",
            "Mentored interns who moved into full-time data science roles within the company."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Databricks Certified Associate Developer for Apache Spark",
                "date": 2021
            }
        ],
        "total_experience": 7,
        "availability": true
    },
    {
        "name": "Aisha K. Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented, feedback-driven; values cross-functional partnership and reproducible, production-ready ML.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Capitol Hill"
            },
            "phone": "+1-206-555-0143",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aishakrahman",
            "github": "https://github.com/aishak-ml"
        },
        "summary": "Data scientist with 6+ years building and deploying ML models for user behavior, personalization, and operational analytics. Strong background in statistical modeling, feature engineering, and production ML pipelines. Experienced working cross-functionally to translate business problems into measurable models and deliver scalable, maintainable solutions.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Northwind Analytics (product & personalization)",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end personalization initiative that increased click-through rate by 18% and revenue per user by 9% by deploying a hybrid ranking model (GBM + lightweight neural embedding).",
                    "Designed and implemented A/B testing framework and instrumentation to validate model impact; reduced experiment rollout time from 6 weeks to 2 weeks.",
                    "Built feature store components and CI/CD pipelines (Airflow + Terraform) enabling reproducible training and automated model retraining schedules.",
                    "Mentored two junior data scientists and established model evaluation guidelines (calibration, fairness checks, drift monitoring)."
                ]
            },
            {
                "name": "Data Scientist \u2014 BrightCore Health",
                "date": {
                    "start": 2019,
                    "end": 2021
                },
                "bullets": [
                    "Developed risk stratification models (XGBoost, Logistic Regression) for patient readmission prediction with 0.82 AUC, enabling targeted intervention programs.",
                    "Collaborated with product and engineering to deploy containerized prediction service on AWS Lambda and ECS; latency < 150ms for inference requests.",
                    "Automated ETL and data quality checks using dbt, reducing upstream data issues by 65% and increasing model retraining reliability.",
                    "Presented model results and business cases to clinical stakeholders; translated statistical outputs into actionable clinical workflows."
                ]
            },
            {
                "name": "Data Analyst \u2014 GreenStream Media (intern \u2192 full-time)",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Built dashboards and cohort analyses to inform content strategy; recommended optimizations that improved 30-day retention by 7%.",
                    "Performed A/B test analysis and causal inference using regression adjustment and bootstrapping to provide robust experiment insights.",
                    "Implemented ETL pipelines in Python and SQL to centralize event data, reducing ad-hoc analysis time by 40%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Personalization Ranking System",
                "description": "End-to-end hybrid ranking system combining gradient-boosted trees for coarse ranking and neural embeddings for item-user similarity; integrated into production with monitoring and automated retraining.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "PyTorch",
                    "Airflow",
                    "Docker",
                    "Postgres"
                ],
                "year": 2023
            },
            {
                "name": "Patient Readmission Risk Dashboard",
                "description": "Interactive clinician-facing dashboard showing readmission risk, key contributing features, and suggested interventions; included model interpretability (SHAP) and uncertainty visualization.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "SHAP",
                    "Tableau",
                    "AWS"
                ],
                "year": 2020
            },
            {
                "name": "Real-time Feature Store Prototype",
                "description": "Prototype feature store for low-latency online features using Redis and Kafka, with API for consistent feature retrieval in training and serving.",
                "technologies": [
                    "Kafka",
                    "Redis",
                    "FastAPI",
                    "Terraform"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2013,
                    "end": 2017
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "PyTorch",
            "XGBoost",
            "Model deployment",
            "Feature engineering",
            "A/B testing",
            "Data pipeline design (Airflow, dbt)",
            "Cloud (AWS)",
            "Docker & Kubernetes",
            "Experiment design",
            "Model monitoring"
        ],
        "achievements": [
            "Improved personalization CTR by 18% and revenue per user by 9% through a deployed ranking system.",
            "Published internal tech talk and workshop on productionizing ML workflows and feature stores.",
            "Reduced model rollout time by 66% by creating CI/CD pipelines for model training and serving."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Morgan Ellis",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven environment focused on measurable impact, cross-functional mentorship, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "123 Market St, Apt 45"
            },
            "phone": "+1-415-555-0137",
            "email": "morgan.ellis.datasci@example.com",
            "linkedin": "https://www.linkedin.com/in/morgan-ellis-ds",
            "github": "https://github.com/morganellis"
        },
        "summary": "Data scientist with 9+ years building production ML systems and analytics platforms for retail and healthcare. I combine rigorous statistical modeling, software engineering best practices, and stakeholder-focused product thinking to deliver scalable, measurable outcomes. Strong background in time-series forecasting, causal inference, and MLOps.",
        "experience": [
            {
                "name": "Senior Data Scientist, Veridian Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a readmissions risk model integrated into EHR workflow \u2014 reduced 30-day readmissions by 14% across pilot hospitals.",
                    "Built causal evaluation pipelines (difference-in-differences + propensity modeling) to quantify impact of care-path changes, guiding $2.1M in operational investments.",
                    "Architected model serving and monitoring on AWS (SageMaker + Lambda + CloudWatch) and Airflow, reducing model rollback time from days to under 2 hours.",
                    "Mentored 4 junior data scientists and introduced code review + CI/CD for model artifacts, improving reproducibility and accelerating delivery."
                ]
            },
            {
                "name": "Data Scientist, Nova Retail",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed demand forecasting models (hierarchical probabilistic forecasts + XGBoost) that improved inventory turnover by 12% and decreased stockouts by 18%.",
                    "Built a personalized promotions recommender using matrix factorization and contextual boosting; A/B tests showed a 7.5% uplift in incremental revenue.",
                    "Collaborated with engineering to productionize real-time scoring via Kafka + Spark Streaming, enabling personalized offers at checkout with <200ms latency.",
                    "Established data quality checks and monitoring dashboards in Tableau and Great Expectations to maintain pipeline reliability across 50+ data sources."
                ]
            },
            {
                "name": "Data Analyst, Bright Metrics",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "bullets": [
                    "Delivered weekly KPIs and automated ETL pipelines (Python + Airflow) that reduced manual reporting time by 70%.",
                    "Conducted cohort analyses and customer segmentation that informed pricing experiments and retention programs.",
                    "Implemented SQL-driven event tracking and attribution models to better measure channel ROI and optimize marketing spend."
                ]
            }
        ],
        "projects": [
            {
                "name": "ChurnPredict",
                "description": "End-to-end churn prediction system for subscription product combining survival analysis, gradient-boosted trees, and automated feature pipelines to prioritize retention campaigns.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "pandas",
                    "Airflow",
                    "Docker",
                    "Postgres"
                ],
                "year": 2020
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Low-latency recommendations using online embeddings and a hybrid candidate generation + ranking architecture served via Kafka and Spark Streaming.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "PyTorch",
                    "Redis",
                    "Kubernetes"
                ],
                "year": 2019
            },
            {
                "name": "Automated Data Quality Platform",
                "description": "Platform for automated data validation, anomaly detection, and alerting that integrated Great Expectations rules with monitoring dashboards to catch pipeline regressions.",
                "technologies": [
                    "Great Expectations",
                    "Airflow",
                    "Python",
                    "Tableau",
                    "AWS"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "R",
            "SQL",
            "pandas",
            "numpy",
            "scikit-learn",
            "XGBoost",
            "PyTorch",
            "TensorFlow",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Tableau",
            "Great Expectations",
            "MLOps",
            "Time-series forecasting",
            "Causal inference"
        ],
        "achievements": [
            "Reduced 30-day hospital readmissions by 14% in a multi-hospital pilot through targeted risk modeling and care-path optimization.",
            "Improved retail inventory turnover by 12% via hierarchical demand forecasting models deployed in production.",
            "Authored an internal MLOps playbook adopted across three product teams to standardize model deployment and monitoring.",
            "Presented work on probabilistic forecasting at an industry meetup (2021) and contributed to open-source forecasting utilities."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (CDS)",
                "date": 2019
            },
            {
                "name": "AWS Certified Data Analytics \u2013 Specialty",
                "date": 2023
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and outcome-focused. Prefers teams that value experimentation, mentorship, transparent feedback, and production-aware ML practices.",
        "contact": {
            "address": {
                "region": "London, UK",
                "detail": "Camden, NW1"
            },
            "phone": "+44 7700 900123",
            "email": "maya.patel.ds@gmail.com",
            "linkedin": "linkedin.com/in/maya-patel-ds",
            "github": "github.com/mayapatel-ds"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems, conducting causal analysis, and delivering data-driven product improvements across healthcare and finance. Strong background in statistical modeling, feature engineering, and MLOps; skilled at translating business questions into scalable models and instrumentation.",
        "experience": [
            {
                "name": "Senior Data Scientist, Orion Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development and deployment of a patient-risk stratification model that improved early-intervention triage precision by 27% and reduced 30-day readmissions by 12%.",
                    "Designed robust feature pipelines using dbt and Spark; reduced model training time by 45% via feature-store reuse and optimized data partitioning.",
                    "Implemented CI/CD for models using MLflow and GitHub Actions; introduced automated performance monitoring and drift alerts to production.",
                    "Mentored a team of three data scientists and established best practices for model documentation, interpretability (SHAP) and fairness testing."
                ]
            },
            {
                "name": "Data Scientist, Astra Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built predictive models for resource allocation that decreased average patient wait time by 18% and cut operational costs by 9%.",
                    "Conducted causal impact analyses for program pilots using Bayesian structural time series and difference-in-differences methodologies.",
                    "Partnered with product and engineering to productionize scoring pipelines on AWS SageMaker; authored runbooks and automated retraining schedules."
                ]
            },
            {
                "name": "Data Analyst, MetroBank",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Developed credit risk segmentation and customer churn models using logistic regression and gradient boosting; improved early-warning precision by 22%.",
                    "Automated monthly reporting and dashboards in Tableau and Looker, reducing reporting time from 5 days to under 8 hours.",
                    "Led A/B experiments and uplift modeling for onboarding flows, contributing to a 7% lift in activation rate."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Anomaly Detection Platform",
                "description": "Built a streaming anomaly detection system for transaction and sensor data using Kafka, Spark Structured Streaming, and an ensemble of statistical and ML detectors. Integrated alerting and root-cause tagging to reduce mean time to detection.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "Python",
                    "Prometheus",
                    "Grafana"
                ],
                "year": 2024
            },
            {
                "name": "Explainable Patient Risk Model",
                "description": "Developed an explainable XGBoost model augmented with SHAP summaries and counterfactual explanations to support clinical decision-making. Packaged as a microservice with explainability endpoints.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "SHAP",
                    "Flask",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Churn Uplift Modeling",
                "description": "Created uplift models to target retention campaigns, increasing campaign ROI by 35% by focusing offers on high-uplift cohorts and reducing wasted spend.",
                "technologies": [
                    "R",
                    "scikit-learn",
                    "SQL",
                    "Airflow"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of Edinburgh",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "MSc Data Science"
            },
            {
                "name": "University of Manchester",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "BSc Mathematics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "XGBoost",
            "Deep Learning (PyTorch)",
            "MLOps (MLflow, SageMaker)",
            "Spark",
            "Docker",
            "Airflow",
            "Feature Engineering",
            "A/B Testing",
            "Causal Inference",
            "Data Visualization"
        ],
        "achievements": [
            "Delivered a production risk model that contributed to a 12% reduction in 30-day readmissions (Orion Analytics).",
            "Reduced model training time by 45% through pipeline optimization and feature-store reuse.",
            "Published an internal whitepaper on fairness-aware modeling and mitigations adopted company-wide.",
            "Mentored junior data scientists; two promoted to mid-level roles within 12 months."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (DASCA)",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Riya Kapoor",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-minded team that values reproducibility, clear documentation, and continuous delivery of impactful ML products.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala, Bengaluru"
            },
            "phone": "+91-9876543210",
            "email": "riya.kapoor@example.com",
            "linkedin": "https://www.linkedin.com/in/riya-kapoor-ai",
            "github": "https://github.com/riyakapoor69"
        },
        "summary": "AI Engineer with 7+ years building and shipping production ML systems across healthcare and enterprise SaaS. Strong background in deep learning, model optimization for latency-constrained deployments, and MLOps (CI/CD, monitoring, model governance). Experienced in end-to-end delivery from data pipelines and experimentation to scalable deployment and post-deployment monitoring.",
        "experience": [
            {
                "name": "Senior AI Engineer, Intellify Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of a multimodal recommendation system servicing 10M+ monthly users; improved click-through rate by 18% and reduced inference latency by 40% through model distillation and pruning.",
                    "Built end-to-end MLOps pipelines using Kubeflow and Argo Workflows for automated training, validation, and canary deployment; cut model release time from weeks to 48 hours.",
                    "Implemented feature-store integrations and drift-detection dashboards (Prometheus + Grafana) to monitor data and model quality in production.",
                    "Mentored a team of 4 ML engineers and instituted reproducible experiment tracking with MLflow, increasing model iteration velocity."
                ]
            },
            {
                "name": "AI Engineer, NexMed Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed deep learning models for chest X-ray abnormality detection achieving 0.92 ROC-AUC; collaborated with radiologists to create clinically-relevant labeling guidelines.",
                    "Integrated PyTorch models into a HIPAA-compliant inference service on AWS Fargate with autoscaling and secure storage.",
                    "Reduced false positives by 25% using ensemble calibration and uncertainty-aware thresholds; authored evaluation framework for regulatory submissions.",
                    "Worked cross-functionally with product and QA to perform A/B experiments and analyze impact on clinical workflow adoption."
                ]
            },
            {
                "name": "Machine Learning Intern, DataSense Research",
                "date": {
                    "start": 2017,
                    "end": 2018
                },
                "bullets": [
                    "Researched and implemented attention-based architectures for time-series forecasting; published results in an internal technical report and open-sourced experiments.",
                    "Built data preprocessing pipelines in Spark to process sensor data at scale and contributed to model training automation scripts."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Anomaly Detection Platform",
                "description": "Designed and deployed a streaming anomaly detection service for IoT telemetry using online learning and threshold adaptation. Provided real-time alerts with root-cause signals.",
                "technologies": [
                    "Python",
                    "Kafka",
                    "Spark Streaming",
                    "scikit-learn",
                    "Prometheus",
                    "Docker"
                ],
                "year": 2023
            },
            {
                "name": "Edge NLP Assistant",
                "description": "Built a compact transformer-based NLU pipeline optimized for edge devices (ARM) using quantization and operator fusion; enabled offline intent classification and entity extraction.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "Quantization",
                    "C++"
                ],
                "year": 2022
            },
            {
                "name": "Chest X-ray Pneumonia Classifier",
                "description": "Developed and validated a CNN-based classifier for pneumonia detection; integrated data augmentation, test-time augmentation, and uncertainty estimation to improve clinical robustness.",
                "technologies": [
                    "PyTorch",
                    "Albumentations",
                    "NumPy",
                    "scikit-learn"
                ],
                "year": 2019
            },
            {
                "name": "Automated Hyperparameter Tuning Framework",
                "description": "Implemented a distributed hyperparameter tuning system using Bayesian optimization and asynchronous schedulers to accelerate model selection across teams.",
                "technologies": [
                    "Ray Tune",
                    "Docker",
                    "Kubernetes",
                    "Python"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "Indian Institute of Science (IISc), Bangalore",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. in Computer Science"
            },
            {
                "name": "BITS Pilani",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.Tech in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "ONNX",
            "scikit-learn",
            "Docker",
            "Kubernetes",
            "Kubeflow",
            "Argo Workflows",
            "MLflow",
            "Kafka",
            "AWS (S3, SageMaker, EKS)",
            "Model quantization & distillation",
            "MLOps",
            "SQL",
            "Data pipelines"
        ],
        "achievements": [
            "Co-author on a workshop paper presented at CVPR Workshops (2020) on efficient architectures for medical imaging.",
            "Speaker at PyData Bengaluru (2022) on productionizing deep learning models.",
            "Led team to 1st place in HackAI Health Hackathon (2019) for a diagnostic assistance prototype."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2019
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Jordan M. Reyes",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven teams that prioritize production-quality ML, strong engineering practices, and measurable product impact.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA, USA"
            },
            "phone": "+1-510-555-0136",
            "email": "jordan.reyes@example.com",
            "linkedin": "https://www.linkedin.com/in/jordanmreyes",
            "github": "https://github.com/jordanreyes"
        },
        "summary": "AI Engineer with 8+ years building and shipping production machine learning systems and LLM-based applications. Strong background in model engineering, retrieval-augmented generation (RAG), scalable inference, and MLOps. I bridge research and product by focusing on reproducible experiments, cost-efficient deployment, and observability.",
        "experience": [
            {
                "name": "Senior AI Engineer, NimbleAI (Hybrid)",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Designed and deployed a multi-stage RAG pipeline (vector DB + LLM + response ranking) powering the company's knowledge assistant; improved first-response accuracy by 28% and reduced average inference cost by 40%.",
                    "Led migration of model serving to Kubernetes with KServe and gRPC-based autoscaling; decreased 99th percentile latency from 1.8s to 320ms for small-batch queries.",
                    "Built observability for model drift and prompt performance using Prometheus + Grafana + custom alerting; identified dataset skew that prevented a major production regression.",
                    "Implemented quantized and distillation-based inference paths (8-bit and int4 experiments) for cost-sensitive endpoints, enabling 3x throughput on identical hardware.",
                    "Mentored a team of 4 ML engineers, establishing CI for ML experiments (DVC + GitHub Actions) and standardizing model reproducibility."
                ]
            },
            {
                "name": "Machine Learning Engineer, BrightHealth Labs",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Built an end-to-end personalization pipeline for member outreach using gradient boosted ensembles and deep embeddings; increased campaign conversion by 18%.",
                    "Produced a containerized time-series forecasting service for capacity planning (Prophet + LSTM ensembles); reduced over-provisioning costs by 12%.",
                    "Collaborated with data engineering to design feature stores and experiment tracking; introduced automated model rollbacks based on A/B safety guardrails.",
                    "Optimized data pipelines (Spark) and inference batchization, reducing per-request compute by 22%."
                ]
            },
            {
                "name": "Data Scientist, Sprout Analytics (startup)",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Led development of recommendation algorithms and real-time scoring services used by partner retailers; improved recommendation CTR by 33%.",
                    "Implemented A/B testing frameworks and uplift modeling to quantify treatment effects for marketing experiments.",
                    "Built ETL flows and dashboards (Airflow, Redshift, Looker) to shorten data-to-insight time from days to hours."
                ]
            }
        ],
        "projects": [
            {
                "name": "OpenRAG: Modular Retrieval-Augmented Generation Framework",
                "description": "Open-source framework combining vector databases, dense retrievers, prompt templates, and model orchestration for building RAG applications. Focused on modularity and extensible connectors for FAISS, Milvus, and Pinecone.",
                "technologies": [
                    "Python",
                    "FAISS",
                    "PyTorch",
                    "LangChain",
                    "Docker",
                    "FastAPI"
                ],
                "year": 2024
            },
            {
                "name": "DistilBERT-lite: Resource-efficient Distillation",
                "description": "Developed a distillation pipeline and hyperparameter recipe to compress BERT models to a 4x smaller, high-throughput variant with minimal accuracy loss for on-device inference.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "Quantization",
                    "ONNX"
                ],
                "year": 2021
            },
            {
                "name": "Demand Forecasting Pipeline",
                "description": "End-to-end forecasting service for retail demand using hybrid statistical + deep learning models, automated retraining, and serving endpoints for demand planners.",
                "technologies": [
                    "Airflow",
                    "Spark",
                    "TensorFlow",
                    "S3",
                    "Kubernetes"
                ],
                "year": 2018
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S., Computer Science (Machine Learning focus)"
            },
            {
                "name": "University of California, Davis",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.S., Computer Engineering"
            }
        ],
        "skills": [
            "PyTorch",
            "TensorFlow",
            "LLMs / Prompting",
            "Retrieval-Augmented Generation",
            "Transformers",
            "Model Distillation & Quantization",
            "Kubernetes / KServe",
            "Docker",
            "Airflow",
            "SQL",
            "Spark",
            "Feature Stores",
            "MLOps / CI-CD",
            "Python",
            "FastAPI"
        ],
        "achievements": [
            "Delivered a production RAG assistant that reduced average ticket resolution time by 45%.",
            "Published an open-source distillation recipe adopted by two startups to reduce inference costs.",
            "Presented best practices for LLM deployment at a regional ML meetup (2023).",
            "Reduced inference infrastructure costs by 35% through mixed-precision and batch optimizations across projects."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2023
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth mindset with strong emphasis on reproducibility and mentoring",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "1234 Pine St, Apt 5B"
            },
            "phone": "+1-206-555-0171",
            "email": "maya.patel71@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-patel",
            "github": "https://github.com/mayarp71"
        },
        "summary": "Data Scientist with 9+ years building production ML systems in healthcare and analytics. Experienced in end-to-end model development, MLOps, causal inference, and leading cross-functional teams to deliver measurable business impact.",
        "experience": [
            {
                "name": "Nexa Health \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a team of 4 data scientists to develop a clinical risk-prediction platform; improved model AUC from 0.78 to 0.87 and reduced false positives by 22%.",
                    "Designed and implemented a CI/CD MLOps pipeline using Docker, Kubernetes and MLflow, cutting deployment time from weeks to under 24 hours.",
                    "Collaborated with clinicians and engineers to integrate models into EHR workflows, resulting in a 15% increase in early intervention rates.",
                    "Mentored junior data scientists, established code review and testing standards, and introduced reproducible experiment tracking."
                ]
            },
            {
                "name": "Astra Analytics \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built personalized recommendation systems and uplift models for a retail analytics product, increasing click-through rate by 11%.",
                    "Led causal inference studies to quantify marketing lift using propensity score methods and synthetic controls.",
                    "Implemented scalable ETL pipelines (Airflow, Spark) and feature stores to support real-time scoring and A/B testing.",
                    "Worked closely with product and sales to translate analytic insights into roadmap priorities and customer deliverables."
                ]
            },
            {
                "name": "OpenLogix \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed NLP pipelines for document classification and entity extraction using spaCy and BERT-based models.",
                    "Optimized model inference and reduced latency by 40% through quantization and model distillation techniques.",
                    "Packaged models as containerized microservices and deployed them to AWS ECS for production workloads."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Deterioration Early Warning",
                "description": "End-to-end system that predicts patient deterioration within 48 hours using EHR time-series data. Includes feature engineering, model training, interpretability, and deployment to hospital workflows.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Pandas",
                    "MLflow",
                    "Kubernetes",
                    "FHIR"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Recommendation Engine",
                "description": "Low-latency recommender for personalized content using hybrid collaborative filtering and contextual bandits for exploration-exploitation tradeoff.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "TensorFlow",
                    "Redis"
                ],
                "year": 2020
            },
            {
                "name": "Document Classification Pipeline",
                "description": "NLP pipeline for automated classification and entity extraction from legal documents using transformer-based models and active learning to reduce labeling costs.",
                "technologies": [
                    "Hugging Face",
                    "spaCy",
                    "Docker",
                    "AWS S3"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Spark",
            "Docker",
            "Kubernetes",
            "MLflow",
            "A/B testing",
            "causal inference",
            "NLP",
            "time series"
        ],
        "achievements": [
            "Increased production model accuracy (AUC) by 0.09 at Nexa Health through improved features and ensembling.",
            "Reduced model deployment time by 60% by introducing CI/CD and automated testing for ML.",
            "Authored a technical blog post on hospital EHR modeling that received 15k+ views.",
            "Presented a poster on clinical machine learning at a regional health informatics conference (2022)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Kapoor",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven team that values clear ownership, continuous learning, automated testing, and fast iteration with strong emphasis on reproducibility and user-centered outcomes.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-7283",
            "email": "aisha.kapoor@example.com",
            "linkedin": "https://www.linkedin.com/in/aishakapoor",
            "github": "https://github.com/aishakapoor"
        },
        "summary": "AI Engineer with 6+ years building and shipping production ML systems across NLP, speech and medical imaging. Strong background in model engineering, MLOps and scalable inference (PyTorch/TensorFlow). Proven track record reducing latency and improving model accuracy in regulated environments.",
        "experience": [
            {
                "name": "Senior ML Engineer \u2014 Cognify Labs",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a multi-lingual speech-to-text pipeline using PyTorch + ONNX Runtime; reduced end-to-end latency by 55% and inference cost by 40% through quantization and batching.",
                    "Designed microservice-based model serving on Kubernetes (KServe) with automated A/B rollouts and canary monitoring; enabled safe monthly model releases across 5 regions.",
                    "Implemented CI/CD for model training and deployment (GitHub Actions, MLflow tracking) and reduced time-to-production for models from 6 weeks to 10 days.",
                    "Mentored a team of 4 ML engineers, established code review and unit testing best practices for model code, and led biweekly model review sessions with product teams."
                ]
            },
            {
                "name": "ML Engineer \u2014 Nova Health",
                "date": {
                    "start": 2020,
                    "end": 2022
                },
                "bullets": [
                    "Built a deep learning pipeline for automated radiology triage using 3D CNNs; achieved a 12% AUC improvement over legacy models and integrated models into clinician workflow with explainability overlays.",
                    "Coordinated data labeling efforts and designed data versioning scheme using DVC and S3, improving dataset reproducibility and auditability for regulatory review.",
                    "Collaborated with cross-functional teams (data engineering, compliance) to produce production-ready inference endpoints and monitoring dashboards (Prometheus + Grafana)."
                ]
            },
            {
                "name": "Machine Learning Research Intern \u2014 Beacon AI",
                "date": {
                    "start": 2019,
                    "end": 2020
                },
                "bullets": [
                    "Researched data augmentation and contrastive pretraining for low-resource medical NLP; published internal evaluation showing up to 8% F1 improvement on downstream tasks.",
                    "Prototyped Transformer-based architectures and optimized training pipelines to scale experiments across GPUs using PyTorch Lightning."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeSpeech",
                "description": "On-device voice recognition stack optimized for edge CPUs. Combined a compact Conformer-based model with pruning and INT8 quantization, integrated with an efficient streaming preprocessor for low-bandwidth environments.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "ONNX Runtime",
                    "TensorRT",
                    "C++"
                ],
                "year": 2023
            },
            {
                "name": "MedInsight Triage",
                "description": "Automated medical image triage pipeline for prioritizing urgent cases. End-to-end system included data ingestion, training loop with automated augmentation, model explainability, and a clinician-facing web dashboard.",
                "technologies": [
                    "TensorFlow",
                    "Docker",
                    "Kubernetes",
                    "MLflow",
                    "React"
                ],
                "year": 2021
            },
            {
                "name": "ContrastAug Toolkit",
                "description": "Open-source library of contrastive augmentation techniques for low-data regimes; provided utilities for image/text augmentations and contrastive pretraining recipes.",
                "technologies": [
                    "PyTorch",
                    "NumPy",
                    "scikit-learn"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "degree": "M.S. in Computer Science (AI)"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2014,
                    "end": 2018
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Transformers",
            "ONNX",
            "Model Quantization & Pruning",
            "MLOps (MLflow, DVC, KServe)",
            "Kubernetes",
            "Docker",
            "AWS (S3, SageMaker, EKS)",
            "GCP",
            "SQL",
            "NumPy",
            "Pandas",
            "scikit-learn",
            "Computer Vision",
            "NLP",
            "CI/CD"
        ],
        "achievements": [
            "Reduced inference costs by 40% and latency by 55% for production ASR pipeline at Cognify Labs.",
            "Deployed clinical triage model that decreased patient review backlog by 30% at Nova Health.",
            "Maintained 99.9% uptime for model serving infrastructure across multi-region clusters.",
            "Open-sourced ContrastAug toolkit with 700+ stars and adoption in two academic projects."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 6,
        "availability": true
    },
    {
        "name": "Elena M. Rivera",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven environment that values clear communication, continuous learning, and mentorship; prefers cross-functional teams and autonomy with shared goals.",
        "contact": {
            "address": {
                "region": "Boston, MA",
                "detail": "Cambridge, MA (willing to travel to Boston offices)"
            },
            "phone": "+1-617-555-4821",
            "email": "elena.rivera73@example.com",
            "linkedin": "https://www.linkedin.com/in/elenarivera73",
            "github": "https://github.com/erivera73"
        },
        "summary": "Data Scientist with 8+ years building production ML systems and analytic solutions in healthcare and fintech. Strengths include end-to-end model development, feature engineering, and deploying scalable pipelines. Proven track record of turning data into measurable business impact and mentoring junior engineers.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 NovaHealth Analytics",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led model development for a hospital readmission risk platform; improved early identification of high-risk patients leading to a 22% reduction in 30-day readmissions for pilot hospitals.",
                    "Designed and productionized ensemble survival and gradient boosting models using Python, XGBoost, and PyTorch served via Docker + Kubernetes, reducing inference latency by 60%.",
                    "Built automated feature pipelines with dbt and Airflow; standardized feature engineering and lineage across 12 clinical data sources.",
                    "Partnered with product and clinical teams to A/B test interventions, defining metrics, and communicating results to stakeholders; drove roadmap prioritization.",
                    "Mentored 5 junior data scientists and established quarterly technical brown-bag sessions on ML best practices."
                ]
            },
            {
                "name": "Data Scientist \u2014 ClearLedger Financial",
                "date": {
                    "start": 2018,
                    "end": 2020
                },
                "bullets": [
                    "Developed real-time fraud detection models using streaming feature stores; reduced false positives by 18% while increasing true positive rate.",
                    "Implemented feature importance and explainability workflows (SHAP) to provide compliance-ready model explanations for regulatory reviews.",
                    "Collaborated with engineers to transition models from notebooks to a CI/CD model deployment pipeline using GitHub Actions and Terraform.",
                    "Optimized model retraining schedules and monitoring, decreasing model drift incidents by 40%."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 BrightLabs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built NLP pipelines for document classification and information extraction using spaCy and BERT fine-tuning; achieved 91% F1 on entity extraction tasks.",
                    "Implemented data validation and unit tests for ML pipelines using Great Expectations, improving data quality and reducing downstream failures.",
                    "Worked closely with backend engineers to containerize models and integrate REST endpoints for client applications."
                ]
            }
        ],
        "projects": [
            {
                "name": "Patient Readmission Predictor",
                "description": "End-to-end platform predicting 30-day hospital readmission risk. Included data ingestion, feature engineering, model training, monitoring, and clinician-facing dashboards.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "PyTorch",
                    "Airflow",
                    "dbt",
                    "Postgres",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Fraud Detection Pipeline",
                "description": "Streaming inference and feature store for transaction fraud scoring. Implemented low-latency scoring, adaptive thresholds, and automated model rollbacks.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "Redis",
                    "scikit-learn",
                    "Docker",
                    "Terraform"
                ],
                "year": 2019
            },
            {
                "name": "Automated Feature Store & Monitoring",
                "description": "Built centralized feature registry and automated monitoring for feature drift and data quality; integrated alerts for anomalies and model degradation.",
                "technologies": [
                    "dbt",
                    "Great Expectations",
                    "Prometheus",
                    "Grafana",
                    "Python"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "Massachusetts Institute of Technology",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Electrical Engineering and Computer Science (focus: ML)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Statistics & Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "dbt",
            "Airflow",
            "Docker",
            "Kubernetes",
            "Kafka",
            "Feature Engineering",
            "Model Monitoring",
            "A/B Testing",
            "Statistics",
            "NLP",
            "AWS"
        ],
        "achievements": [
            "Reduced hospital 30-day readmissions by 22% during pilot through targeted ML-driven interventions.",
            "Delivered fraud detection improvements that decreased false positives by 18% while increasing detection rates.",
            "Mentored and promoted 3 junior data scientists to mid-level roles within two years.",
            "Presented work at the 2023 Applied ML in Healthcare conference."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that prioritize experimentation, clear communication, and mentorship\u2014balanced with autonomy and measurable impact.",
        "contact": {
            "address": {
                "region": "Seattle, WA",
                "detail": "Seattle, WA, USA"
            },
            "phone": "+1-206-555-0147",
            "email": "maya.patel.datasci@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-patel",
            "github": "https://github.com/mayarp"
        },
        "summary": "Data Scientist with 7+ years of experience building production ML systems, causal inference analyses, and data products that drive revenue and operational efficiency. Strong background in Python, scalable model deployment, and experimentation design. Experienced mentoring teams and partnering with product and engineering to deliver measurable business outcomes.",
        "experience": [
            {
                "name": "Senior Data Scientist, Acme Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and deployment of a customer churn prediction model that reduced monthly churn by 18% and increased 6-month retention revenue by $2.1M.",
                    "Built a real-time scoring pipeline using Kafka, Spark Structured Streaming, and TensorFlow Serving, processing 200k+ events/hour with <200ms latency.",
                    "Designed and ran A/B tests and holdout experiments to validate model impact; established experiment metrics and monitoring dashboards in Looker.",
                    "Mentored a team of 4 junior data scientists, established code review and model documentation practices, and reduced model rollback incidents by 40%."
                ]
            },
            {
                "name": "Data Scientist, BrightPath Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed risk stratification models for patient readmission using gradient boosting and survival analysis, improving care management prioritization and reducing readmission rates by 12%.",
                    "Collaborated with clinicians to implement explainable ML (SHAP) for model acceptance; decreased manual review time by 30%.",
                    "Built ETL pipelines in Airflow and dbt to standardize clinical and claims data, cutting data preparation time from days to hours."
                ]
            },
            {
                "name": "Data Analyst, RetailWorld",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Performed RFM segmentation and customer lifetime value modeling that drove targeted marketing campaigns\u2014lifting campaign ROI by 35%.",
                    "Automated weekly sales and inventory reports using SQL and Python, enabling faster merchandising decisions.",
                    "Introduced propensity models for product recommendations, improving click-through rate by 22%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Dynamic Pricing Engine",
                "description": "Designed and deployed a dynamic pricing model for an e-commerce platform that adjusted prices in near real-time based on demand, inventory, and competitor signals.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "Kafka",
                    "AWS Lambda",
                    "PostgreSQL"
                ],
                "year": 2022
            },
            {
                "name": "Patient Risk Dashboard",
                "description": "End-to-end pipeline and interactive dashboard for clinicians to monitor patient risk scores and treatment recommendations with model explanations.",
                "technologies": [
                    "Spark",
                    "MLflow",
                    "Streamlit",
                    "SHAP"
                ],
                "year": 2020
            },
            {
                "name": "Time-series Forecasting for Inventory",
                "description": "Implemented hierarchical multi-store demand forecasting with Prophet and LSTM ensembles; reduced stockouts by 27% and inventory holding costs by 9%.",
                "technologies": [
                    "Prophet",
                    "TensorFlow",
                    "Docker",
                    "Airflow"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "NumPy",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS (S3, SageMaker, Lambda)",
            "Experimentation / A/B testing",
            "Causal inference",
            "Model interpretability (SHAP)",
            "Looker / Tableau",
            "dbt"
        ],
        "achievements": [
            "Reduced customer churn by 18% through a production ML model, yielding $2.1M in incremental 6-month revenue.",
            "Presented a talk on explainable ML in healthcare at the 2021 Healthcare Data Science Summit.",
            "Mentored and promoted 3 junior data scientists to mid-level roles across two companies.",
            "Cut data prep time from days to hours by implementing standardized ETL pipelines with dbt and Airflow."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (DASCA Senior Data Scientist)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Riley Park",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and growth-oriented. Values psychological safety, open knowledge sharing, mentorship, and pragmatic experimentation.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Capitol Hill"
            },
            "phone": "+1-206-555-0143",
            "email": "riley.park@example.com",
            "linkedin": "linkedin.com/in/rileypark",
            "github": "github.com/rileypark"
        },
        "summary": "Data scientist with 9+ years building production ML systems and analytics platforms across healthcare and SaaS. Strong background in predictive modeling, feature engineering, and end-to-end deployment on cloud infrastructure. Proven track record of translating business problems into measurable ML solutions that drive revenue and operational efficiency.",
        "experience": [
            {
                "name": "Senior Data Scientist, Aurora Analytics",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of user-behavior models (XGBoost, deep learning) powering personalization that increased engagement by 18% and ARPU by 12%.",
                    "Designed and implemented feature store and automated ETL pipelines using Airflow, Spark, and AWS S3, reducing model refresh time from weekly to daily.",
                    "Built MLOps workflows with Docker, MLflow, and CI/CD that cut model release time by 40% and improved reproducibility.",
                    "Partnered with product and engineering to define KPIs, run experimentation, and implement model monitoring and drift detection.",
                    "Mentored 4 junior data scientists and established quarterly knowledge-sharing sessions on model interpretability and causal inference."
                ]
            },
            {
                "name": "Data Scientist, Nimbus Health",
                "date": {
                    "start": 2017,
                    "end": 2020
                },
                "bullets": [
                    "Developed predictive models for 30-day hospital readmission (logistic regression, gradient boosting) achieving 0.78 AUC and enabling targeted intervention programs.",
                    "Implemented time-series forecasting for resource planning, improving staffing efficiency and reducing overtime by 15%.",
                    "Designed and analyzed A/B tests for care pathways; translated results into policy changes that improved patient outcomes.",
                    "Collaborated with clinicians to validate features and ensure model fairness across demographic groups."
                ]
            },
            {
                "name": "Data Analyst, BluePeak Consulting",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Delivered client-facing dashboards and analytics using Tableau and SQL that distilled complex datasets into actionable insights.",
                    "Built ETL processes and cleaned large transactional datasets to support modeling and client reports.",
                    "Worked directly with stakeholders to frame problems, prioritize deliverables, and present results to executive sponsors."
                ]
            }
        ],
        "projects": [
            {
                "name": "ChurnShield",
                "description": "End-to-end churn prediction and retention recommendation engine for a subscription SaaS product. Includes feature pipeline, model training, uplift modeling for personalized offers, and A/B test integration.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Airflow",
                    "Docker",
                    "Postgres",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "RealTime Fraud Detector",
                "description": "Streaming fraud detection service processing transaction events with low-latency scoring; combined tree-based models and rule-based ensemble with online feature store.",
                "technologies": [
                    "Spark Structured Streaming",
                    "Kafka",
                    "PySpark",
                    "LightGBM",
                    "Kubernetes"
                ],
                "year": 2021
            },
            {
                "name": "Clinical Readmission Predictor",
                "description": "Predictive model to identify patients at high risk of 30-day readmission. Delivered model, clinical feature validations, and deployment plan; informed care coordination workflows.",
                "technologies": [
                    "R",
                    "tidyverse",
                    "xgboost",
                    "Docker"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "R",
            "SQL",
            "Spark",
            "Airflow",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "Docker",
            "Kubernetes",
            "AWS (S3, EC2, SageMaker)",
            "GCP",
            "MLflow",
            "Feature engineering",
            "Time series",
            "Causal inference",
            "A/B testing",
            "Data visualization (Tableau, Looker)"
        ],
        "achievements": [
            "Reduced model false positive rate by 35% while maintaining recall, saving estimated $2.4M annually in operational costs.",
            "Presented a production ML pipeline case study at KDD 2022 workshop.",
            "Open-sourced a small feature-engineering library used by internal teams to standardize preprocessing.",
            "Built cross-functional ML governance that decreased model incidents by 60%."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Databricks Certified Data Scientist",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and experimental \u2014 prefers cross-functional teams, open knowledge sharing, and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "241 Potrero Ave, Apt 4B"
            },
            "phone": "+1-415-555-7894",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data scientist with 6+ years of experience building production ML systems and analytics platforms. Strong background in end-to-end model development, feature engineering, and causal inference for product optimization. Passionate about turning ambiguous business problems into measurable experiments and scalable data products.",
        "experience": [
            {
                "name": "Senior Data Scientist, Recommendation Systems \u2014 NovaStream (Hybrid)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Designed and deployed a session-aware recommendation model (Transformer-based) that increased user engagement (time-on-site) by 12% and CTR by 9% compared to baseline.",
                    "Led A/B testing framework integration for continuous model evaluation; automated rollout gating reduced negative-impact rollouts by 85%.",
                    "Built feature pipelines in Spark and Airflow to support near-real-time personalization for 10M monthly active users, reducing feature latency from 6 hours to under 15 minutes.",
                    "Mentored 4 junior data scientists and established best practices for model monitoring, bias checks, and reproducibility."
                ]
            },
            {
                "name": "Data Scientist \u2014 FinEdge Analytics (On-site)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed credit-risk models using gradient boosting and survival analysis that reduced default prediction error by 18% and enabled more granular underwriting decisions.",
                    "Implemented a pipeline for feature-store-backed cohort analysis, accelerating model iteration time by 40%.",
                    "Collaborated with engineering to productionize models using Docker and Kubernetes; established CI/CD for model deployments.",
                    "Led stakeholder-facing analyses translating model outputs into business KPIs, contributing to a 7% improvement in portfolio performance."
                ]
            },
            {
                "name": "Data Analyst \u2014 GreenMetrics (On-site)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built interactive dashboards (Tableau, Looker) to track sustainability KPIs used by executive leadership to guide vendor decisions.",
                    "Performed causal inference and uplift modeling to identify interventions that increased recycling program participation by 15%.",
                    "Automated ETL workflows with Python and SQL, cutting weekly reporting time from 12 hours to 2 hours."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Content Personalization Engine",
                "description": "Implemented a low-latency personalization stack using session embeddings and approximate nearest neighbor search to serve recommendations in under 50ms for web and mobile clients.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Faiss",
                    "Kafka",
                    "Redis"
                ],
                "year": 2022
            },
            {
                "name": "Credit Risk Survival Model",
                "description": "Developed a survival-analysis-based model to predict time-to-default; integrated into underwriting pipeline and improved early-warning detection.",
                "technologies": [
                    "scikit-learn",
                    "lifelines",
                    "Pandas",
                    "Spark"
                ],
                "year": 2019
            },
            {
                "name": "Causal Uplift Framework for Marketing",
                "description": "Designed an experimentation and uplift modeling framework to identify segments with highest positive response to promotions, optimizing marketing spend.",
                "technologies": [
                    "DoWhy",
                    "PyTorch",
                    "SQL",
                    "Airflow"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "Master of Science in Data Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign \u2014 B.S. Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "Bachelor of Science in Computer Science"
            }
        ],
        "skills": [
            "Machine Learning",
            "Deep Learning",
            "Feature Engineering",
            "Causal Inference",
            "Python",
            "SQL",
            "Spark",
            "TensorFlow",
            "PyTorch",
            "Airflow",
            "Docker",
            "Kubernetes",
            "Model Monitoring",
            "A/B Testing",
            "Data Visualization"
        ],
        "achievements": [
            "Speaker \u2014 PyData San Francisco 2023: 'Scaling Personalization Pipelines'",
            "Published internal benchmark paper on session-based recommendation models adopted company-wide",
            "Recipient, NovaStream Impact Award 2022 for improving engagement through personalization"
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya Chen",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and growth-oriented; values cross-functional mentorship and reproducible, production-ready ML solutions.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0177",
            "email": "maya.chen@datapulse.example",
            "linkedin": "https://www.linkedin.com/in/maya-chen-ds",
            "github": "https://github.com/mayachen-ds"
        },
        "summary": "Data scientist with 7+ years of experience designing and deploying ML models for forecasting, recommendation, and NLP. Strong background in statistical modeling, feature engineering, and end-to-end productization on cloud platforms. Enjoys mentoring engineers, improving data quality, and producing interpretable business insights that drive measurable outcomes.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Astra Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a time-series demand-forecasting initiative that improved SKU-level forecast accuracy (MAPE reduced by 22%) and enabled a 12% reduction in safety stock across three product lines.",
                    "Designed and deployed an automated model training pipeline (Airflow + MLflow) reducing model retraining lead time from 3 days to 4 hours; integrated CI checks and model drift alerts.",
                    "Collaborated with product and engineering to productionize a personalized recommendation service using factorization machines and lightGBM, increasing click-through rate by 9% in A/B tests.",
                    "Mentored four junior data scientists; introduced a standardized feature-store schema and model documentation template that decreased onboarding time by 30%."
                ]
            },
            {
                "name": "Data Scientist \u2014 BrightEdge Tech",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built and validated customer-churn models (XGBoost + survival analysis) that identified high-risk cohorts; targeted interventions reduced churn by 8% quarter-over-quarter.",
                    "Implemented scalable ETL processes (Spark on AWS EMR) for 50M+ event records/month, improving query performance and enabling faster feature experimentation.",
                    "Led a cross-functional initiative to instrument product telemetry, producing dashboards (Tableau) used by executives for monthly KPIs and prioritization.",
                    "Authored reproducible model evaluation framework that standardized uplift measurement and logging across teams."
                ]
            },
            {
                "name": "Research Assistant \u2014 University of California, Berkeley (Data Lab)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Conducted research in applied NLP for low-resource languages; developed data augmentation and transfer learning workflows improving performance by 11% on target tasks.",
                    "Published and presented findings at a regional ML workshop; collaborated with faculty to release an open-source preprocessing library used by internal research groups.",
                    "Supported graduate courses by designing lab assignments on probabilistic models and deep learning for 120+ students."
                ]
            }
        ],
        "projects": [
            {
                "name": "Inventory Demand Forecasting Platform",
                "description": "End-to-end forecasting system for SKU-level demand: data ingestion, feature engineering (calendar, promotions, external signals), model ensemble (Prophet + LSTM + gradient boosting), and deployment with automated retraining and monitoring.",
                "technologies": [
                    "Python",
                    "TensorFlow",
                    "Prophet",
                    "LightGBM",
                    "Airflow",
                    "MLflow",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "Customer Churn Uplift Model",
                "description": "Developed uplift modeling pipeline to target retention campaigns. Integrated causal uplift objectives, segment-aware feature creation, and A/B evaluation framework.",
                "technologies": [
                    "XGBoost",
                    "scikit-learn",
                    "Pandas",
                    "Spark",
                    "Tableau"
                ],
                "year": 2020
            },
            {
                "name": "Sentiment Analysis for Support Tickets",
                "description": "Built an NLP classifier to triage support tickets by sentiment and urgency; used transfer learning with BERT and custom rule-based features to improve triage routing accuracy and reduce SLA breaches.",
                "technologies": [
                    "Transformers",
                    "PyTorch",
                    "spaCy",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Feature Store & Model Registry Prototype",
                "description": "Implemented a lightweight feature store and model registry to standardize feature definitions, ensure consistency between training and serving, and track model metadata across experiments.",
                "technologies": [
                    "Feast (prototype)",
                    "MLflow",
                    "Kubernetes",
                    "Postgres"
                ],
                "year": 2024
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "XGBoost",
            "LightGBM",
            "TensorFlow",
            "PyTorch",
            "Time-series modeling",
            "NLP (Transformers)",
            "Feature engineering",
            "A/B testing & causal inference",
            "Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "AWS (S3, EC2, EMR, SageMaker)",
            "Tableau / Looker",
            "Git"
        ],
        "achievements": [
            "Reduced aggregate forecasting error (MAPE) by 22% for a multi-million-dollar product portfolio, enabling a 12% decrease in safety stock.",
            "Authored an internal model-retraining orchestration that cut end-to-end retrain time from days to hours.",
            "Published research on transfer-learning techniques for low-resource NLP; open-sourced preprocessing tools used by academic peers.",
            "Led mentorship program for junior data scientists, with mentees promoted to mid-level roles within 12\u201318 months."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Google Professional Machine Learning Engineer",
                "date": 2021
            },
            {
                "name": "AWS Certified Data Analytics \u2013 Specialty",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Jordan Lee",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and outcome-oriented. Values clear communication, continuous learning, and cross-functional partnership between research, product, and engineering.",
        "contact": {
            "address": {
                "region": "Oakland, CA, USA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (510) 555-0178",
            "email": "jordan.lee78@example.com",
            "linkedin": "https://www.linkedin.com/in/jordan-lee-ml",
            "github": "https://github.com/jordanlee78"
        },
        "summary": "AI Engineer with 9+ years building production ML systems across recommendation, computer vision, and NLP. Experienced in end-to-end model development, deployment, and MLOps for low-latency, scalable services. Strong background in deep learning research and software engineering, focused on measurable product impact.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 NeuroPulse AI",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multimodal personalization engine serving 100M+ monthly users; increased engagement (CTR) by 18% while maintaining latency targets.",
                    "Built a real-time feature pipeline using Kafka, Spark Structured Streaming, and Redis for low-latency feature access; reduced feature retrieval time from 45ms to 8ms.",
                    "Introduced PyTorch-based training infra and model registry integrated with MLflow and K8s; cut model rollout time from weeks to days.",
                    "Mentored a team of 5 ML engineers and coordinated cross-functional experiments with product and data science teams."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 RecomWorks",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed a hybrid collaborative-filtering + deep contextual model for recommendations, improving conversion rate by 12% A/B.",
                    "Optimized model inference pipeline and containerized services (Docker + Kubernetes), reducing CPU utilization by 35% and inference latency by 4x.",
                    "Implemented automated CI/CD for model training, validation, and canary deployment using GitHub Actions and Argo CD.",
                    "Collaborated with data engineers to re-architect training data flows, improving data freshness from daily to hourly."
                ]
            },
            {
                "name": "Data Scientist \u2014 MarketSense Analytics",
                "date": {
                    "start": 2016,
                    "end": 2019
                },
                "bullets": [
                    "Built churn-prediction and LTV models using XGBoost and time-series features; reduced churn by enabling targeted retention campaigns (8% lift in retention).",
                    "Led feature engineering and ETL using SQL and Airflow; standardized feature definitions across teams.",
                    "Presented model explainability reports (SHAP) to stakeholders to prioritize product interventions."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-Time Personalization Engine",
                "description": "End-to-end recommendation pipeline combining session-based transformers and graph embeddings, serving real-time recommendations with sub-50ms latency.",
                "technologies": [
                    "PyTorch",
                    "Spark",
                    "Kafka",
                    "Redis",
                    "Kubernetes",
                    "MLflow"
                ],
                "year": 2023
            },
            {
                "name": "Edge Object Detection Suite",
                "description": "Developed a quantized and pruned object detection model optimized for edge devices; integrated with ONNX Runtime and reduced model size by 6x with <3% mAP drop.",
                "technologies": [
                    "TensorFlow",
                    "TensorRT",
                    "ONNX",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Customer Churn & LTV Platform",
                "description": "Full-stack ML pipeline for churn prediction and lifetime value estimation powering marketing automation and budgeting decisions.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "Airflow",
                    "BigQuery"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "MS in Computer Science (Machine Learning)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "BS in Statistics"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Spark",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, S3, EC2)",
            "GCP (BigQuery)",
            "MLflow",
            "MLOps",
            "Model interpretability (SHAP, LIME)",
            "NLP",
            "Computer Vision",
            "Time Series"
        ],
        "achievements": [
            "Delivered product-facing recommendation system that increased CTR by 18% for a major product line.",
            "Reduced model inference latency 4x through pipeline and infra optimizations, enabling real-time personalization.",
            "Filed 2 patents related to multimodal recommendation ranking and feature-store optimizations.",
            "Published 3 machine learning conference papers and presented solutions at internal and external engineering forums."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2017
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Varma",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented team that values data-driven decision making, clear communication, mentorship, and experimentation. Prefers teams that balance research rigor with pragmatic product delivery.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "1354 Market St, Apt 12"
            },
            "phone": "+1-415-555-4829",
            "email": "aisha.varma@email.com",
            "linkedin": "https://www.linkedin.com/in/aishavarma",
            "github": "https://github.com/aishavarma"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems and data platforms for healthcare and fintech. Strong background in supervised learning, time-series forecasting, model deployment, and MLOps. Experienced in end-to-end delivery from feature engineering and model development to monitoring and cost optimization.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Nimble Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production rollout of an XGBoost/LightGBM-based clinical risk prediction model that improved early-intervention identification by 18% and was adopted across three care pathways.",
                    "Built feature store and automated feature pipelines with Airflow and Spark, reducing feature computation latency from hours to minutes.",
                    "Designed ML monitoring and alerting using Great Expectations and Prometheus to detect data drift and model performance regressions; reduced incident mean time to detect by 60%.",
                    "Partnered with product and engineering to containerize models (Docker) and deploy on AWS ECS; optimized inference to reduce per-request cost by 40%."
                ]
            },
            {
                "name": "Data Scientist \u2014 FinSight Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed customer lifetime value and churn models using gradient boosting and survival analysis for merchant clients, increasing retention-driven revenue by 12%.",
                    "Implemented A/B testing frameworks and causal inference pipelines to quantify feature releases and marketing experiments.",
                    "Created interactive dashboards (Looker, Tableau) and self-serve ML endpoints for business stakeholders, shortening insight-to-action time from weeks to days."
                ]
            },
            {
                "name": "Data Analyst \u2014 Bridge Insights",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Performed exploratory analysis and ETL on large transactional datasets to support recommendation and pricing models.",
                    "Automated weekly reporting and built SQL-based reporting pipelines, freeing analyst time by 30%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Risk Model",
                "description": "End-to-end risk stratification pipeline for early detection of patient deterioration. Included feature engineering from EHR, model training with XGBoost, calibration, and deployment with CI/CD.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Pandas",
                    "Docker",
                    "AWS (S3, ECS)"
                ],
                "year": 2022
            },
            {
                "name": "ML Monitoring & Rollback System",
                "description": "Automated monitoring pipeline that computes feature and prediction drift metrics, integrates with Prometheus/Grafana, and supports automated rollback of models failing safety checks.",
                "technologies": [
                    "Great Expectations",
                    "Prometheus",
                    "Grafana",
                    "Airflow",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Customer Churn Dashboard",
                "description": "Interactive dashboard showing churn cohorts, drivers, and model explainability (SHAP) for marketing and product teams to identify retention levers.",
                "technologies": [
                    "Tableau",
                    "Python",
                    "SHAP",
                    "SQL"
                ],
                "year": 2019
            },
            {
                "name": "Data Warehouse Migration",
                "description": "Led migration of analytics pipelines from on-premise PostgreSQL to Snowflake, rewrote ETL in dbt, and improved query performance and developer productivity.",
                "technologies": [
                    "Snowflake",
                    "dbt",
                    "Airflow",
                    "SQL"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science (Data Science)"
            },
            {
                "name": "University of Delhi",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Pandas",
            "scikit-learn",
            "XGBoost",
            "PyTorch",
            "TensorFlow",
            "Spark",
            "Airflow",
            "dbt",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLOps",
            "Model monitoring",
            "Time series forecasting",
            "Causal inference",
            "Data visualization"
        ],
        "achievements": [
            "Published workshop paper on interpretable time-to-event models at NeurIPS 2023",
            "Implemented model optimizations that reduced inference infrastructure cost by 40% while maintaining performance",
            "Mentored and onboarded 6 junior data scientists; structured team learning sessions and code reviews"
        ],
        "certifications": [
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, impact-focused; values mentorship, experimentation, and clear product partnership.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "San Francisco, CA"
            },
            "phone": "+1-415-555-8240",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 9+ years of experience building and shipping machine learning systems for healthcare and SaaS products. Strong track record in productionizing predictive models, designing experiment frameworks, and scaling feature pipelines. Comfortable across the stack from data engineering (Spark, SQL) to model development (PyTorch, scikit-learn) and deployment (Docker, Kubernetes, MLflow). Passionate about mentoring, reproducible ML, and translating analytics into product impact.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nimbus Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development of a hospital readmission risk scoring system using EHR and claims data (XGBoost & PyTorch), improving early-intervention triage precision by 28% and reducing 30-day readmission rates by 12% in pilot sites.",
                    "Designed and implemented production feature pipelines with Spark and Airflow, reducing feature refresh latency from 24h to 1h and enabling near-real-time predictions.",
                    "Built model monitoring and retraining workflows with MLflow and Prometheus; automated drift detection and scheduled retraining that improved model stability and reduced false positives by 18%.",
                    "Partnered with product and clinical teams to A/B test care pathways; defined metrics, analyzed results, and presented actionable recommendations to stakeholders.",
                    "Mentored 4 junior data scientists and led weekly technical brown-bags on model interpretability and causal evaluation."
                ]
            },
            {
                "name": "Data Scientist, BrightMetrics (SaaS analytics)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built customer churn and upsell propensity models using survival analysis and gradient-boosted trees; together with targeted interventions, increased net revenue retention by 7% over 12 months.",
                    "Developed a personalized recommendation engine for product features using collaborative filtering and feature-based ranking, increasing feature adoption by 15%.",
                    "Owned ETL workflows leveraging AWS Glue and Spark; improved data quality and cut query costs by 30% through optimized partitioning and schema management.",
                    "Implemented instrumentation for experiment tracking and standardized SQL-based analysis notebooks for the analytics team."
                ]
            },
            {
                "name": "Data Analyst, CityLabs Diagnostics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built operational dashboards (Tableau) and automated reporting to reduce manual reporting time by 60%.",
                    "Performed cohort analyses and root-cause investigations to guide lab process improvements that decreased turnaround time by 20%.",
                    "Collaborated with engineers to define data schemas and improve upstream logging for higher-fidelity analytics."
                ]
            }
        ],
        "projects": [
            {
                "name": "Remote Patient Risk Scoring System",
                "description": "End-to-end system to score remote patient risk using streaming device telemetry and recent EHR events; included feature store, online scoring API, and clinician-facing risk visualization.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Spark",
                    "Airflow",
                    "MLflow",
                    "Docker",
                    "Postgres"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Feature Store",
                "description": "Designed and implemented a low-latency feature store to serve features for online inference and A/B experiments, supporting 10k requests/sec with <50ms latency.",
                "technologies": [
                    "Redis",
                    "Kafka",
                    "Spark Structured Streaming",
                    "AWS",
                    "Terraform"
                ],
                "year": 2022
            },
            {
                "name": "Sales Uplift Experimentation Platform",
                "description": "Built an experimentation platform to measure personalized outreach strategies using causal inference techniques; produced automated reports and uplift models used by the sales ops team.",
                "technologies": [
                    "Python",
                    "CausalImpact",
                    "pandas",
                    "SQL",
                    "Tableau"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Illinois at Urbana-Champaign",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "MLflow",
            "AWS",
            "GCP",
            "Tableau",
            "A/B testing",
            "Causal inference",
            "Feature engineering",
            "Model monitoring"
        ],
        "achievements": [
            "Reduced prediction latency by 60% and operational costs by 30% through optimized feature pipelines and model serving improvements.",
            "Improved a core model's AUC from 0.72 to 0.84 via feature engineering and ensembling.",
            "Mentored 6 data scientists and organized internal ML best-practices program.",
            "Top 1% in multiple Kaggle competitions (team events) and presented work at an industry ML summit."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "IBM Data Science Professional Certificate",
                "date": 2017
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya Singh",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-oriented, data-driven; values mentorship and clear product impact",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0181",
            "email": "maya.singh.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-singh-ai",
            "github": "https://github.com/mayasingh-ai"
        },
        "summary": "AI Engineer with 7+ years building production ML systems and end-to-end model pipelines. Experienced in model development, MLOps, and deploying optimized LLM and vision models at scale. Strong emphasis on reliability, reproducibility, and measurable product impact.",
        "experience": [
            {
                "name": "Senior AI Engineer, Aurora Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multimodal clinical inference pipeline (vision + tabular) used in production across partner hospitals; improved diagnostic throughput by 2.8x while maintaining regulatory traceability.",
                    "Implemented CI/CD for ML using Terraform, IaC, Docker, and Kubernetes; reduced model release time from weeks to under 48 hours.",
                    "Fine-tuned and deployed instruction-tuned LLMs for clinical summarization with retrieval-augmented generation (RAG); decreased average clinician turnaround time by 35%.",
                    "Optimized inference cost via quantization and batching strategies, reducing GPU spend by ~45% without measurable accuracy loss."
                ]
            },
            {
                "name": "AI Engineer, Nexa Health",
                "date": {
                    "start": 2019,
                    "end": 2021
                },
                "bullets": [
                    "Built end-to-end predictive models for patient risk stratification (XGBoost, PyTorch); increased early-intervention accuracy (AUC) from 0.72 to 0.80.",
                    "Created feature pipelines and ETL jobs in Airflow and Spark to process streaming EHR data; ensured data quality checks and monitoring.",
                    "Collaborated with product and clinical teams to prioritize model interpretability and deploy explainability dashboards used by clinicians."
                ]
            },
            {
                "name": "Machine Learning Engineer, Edge Analytics",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Developed and productionized real-time recommendation engine serving personalized content to 200k+ daily users.",
                    "Designed experiments and A/B tests to validate model changes; introduced automated model rollback based on key business KPIs.",
                    "Authored internal tooling for model evaluation and feature lineage that reduced debugging time by 40%."
                ]
            },
            {
                "name": "Research Intern, Vision & Learning Lab (University)",
                "date": {
                    "start": 2016,
                    "end": 2017
                },
                "bullets": [
                    "Implemented novel data augmentation strategies for small-sample image classification; results published in internal workshop.",
                    "Worked on semi-supervised learning pipelines and benchmarking across public datasets."
                ]
            }
        ],
        "projects": [
            {
                "name": "MedAI Diagnostic Pipeline",
                "description": "End-to-end clinical inference platform combining imaging and structured patient data. Includes data ingestion, preprocessing, model ensembling, explainability outputs, and monitoring dashboards.",
                "technologies": [
                    "PyTorch",
                    "FastAPI",
                    "Docker",
                    "Kubernetes",
                    "Airflow",
                    "Postgres",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "Realtime Recommendation Engine",
                "description": "Low-latency recommendation service supporting personalized ranking and contextual features; implemented feature store and incremental model updates with online learning.",
                "technologies": [
                    "Spark",
                    "Kafka",
                    "Redis",
                    "Scikit-learn",
                    "TensorFlow"
                ],
                "year": 2018
            },
            {
                "name": "RAG Chatbot for Clinical Summaries",
                "description": "Retrieval-Augmented Generation system that combines a vector store of clinical documents with a fine-tuned LLM to produce concise, referenced summaries for clinicians.",
                "technologies": [
                    "Hugging Face Transformers",
                    "FAISS",
                    "PyTorch",
                    "LangChain"
                ],
                "year": 2023
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Computer Science",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "degree": "M.S. Computer Science, Machine Learning Track"
            },
            {
                "name": "Indian Institute of Technology Delhi \u2014 B.Tech",
                "date": {
                    "start": 2011,
                    "end": 2015
                },
                "degree": "B.Tech in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face",
            "JAX",
            "MLOps",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Spark",
            "SQL",
            "Model Quantization",
            "Distributed Training",
            "Feature Engineering",
            "CI/CD for ML",
            "REST APIs"
        ],
        "achievements": [
            "Reduced inference latency by 3x through model optimization and batching strategies, lowering production costs by ~45%",
            "Improved predictive AUC by 8% for a patient-risk model used in prior authorization workflows",
            "Deployed and maintained models serving 1M+ inference requests per week with automated monitoring and alerting",
            "Maintainer of an open-source PyTorch utilities library used by internal teams"
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Alexandra Lin",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and outcome-focused. Values psychological safety, code reviews, reproducible experiments, and mentorship.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Based in Bay Area; open to relocation within US"
            },
            "phone": "+1-415-555-7821",
            "email": "alex.lin.ai@gmail.com",
            "linkedin": "https://www.linkedin.com/in/alexandra-lin-ai",
            "github": "https://github.com/alexlin-ai"
        },
        "summary": "AI Engineer with 8+ years building production ML systems and research-informed models for recommendation, computer vision, and NLP. Strong background in model architecture, MLOps, and scaling training pipelines. Proven track record delivering 15-30% metric improvements through rigorous A/B testing and deployment of robust inference services.",
        "experience": [
            {
                "name": "Senior AI Engineer, Nimbus Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of a multimodal recommendation model (text + image) that increased click-through rate by 22% and reduced latency 35% via model distillation and TensorRT optimization.",
                    "Built end-to-end MLOps pipelines using Kubeflow, MLflow, and Terraform to automate retraining, validation, and canary deployments across 50+ microservices.",
                    "Implemented feature store integration (Feast) and real-time inference adapter supporting 10k QPS with <120ms 95th percentile latency.",
                    "Mentored a team of 4 engineers on model interpretability, unit-tested training code, and reproducible experiments; established CI for model training and data schema checks."
                ]
            },
            {
                "name": "ML Engineer, AdaptiTech Inc.",
                "date": {
                    "start": 2017,
                    "end": 2021
                },
                "bullets": [
                    "Developed and deployed transformer-based ranking models for personalized feeds, improving retention by 18% in A/B tests.",
                    "Optimized data pipelines using Apache Beam and Airflow, reducing daily ETL runtime from 6 hours to 90 minutes.",
                    "Introduced continuous evaluation metrics and automated drift detection leading to 30% faster rollback times on degraded models.",
                    "Collaborated with data scientists to convert prototypes into production-grade services using Docker, Kubernetes, and gRPC."
                ]
            },
            {
                "name": "ML Engineer (Computer Vision), Verisight",
                "date": {
                    "start": 2014,
                    "end": 2017
                },
                "bullets": [
                    "Designed and trained deep convolutional models for object detection and segmentation (Faster R-CNN, U-Net) for inspection automation, achieving 92% detection precision in production.",
                    "Implemented model compression (pruning + quantization) to deploy models on edge devices, reducing model size by 8x with minimal accuracy loss.",
                    "Worked with hardware and embedded teams to integrate inference pipelines on Jetson platforms and Linux-based edge appliances."
                ]
            }
        ],
        "projects": [
            {
                "name": "Multimodal Distilled Recommender",
                "description": "Combined text embeddings and image features into a single distilled model for fast production inference. Focused on reducing latency and maintaining accuracy of a large ensemble.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "TensorRT",
                    "ONNX",
                    "Feast"
                ],
                "year": 2023
            },
            {
                "name": "Real-time Feature Store Integration",
                "description": "Built a low-latency feature retrieval layer for online serving, ensuring consistent feature engineering between training and inference with versioning.",
                "technologies": [
                    "Kafka",
                    "Redis",
                    "Feast",
                    "Golang"
                ],
                "year": 2022
            },
            {
                "name": "EdgeVision: Compressed CV Models for Inspection",
                "description": "Developed compressed object detection models and an automated pipeline to quantize and validate models for edge deployment on Jetson Nano.",
                "technologies": [
                    "TensorFlow",
                    "TensorRT",
                    "OpenCV"
                ],
                "year": 2016
            },
            {
                "name": "Automated Model Drift Alerting System",
                "description": "Created monitoring and alerting to detect dataset shift and model degradation using statistical tests and model-based monitors, tied into CI/CD for automated retraining triggers.",
                "technologies": [
                    "Prometheus",
                    "Grafana",
                    "Pandas",
                    "scikit-learn"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2014
                },
                "degree": "M.S. in Electrical Engineering and Computer Sciences (EECS)"
            },
            {
                "name": "University of California, San Diego",
                "date": {
                    "start": 2008,
                    "end": 2012
                },
                "degree": "B.S. in Computer Science"
            }
        ],
        "skills": [
            "PyTorch",
            "TensorFlow",
            "Transformers",
            "Distributed Training",
            "MLOps (Kubeflow, MLflow)",
            "Feature Engineering",
            "Python",
            "Golang",
            "Docker",
            "Kubernetes",
            "SQL",
            "AWS (Sagemaker, EKS)",
            "Model Compression (pruning, quantization)",
            "Data Pipelines (Airflow, Beam)"
        ],
        "achievements": [
            "Delivered a production recommender that increased CTR by 22% and retention by 12%.",
            "Reduced model inference latency by 35% across key endpoints through distillation and optimization.",
            "Authored internal best-practices for reproducible training and CI for ML; adopted across three engineering teams.",
            "Speaker at ML Infra Summit 2023: 'Practical Model Distillation for Production'"
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Jordan Lee",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused, data-driven, and inclusive \u2014 values mentorship, cross-functional partnership, and iterative experimentation.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "Based in San Francisco; open to relocation and remote roles"
            },
            "phone": "+1-415-555-0147",
            "email": "jordan.lee.data@gmail.com",
            "linkedin": "https://www.linkedin.com/in/jordan-lee-ds",
            "github": "https://github.com/jordanlee-ds"
        },
        "summary": "Data Scientist with 9+ years of experience building and deploying ML-driven product features and analytics platforms for e-commerce and health-tech. Strong track record of translating business problems into robust models and production pipelines, improving KPIs through experimentation, time-series forecasting, and recommendation systems. Comfortable leading cross-functional teams and mentoring junior engineers.",
        "experience": [
            {
                "name": "Senior Data Scientist, Arcwave Health (product analytics & ML)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a personalized recommendation system for patient engagement, increasing weekly active users by 18% and feature adoption by 24%.",
                    "Built end-to-end ML pipelines in AWS (Sagemaker, Lambda, Step Functions) to automate model retraining and A/B experiment scoring, reducing time-to-deploy from 4 weeks to 5 days.",
                    "Designed causal inference experiments and uplift modeling that improved targeted intervention ROI by 2.6x and reduced unnecessary outreach by 30%.",
                    "Mentored a team of 4 data scientists and collaborated with product and engineering to prioritize roadmap and KPIs."
                ]
            },
            {
                "name": "Data Scientist, Lumina Retail (demand forecasting & personalization)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Architected a hierarchical demand forecasting system (Prophet + XGBoost residuals + feature store) that reduced out-of-stock events by 22% and lowered inventory carrying costs by 11%.",
                    "Implemented real-time personalization features using approximate nearest neighbors and light-weight ranking models served via microservices, increasing conversion rate by 7%.",
                    "Standardized feature engineering and evaluation frameworks, enabling reproducible experiments and reducing model iteration time by 40%."
                ]
            },
            {
                "name": "Data Scientist / ML Engineer, Insight Analytics (consulting)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Delivered end-to-end analytics and predictive models for B2B clients, including churn prediction and pricing optimization; typical client KPI improvements ranged 8\u201320%.",
                    "Built Spark ETL pipelines and deployed Dockerized models to clients' on-prem and cloud environments, ensuring monitoring and retraining flows were in place.",
                    "Conducted technical workshops on A/B testing, feature engineering, and model interpretability for cross-functional stakeholders."
                ]
            }
        ],
        "projects": [
            {
                "name": "Demand Forecasting Platform",
                "description": "End-to-end demand forecasting solution combining hierarchical models, external features (promotions, holidays), and automated model selection. Integrated forecast outputs into inventory planning dashboards and replenishment workflows.",
                "technologies": [
                    "Python",
                    "Prophet",
                    "XGBoost",
                    "Airflow",
                    "Spark",
                    "AWS S3"
                ],
                "year": 2020
            },
            {
                "name": "Personalized Recommendation & Ranking Service",
                "description": "Built a two-stage recommendation pipeline (candidate generation + learn-to-rank) served via low-latency microservices; included offline evaluation suite and online A/B testing harness.",
                "technologies": [
                    "PyTorch",
                    "Faiss",
                    "scikit-learn",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "Causal Impact Toolkit for Marketing",
                "description": "Toolkit combining synthetic controls and uplift models to measure incremental impact of campaigns across channels; automated reporting and significance testing to inform budget allocation.",
                "technologies": [
                    "R",
                    "Python",
                    "AWS Lambda",
                    "Tableau"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Electrical Engineering"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "Time Series Forecasting",
            "Causal Inference",
            "NLP",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Tableau",
            "Experimentation / A/B Testing"
        ],
        "achievements": [
            "Reduced inventory costs by $3M annually through demand-forecasting improvements.",
            "Increased product feature adoption by 24% through personalized recommendations and experimentation.",
            "Speaker at PyData SF 2021 on operationalizing ML pipelines for medium-sized teams."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "Google Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Asha Raman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, impact-driven, learning-focused \u2014 values cross-functional collaboration, clear ownership, and continuous improvement.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala"
            },
            "phone": "+91-98450-12345",
            "email": "asha.raman@example.com",
            "linkedin": "https://www.linkedin.com/in/asharaman",
            "github": "https://github.com/asharaman"
        },
        "summary": "AI Engineer with 8+ years building and productionizing machine learning systems for healthcare and e-commerce. Strong background in end-to-end model development, MLOps, and scalable inference pipelines. Skilled at translating product requirements into robust architectures and measurable business outcomes.",
        "experience": [
            {
                "name": "Senior Machine Learning Engineer \u2014 Veridian Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and production deployment of a multimodal clinical risk-prediction model that improved early-detection sensitivity by 18% and reduced ICU admissions by 6%.",
                    "Built scalable inference pipeline using Docker, Kubernetes, and TF Serving / TorchServe; reduced end-to-end latency by 40% and improved throughput to 200+ requests/sec.",
                    "Established CI/CD for models (MLflow + GitHub Actions) and automated model validation checks, reducing manual deployment time from days to hours.",
                    "Mentored a team of 4 ML engineers, instituted code review standards and reproducible training recipes."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 BlueLens Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed a real-time recommendation engine for an e-commerce client that increased click-through rate by 12% and incremental revenue by 7%.",
                    "Designed feature stores and offline/online feature pipelines using Spark and Redis, improving feature retrieval latency to <15ms.",
                    "Implemented A/B testing and causal analysis frameworks; partnered with data engineering to instrument metrics and dashboards.",
                    "Converted research prototypes into production-ready services using FastAPI, Docker, and GCP, ensuring 99.95% service availability."
                ]
            },
            {
                "name": "Data Scientist \u2014 Independent Consultant",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Delivered end-to-end analytics and ML solutions for startups in healthtech and fintech \u2014 from data ingestion to model deployment.",
                    "Created automated data labeling workflows combining active learning and weak supervision to accelerate dataset creation by 5x.",
                    "Built NLP pipelines for intent classification and entity extraction using spaCy and BERT, improving NLU accuracy across clients."
                ]
            }
        ],
        "projects": [
            {
                "name": "CardioSight \u2014 Multimodal Clinical Risk Model",
                "description": "Developed a multimodal model combining EHR time series and ECG image embeddings to predict 30-day cardiac readmission risk; integrated with hospital workflow for clinician review.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "TensorFlow",
                    "MLflow",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Realtime Recommendation Engine",
                "description": "Built a low-latency recommendation service using candidate generation + lightweight ranking, deployed for high-traffic e-commerce site.",
                "technologies": [
                    "Spark",
                    "Redis",
                    "Scikit-learn",
                    "FastAPI",
                    "GCP"
                ],
                "year": 2020
            },
            {
                "name": "AutoLabel \u2014 Automated Data Labeling Toolkit",
                "description": "Open-source toolkit combining active learning, weak supervision, and human-in-the-loop labeling to reduce manual annotation overhead.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "snorkel",
                    "AWS S3"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of Hyderabad",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. in Computer Science (Machine Learning focus)"
            },
            {
                "name": "National Institute of Technology, Trichy",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.Tech in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "MLflow",
            "MLOps",
            "Docker",
            "Kubernetes",
            "Spark",
            "SQL",
            "Pandas",
            "NumPy",
            "NLP",
            "Computer Vision",
            "AWS",
            "GCP",
            "FastAPI",
            "CI/CD"
        ],
        "achievements": [
            "Speaker \u2014 NeurIPS workshop on clinical ML deployment (2023)",
            "Reduced model inference cost by 35% through quantization and batching in production",
            "Maintainer of an open-source data labeling toolkit with 1.2k GitHub stars",
            "Authored 3 peer-reviewed papers on time-series risk prediction"
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "Professional Data Engineer (Google Cloud)",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya Patel",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, metrics-driven team that values code quality, reproducibility, mentorship, and continuous learning",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (510) 555-4821",
            "email": "maya.patel.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-patel-ai",
            "github": "https://github.com/mayapatel-ai"
        },
        "summary": "AI Engineer with 8+ years building and productionizing ML systems for recommendation, search, and language applications. Strong background in deep learning, ML infrastructure, and model deployment at scale. Experience leading cross-functional teams to deliver measurable business impact and maintain robust MLOps pipelines.",
        "experience": [
            {
                "name": "CortexAI Labs \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a multimodal retrieval system (text + image) used by 15M monthly users, reducing relevant-result latency by 40% and increasing engagement by 12%.",
                    "Built a production inference stack using PyTorch, TorchServe, and Kubernetes with autoscaling and A/B rollout, supporting 300+ requests/sec at peak.",
                    "Implemented model monitoring (data drift, concept drift, perf regression) with Prometheus and Grafana and automated alerting/noise-detection to reduce production incidents by 60%.",
                    "Mentored 4 junior engineers, established coding standards, and introduced reproducible experiment tracking using MLflow."
                ]
            },
            {
                "name": "NexGen Analytics \u2014 ML Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed and optimized recommendation models (matrix factorization, neural collaborative filtering) that increased conversion rate by 8% for a B2C product.",
                    "Designed ETL pipelines with Spark and Airflow to process 10TB/week of user interaction data; reduced pipeline runtime by 35% through partitioning and optimized joins.",
                    "Collaborated with product and data engineering to productionize feature stores and incremental training pipelines, enabling daily model refreshes.",
                    "Introduced model compression techniques (quantization, distillation) to reduce serving cost by 3x while maintaining >95% baseline accuracy."
                ]
            },
            {
                "name": "UrbanSense \u2014 Data Scientist",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built time-series forecasting models for demand prediction in urban mobility, improving demand prediction MAPE from 18% to 10%.",
                    "Performed A/B testing analysis and created dashboards to drive data-informed product decisions across operations and marketing teams.",
                    "Automated data validation and unit tests for critical data pipelines, reducing downstream analysis errors by 45%."
                ]
            }
        ],
        "projects": [
            {
                "name": "Low-latency Semantic Search",
                "description": "End-to-end semantic search system combining dense embeddings (SBERT) and optimized ANN indices for sub-50ms query latency at 99th percentile; integrated with autocomplete and relevance tuning.",
                "technologies": [
                    "PyTorch",
                    "FAISS",
                    "Redis",
                    "FastAPI",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Customer Support QA Assistant",
                "description": "Deployed an LLM-based retrieval-augmented generation assistant for customer support knowledge base; reduced average handling time by 22% and improved CSAT scores.",
                "technologies": [
                    "Hugging Face Transformers",
                    "OpenAI API",
                    "Postgres",
                    "LangChain",
                    "Sentry"
                ],
                "year": 2024
            },
            {
                "name": "Real-time Recommendation Pipeline",
                "description": "Built streaming feature and model-serving pipeline using Kafka, Flink, and Triton for sub-second personalized recommendations in production.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "Triton Inference Server",
                    "Python",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "Model Compression Toolkit",
                "description": "Open-source toolkit for model pruning and quantization workflows, enabling reproducible experiments and integration with CI/CD for model entry into production.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "GitHub Actions",
                    "Docker"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S., Computer Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science (Machine Learning)"
            },
            {
                "name": "University of Illinois \u2014 B.S., Computer Engineering",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Engineering"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face Transformers",
            "scikit-learn",
            "SQL",
            "Spark",
            "Flink",
            "Kafka",
            "Docker",
            "Kubernetes",
            "Triton",
            "MLflow",
            "Airflow",
            "FAISS",
            "AWS (S3, SageMaker, Lambda)",
            "GCP (BigQuery, Vertex AI)",
            "Model Compression",
            "MLOps",
            "Prompt Engineering",
            "Embeddings",
            "REST APIs"
        ],
        "achievements": [
            "Deployed and maintained production AI services serving 15M monthly active users with 99.9% uptime.",
            "Reduced model inference cost by 3x via quantization and optimized serving pipelines.",
            "Published an RFC and led company-wide adoption of standardized experiment tracking and model governance.",
            "Maintained open-source model compression toolkit with 1.2k GitHub stars and adoption in two startups."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Jordan M. Lee",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, growth mindset; values production-focused MLOps, cross-functional ownership, and continuous learning. Prefers teams that emphasize code review, reproducible experiments, and measurable impact.",
        "contact": {
            "address": {
                "region": "San Francisco, CA, USA",
                "detail": "Based in the Bay Area; open to remote-first roles"
            },
            "phone": "+1 (415) 555-0186",
            "email": "jordan.lee86@example.com",
            "linkedin": "https://linkedin.com/in/jordanmlee",
            "github": "https://github.com/jordanmlee"
        },
        "summary": "AI Engineer with 9+ years building and shipping machine learning systems for vision and recommendation products. Strong background in model engineering, MLOps, and production optimization \u2014 from research prototyping to scalable deployment. Experienced with transformers, CV architectures, containerized pipelines, and cloud-native inference serving.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 Nimbus AI",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end operationalization of multi-modal recommendation models (text + images) served to 20M monthly users; improved click-through-rate by 12% vs baseline through feature fusion and re-ranking.",
                    "Designed and implemented a reproducible MLOps stack using Kubeflow, Docker, and GitOps; cut deployment time for new models from weeks to days.",
                    "Built a low-latency transformer inference service (TorchServe + ONNX runtime) reducing 99th percentile latency by 65% and inference cost by 40% through quantization and batching.",
                    "Mentored a team of 4 ML engineers; introduced model governance, CI for training pipelines, and automated evaluation/rollback policies."
                ]
            },
            {
                "name": "AI Engineer \u2014 EdgeVision Labs",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed mobile-first object detection and segmentation pipelines (MobileNetV3, EfficientDet) optimized with TensorRT and TFLite; reduced model size by 60% while maintaining >85% mAP on target classes.",
                    "Implemented on-device update mechanism and A/B testing framework to continuously evaluate model updates in the field.",
                    "Collaborated with embedded and product teams to integrate real-time CV capabilities into consumer apps; improved user retention for camera features by 18%.",
                    "Authored internal tooling for automated dataset labeling and augmentation that sped up dataset iteration by 3x."
                ]
            },
            {
                "name": "Data Scientist \u2014 OpenRetail Analytics",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Built demand-forecasting models (LSTM, gradient-boosted trees) for retail partners, decreasing stockouts by 22% and excess inventory by 15%.",
                    "Designed feature stores and ETL pipelines (Airflow + Spark) to supply production models with stable features.",
                    "Performed causal analysis and experiments to quantify pricing and promotion effects; presented findings to executive stakeholders to inform merchandising strategy."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Recommendation Engine",
                "description": "End-to-end system combining lightweight on-device embeddings with cloud re-ranking using transformer-based models to deliver personalized recommendations under tight latency constraints.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "FastAPI",
                    "Redis",
                    "Kubernetes",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "EdgeVision Mobile Object Detection",
                "description": "Optimized EfficientDet-based detection pipeline for mobile devices, including pruning, quantization, and custom NMS; delivered a reference SDK used by multiple partners.",
                "technologies": [
                    "TensorFlow",
                    "TFLite",
                    "TensorRT",
                    "ONNX",
                    "Android NDK"
                ],
                "year": 2020
            },
            {
                "name": "AutoML Hyperband Pipeline",
                "description": "Built a scalable AutoML experimentation platform leveraging Hyperband and Bayesian search to tune CV and NLP models; integrated results with CI to auto-promote best candidates to staging.",
                "technologies": [
                    "Ray Tune",
                    "Docker",
                    "MLflow",
                    "Kubernetes"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of Illinois at Urbana-Champaign",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S., Electrical Engineering"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "JAX",
            "Hugging Face",
            "Computer Vision",
            "Natural Language Processing",
            "MLOps",
            "Docker",
            "Kubernetes",
            "AWS (Sagemaker, ECS)",
            "GCP",
            "SQL",
            "Spark",
            "Model Quantization & Pruning",
            "CI/CD for ML"
        ],
        "achievements": [
            "Cut production transformer inference cost by 40% and 99th percentile latency by 65% through ONNX conversion, quantization, and batching.",
            "Published a peer-reviewed conference paper on efficient on-device object detection (ICCV workshop, 2020).",
            "Maintainer of an open-source MLOps utilities library with 1.2k GitHub stars and contributions from external partners.",
            "Led cross-functional migration of training pipelines to cloud-native infrastructure, reducing model release cycle by 3x."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "Certified Kubernetes Administrator (CKA)",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Maya R. Desai",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, inclusive, fast-paced teams that prioritize data-driven decision making, experimentation, and clear ownership.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "88 Market St, Apt 12B"
            },
            "phone": "+1-415-555-4827",
            "email": "maya.desai@email.com",
            "linkedin": "https://www.linkedin.com/in/mayar-desai",
            "github": "https://github.com/mayar-desai"
        },
        "summary": "Data scientist with 9+ years building and productionizing ML systems for consumer and healthcare products. Experienced end-to-end from discovery and feature engineering to model deployment and A/B testing. Strong background in time series, causal inference, and scalable ML pipelines using cloud-native tools.",
        "experience": [
            {
                "name": "Senior Data Scientist, BrightWave Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a customer churn prediction model that increased retention-targeting lift by 18% and reduced marketing spend by 12%.",
                    "Designed ML feature store and automated feature pipelines with Airflow and dbt, reducing data prep time by 60%.",
                    "Built end-to-end monitoring (data drift, performance) and retraining workflows using Seldon, Prometheus, and automated CI/CD; cut model rollback incidents to zero over 12 months.",
                    "Mentored a team of 4 data scientists and collaborated with product and engineering to scope experiments and interpret causal impacts using uplift modeling and randomized trials."
                ]
            },
            {
                "name": "Data Scientist, PulseHealth",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed predictive models for patient no-shows and readmission risk using gradient boosting and deep learning, improving early intervention rates by 22%.",
                    "Implemented real-time scoring pipeline on AWS (Lambda, SQS, DynamoDB) enabling near-instant risk alerts to care teams.",
                    "Partnered with clinicians to translate model outputs into operational workflows, and validated models with retrospective and prospective studies.",
                    "Improved model recall by 14% through feature engineering (temporal aggregation, embeddings) and class-imbalance strategies."
                ]
            },
            {
                "name": "Data Analyst, UrbanMetrics",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Built dashboards and metrics frameworks in Tableau and Looker to inform city planning decisions and optimize resource allocation.",
                    "Performed cohort and time-series analyses to quantify impact of policy changes; findings used to redesign three major initiatives.",
                    "Automated ETL workflows in Python and Airflow, lowering weekly report generation time from 10 hours to 1 hour."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Churn Scoring Platform",
                "description": "Designed and implemented a real-time churn scoring platform serving production API requests for personalized retention campaigns; included feature store, streaming features, and automated retraining.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "TensorFlow",
                    "Kafka",
                    "Airflow",
                    "Docker",
                    "AWS (EKS, Lambda, S3)"
                ],
                "year": 2022
            },
            {
                "name": "Causal Impact Framework for Pricing Experiments",
                "description": "Built a toolkit combining randomized experiments, difference-in-differences, and Bayesian structural time series to measure and forecast the impact of pricing changes across cohorts.",
                "technologies": [
                    "R",
                    "PyMC3",
                    "pandas",
                    "SQL",
                    "Tableau"
                ],
                "year": 2021
            },
            {
                "name": "Readmission Risk Model",
                "description": "End-to-end model to predict 30-day hospital readmission risk; integrated with clinician dashboard and triggered care-management workflows.",
                "technologies": [
                    "XGBoost",
                    "Spark",
                    "Airflow",
                    "AWS"
                ],
                "year": 2020
            },
            {
                "name": "Customer Segmentation with Embeddings",
                "description": "Used user-behavior embeddings and clustering to identify high-value micro-segments, enabling targeted marketing that improved conversion by 9%.",
                "technologies": [
                    "PyTorch",
                    "scikit-learn",
                    "SQL"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. in Data Science"
            },
            {
                "name": "University of Michigan",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Machine Learning",
            "Deep Learning",
            "Feature Engineering",
            "Time Series",
            "Causal Inference",
            "Model Deployment",
            "MLOps",
            "Airflow",
            "Spark",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "Tableau"
        ],
        "achievements": [
            "Delivered a production churn model that generated a 12% reduction in marketing cost while improving retention.",
            "Published internal best-practices for model monitoring adopted across three product teams.",
            "Presented a paper on uplift modeling at an industry conference (2022)."
        ],
        "certifications": [
            {
                "name": "Google Professional Machine Learning Engineer",
                "date": 2022
            },
            {
                "name": "AWS Certified Data Analytics - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Riya Kapoor",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, product-focused team that values experimentation, clear ownership, and continuous learning; mentoring junior engineers and adopting MLOps best practices.",
        "contact": {
            "address": {
                "region": "Bengaluru, India",
                "detail": "Koramangala"
            },
            "phone": "+91-9876543210",
            "email": "riya.kapoor88@example.com",
            "linkedin": "https://www.linkedin.com/in/riyakapoor",
            "github": "https://github.com/riyakapoor"
        },
        "summary": "AI Engineer with 7+ years of experience building and productionizing ML systems for recommendation, computer vision, and forecasting. Strong background in model development (PyTorch/TensorFlow), ML infrastructure (Kubernetes, Docker), and end-to-end deployment (CI/CD, feature stores). Passionate about optimizing model latency, improving data quality, and mentoring cross-functional teams to ship measurable product impact.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 Synapse Analytics (product AI team)",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time recommendation microservice using PyTorch, FastAPI, and Redis, reducing recommendation latency from 120ms to 40ms and increasing click-through by 12%.",
                    "Built scalable feature pipelines with Feast and Airflow; cut feature computation runtime by 50% and eliminated multiple data-skew incidents through monitoring and automated alerts.",
                    "Implemented model CI/CD with GitHub Actions and Kubernetes, enabling safe canary rollouts and automated rollback for model releases.",
                    "Mentored a team of 4 ML engineers and data scientists; introduced pair design reviews and model cards to improve reproducibility and reduce iteration time."
                ]
            },
            {
                "name": "AI Engineer \u2014 InnoTech Solutions",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed end-to-end computer vision pipelines for defect detection using TensorFlow and OpenCV; achieved a 92% precision and reduced manual QA effort by 70%.",
                    "Optimized model serving stack using TensorRT and ONNX runtime, improving throughput by 3x for batch inference workloads.",
                    "Collaborated with product and backend teams to define ML requirements, created A/B tests, and measured business KPIs tied to model updates.",
                    "Authored production monitoring dashboards (Prometheus + Grafana) for model drift, data quality, and latency; implemented retraining triggers based on drift thresholds."
                ]
            },
            {
                "name": "Data Science Intern \u2014 TechLabs",
                "date": {
                    "start": 2016,
                    "end": 2017
                },
                "bullets": [
                    "Built time-series forecasting models for demand prediction using XGBoost and LSTM; reduced inventory stockouts by 18% versus baseline heuristics.",
                    "Performed data exploration, feature engineering, and automated model evaluation pipelines for rapid prototyping."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Personalization Engine",
                "description": "End-to-end system for session-based personalization using a transformer-based encoder, online feature store, and low-latency serving. Integrated with product A/B framework and rollout automation.",
                "technologies": [
                    "PyTorch",
                    "Feast",
                    "Redis",
                    "FastAPI",
                    "Kubernetes"
                ],
                "year": 2023
            },
            {
                "name": "Automated Defect Detection Platform",
                "description": "Computer vision pipeline for automated inspection on manufacturing lines. Included data augmentation, model pruning, and edge deployment to NVIDIA Jetson.",
                "technologies": [
                    "TensorFlow",
                    "OpenCV",
                    "TensorRT",
                    "ONNX"
                ],
                "year": 2021
            },
            {
                "name": "Demand Forecasting Service",
                "description": "Hybrid model combining XGBoost and LSTM ensembles for multi-horizon demand forecasting with uncertainty estimates and automated retraining.",
                "technologies": [
                    "XGBoost",
                    "PyTorch",
                    "Airflow",
                    "Docker"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "Carnegie Mellon University \u2014 M.S. in Computer Science (Machine Learning)",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "Indian Institute of Technology Madras \u2014 B.Tech Computer Science",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "B.Tech Computer Science"
            }
        ],
        "skills": [
            "PyTorch",
            "TensorFlow",
            "Python",
            "SQL",
            "Kubernetes",
            "Docker",
            "Feast",
            "Airflow",
            "FastAPI",
            "XGBoost",
            "MLflow",
            "Model Serving",
            "MLOps",
            "Data Engineering"
        ],
        "achievements": [
            "Reduced recommendation service latency by 67% and increased CTR by 12% through model and infra optimizations.",
            "Designed production monitoring and drift-detection pipelines, cutting incident response time by 40%.",
            "Presented a poster on efficient transformer encoders at a regional ML workshop (2022).",
            "Led a cross-team migration to a standardized feature store, improving feature reuse and reducing duplicate pipelines by 60%."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven team that values clear communication, continuous learning, and practical deployment of research into production systems.",
        "contact": {
            "address": {
                "region": "Boston, MA, USA",
                "detail": "Cambridge, MA \u2014 near MIT/Kendall Square"
            },
            "phone": "+1-617-555-4821",
            "email": "aisha.rahman89@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman89",
            "github": "https://github.com/aishar89"
        },
        "summary": "AI Engineer with 6+ years of experience building and deploying production ML systems. Strong background in deep learning, model optimization, and MLOps. Proven track record improving model latency and accuracy, automating training pipelines, and collaborating with cross-functional teams to deliver scalable AI features.",
        "experience": [
            {
                "name": "Lead AI Engineer \u2014 NovaHealth Technologies",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of a multimodal diagnostic model (imaging + EHR) that increased early-detection accuracy by 18% and reduced false positives by 22%.",
                    "Built and maintained end-to-end MLOps pipelines using Kubeflow, MLflow, and Terraform; reduced model release cycle from 6 weeks to 10 days.",
                    "Optimized model inference using TensorRT and ONNX, cutting latency by 60% and enabling edge deployment on GPU-enabled medical devices.",
                    "Mentored a team of 4 ML engineers and data scientists; instituted code review and model governance practices resulting in more reproducible experiments.",
                    "Collaborated with product and regulatory teams to produce explainability reports and model validation artifacts for FDA pre-submission review."
                ]
            },
            {
                "name": "Senior Machine Learning Engineer \u2014 Veridian Analytics",
                "date": {
                    "start": 2017,
                    "end": 2020
                },
                "bullets": [
                    "Architected recommendation and ranking systems using deep learning (Siamese networks, Transformers) improving CTR by 12% for core product.",
                    "Deployed real-time feature store with Redis and Feast and implemented streaming feature pipelines using Kafka and Spark Structured Streaming.",
                    "Implemented automated hyperparameter tuning with Ray Tune, delivering consistent 4-6% model performance improvements across tasks.",
                    "Introduced model monitoring dashboards (Prometheus + Grafana) and drift detection alerts, reducing time-to-detection for production issues by 70%."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 OpenSight Labs (startup)",
                "date": {
                    "start": 2015,
                    "end": 2017
                },
                "bullets": [
                    "Built computer vision models for industrial inspection (CNNs, transfer learning) deployed on edge devices; achieved 95% defect detection recall.",
                    "Designed data augmentation and synthetic data pipelines to address class imbalance for small datasets.",
                    "Collaborated directly with customers to integrate models into manufacturing QA systems, providing on-site optimization and tuning."
                ]
            }
        ],
        "projects": [
            {
                "name": "EdgeCardio",
                "description": "On-device model for arrhythmia detection combining 1D CNNs on ECG signals and lightweight attention blocks for resource-constrained wearable hardware. Implemented quantization-aware training and deployment with ONNX Runtime Mobile.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "Quantization-aware training",
                    "C++ (embedded inference)"
                ],
                "year": 2023
            },
            {
                "name": "MedExplain",
                "description": "Explainability toolkit for clinical models producing counterfactuals and feature attributions tailored to clinicians, integrating SHAP and custom saliency visualizations.",
                "technologies": [
                    "SHAP",
                    "scikit-learn",
                    "FastAPI",
                    "Docker",
                    "React (visualization)"
                ],
                "year": 2021
            },
            {
                "name": "Realtime Recommender",
                "description": "Low-latency ranking stack combining embedding retrieval with lightweight Transformer re-ranker, deployed with Kafka and Redis for sub-50ms end-to-end latency.",
                "technologies": [
                    "TensorFlow",
                    "Kafka",
                    "Redis",
                    "TensorFlow Serving",
                    "Ray"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Master of Science in Computer Science \u2014 Northeastern University",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. Computer Science (Machine Learning specialization)"
            },
            {
                "name": "Bachelor of Science in Electrical Engineering \u2014 University of Toronto",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.Sc. Electrical Engineering"
            }
        ],
        "skills": [
            "Deep Learning (CNNs, Transformers)",
            "PyTorch",
            "TensorFlow",
            "MLOps (Kubeflow, MLflow, Terraform)",
            "Model optimization (quantization, pruning, TensorRT)",
            "Feature stores & data engineering (Feast, Kafka, Spark)",
            "Model monitoring & evaluation",
            "Python, SQL, Docker, Kubernetes",
            "ONNX, inference engineering",
            "Experimentation & A/B testing"
        ],
        "achievements": [
            "Published paper at ICLR Workshop on multimodal fusion for clinical prediction (2022).",
            "Reduced inference latency by 60% and memory footprint by 45% on a production diagnostic model through optimization and quantization.",
            "Speaker at MLOps World 2023 on productionizing clinical AI pipelines."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Certified Kubernetes Application Developer (CKAD)",
                "date": 2021
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, emphasis on mentorship, reproducibility, and pragmatic experimentation",
        "contact": {
            "address": {
                "region": "Cambridge, MA, USA",
                "detail": "1 Broadway, Cambridge, MA 02139"
            },
            "phone": "+1 (617) 555-0136",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data scientist with 9+ years of experience building and deploying ML systems in healthcare and retail. Strong background in statistical modeling, time-series forecasting, MLOps, and applied NLP. Proven track record of shipping production models that improved clinical outcomes and reduced costs. Comfortable leading cross-functional teams and translating business problems into data-driven solutions.",
        "experience": [
            {
                "name": "Senior Data Scientist \u2014 Nimbus Health",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a hospital readmission risk model that reduced 30-day readmissions by 12% for pilot hospitals; model served 150k+ predictions/month.",
                    "Designed and implemented robust ML feature store and CI/CD model pipeline using MLflow, Docker, and GitHub Actions, reducing model deployment time from weeks to hours.",
                    "Collaborated with clinicians to define interpretable model outputs and implemented SHAP-based explainability dashboards used in care-team workflows.",
                    "Mentored a team of 4 data scientists and established best practices for model validation, data lineage, and monitoring (drift detection, automated retraining triggers)."
                ]
            },
            {
                "name": "Data Scientist \u2014 ThermoSense Analytics",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built end-to-end demand forecasting solution for a national retail client using hybrid ARIMA+XGBoost models, yielding a 15% improvement in forecast accuracy and reducing inventory stockouts by 9%.",
                    "Developed anomaly detection and early-warning systems for sensor and transactional data using isolation forests and probabilistic models.",
                    "Implemented A/B testing framework and statistical analysis pipeline for pricing experiments; produced experiment reports that directly informed pricing strategy.",
                    "Worked closely with data engineers to productionize Spark-based ETL jobs on AWS EMR and orchestrate workflows with Apache Airflow."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 OpenFarm Labs",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Designed convolutional neural network models for plant disease classification (PyTorch), achieving 92% top-1 accuracy on held-out field data.",
                    "Built scalable image ingestion and labeling pipeline using AWS S3 and Lambda, reducing labeling turnaround by 40%.",
                    "Collaborated with product and field teams to integrate ML outputs into mobile apps used by agronomists, improving disease detection speed in field trials."
                ]
            },
            {
                "name": "Research Intern \u2014 Center for Applied Statistics",
                "date": {
                    "start": 2015,
                    "end": 2016
                },
                "bullets": [
                    "Conducted statistical analysis and experimental design for health-behavior studies; implemented mixed-effects models and survival analysis.",
                    "Co-authored technical reports and presented findings to stakeholders, contributing to grant proposals that secured research funding."
                ]
            }
        ],
        "projects": [
            {
                "name": "ReadmitPredict",
                "description": "Production-ready readmission risk scoring system for hospital EHRs combining structured features, embedding-based patient history, and interpretable explanations for clinicians.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "SHAP",
                    "MLflow",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "DemandCast",
                "description": "Hybrid time-series forecasting framework combining statistical seasonal decomposition and gradient-boosted regressors for SKU-level demand forecasting across 500+ stores.",
                "technologies": [
                    "pandas",
                    "Prophet",
                    "XGBoost",
                    "Spark",
                    "Airflow"
                ],
                "year": 2020
            },
            {
                "name": "AutoML Model Ops Pipeline",
                "description": "Automated pipeline for model training, validation, deployment, and monitoring that standardizes training runs, model artifact storage, and drift alerts.",
                "technologies": [
                    "Docker",
                    "Kubernetes",
                    "MLflow",
                    "Terraform",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "SentimentAssist",
                "description": "NLP service to extract patient sentiment and topic signals from free-text feedback to prioritize cases for care-team follow-up.",
                "technologies": [
                    "spaCy",
                    "TensorFlow",
                    "BERT",
                    "Flask"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Columbia University \u2014 M.S. Data Science",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "Master of Science in Data Science"
            },
            {
                "name": "University of Dhaka \u2014 B.S. Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "Bachelor of Science in Computer Science"
            }
        ],
        "skills": [
            "Python",
            "pandas",
            "NumPy",
            "scikit-learn",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "SQL",
            "Spark",
            "Airflow",
            "MLflow",
            "Docker",
            "Kubernetes",
            "AWS (S3, EC2, SageMaker)",
            "GCP",
            "Time-series forecasting",
            "Causal inference",
            "NLP",
            "Experiment design & A/B testing",
            "Data visualization (Tableau, matplotlib, seaborn)"
        ],
        "achievements": [
            "Led model initiative that reduced 30-day hospital readmissions by 12% in pilot deployments.",
            "Deployed production models serving 150k+ predictions/month with automated monitoring and retraining.",
            "Reduced infrastructure and compute costs for model training by ~28% through optimized pipelines and spot instances.",
            "Co-authored a peer-reviewed paper on applied time-series forecasting in a healthcare informatics journal."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "IBM Data Science Professional Certificate (Coursera)",
                "date": 2017
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Maya R. Singh",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, growth-minded team with strong engineering rigor, emphasis on reproducibility, mentorship, and practical research-to-production pathways.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (510) 555-4821",
            "email": "maya.singh@example.com",
            "linkedin": "https://www.linkedin.com/in/mayarisingh",
            "github": "https://github.com/mayarisingh"
        },
        "summary": "AI Engineer with 9+ years building and shipping production ML systems and LLM-powered applications. Deep experience in model engineering (PyTorch/TensorFlow), retrieval-augmented generation, inference optimization, and MLOps on cloud platforms. Proven track record reducing latency and cost while improving model quality and observability. Strong collaborator who bridges research and product engineering.",
        "experience": [
            {
                "name": "Neurolytics Inc. \u2014 Senior AI Engineer",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and productionization of a retrieval-augmented generation (RAG) system powering a customer support assistant \u2014 integrated vector search (FAISS) with an LLM and productionized via Kubernetes microservices.",
                    "Reduced median inference latency by 45% and cost-per-query by 30% through model distillation, dynamic batching, and mixed-precision quantization.",
                    "Built end-to-end MLOps pipelines (training \u2192 validation \u2192 deployment) using Terraform, GitHub Actions, and ArgoCD; created automated canary rollout and drift-detection workflows.",
                    "Implemented real-time monitoring and explainability dashboards (Prometheus + Grafana + SHAP summaries) to track model performance and data distribution shifts.",
                    "Mentored a team of 4 ML Engineers; ran sprint-level technical reviews and established model testing and reproducibility standards."
                ]
            },
            {
                "name": "Acuity Health \u2014 Machine Learning Engineer",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed predictive models for patient readmission and resource allocation using XGBoost and TensorFlow; improved AUC by 0.07 over baseline.",
                    "Designed and maintained ETL and feature pipelines in Airflow and Spark, enabling near-real-time feature availability for clinical models.",
                    "Deployed models to AWS SageMaker and containerized inference services; implemented endpoint autoscaling and request-level routing.",
                    "Collaborated with clinicians and product managers to translate business needs into measurable ML objectives and evaluation plans."
                ]
            },
            {
                "name": "BrightData Solutions \u2014 Data Engineer",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Built scalable ETL pipelines using Spark and Kafka to ingest and normalize terabytes of customer and event data daily.",
                    "Implemented a Snowflake data warehouse and optimized query patterns, reducing dashboard latency by 60%.",
                    "Authored common data quality frameworks and unit/integration tests for pipelines, improving reliability and deployment speed."
                ]
            }
        ],
        "projects": [
            {
                "name": "DocAssist \u2014 LLM-powered Document Assistant",
                "description": "Built a production RAG pipeline to answer domain-specific queries over company documents, with vector indexing, chunking strategies, and confidence scoring.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "FAISS",
                    "Docker",
                    "Kubernetes",
                    "AWS EKS"
                ],
                "year": 2023
            },
            {
                "name": "Model Compression Toolkit",
                "description": "Created a set of utilities to perform quantization-aware training, structured pruning, and post-training quantization to shrink models for edge deployment while preserving accuracy.",
                "technologies": [
                    "TensorFlow",
                    "PyTorch",
                    "ONNX",
                    "TensorRT"
                ],
                "year": 2022
            },
            {
                "name": "Realtime Inference Orchestrator",
                "description": "Developed an orchestration layer that dynamically routes requests between large and distilled models based on latency/SLA and input complexity, optimizing cost-performance tradeoffs.",
                "technologies": [
                    "Kubernetes",
                    "Istio",
                    "gRPC",
                    "Prometheus"
                ],
                "year": 2022
            },
            {
                "name": "Clinical Readmission Predictor",
                "description": "End-to-end pipeline from EHR feature engineering to deployment predicting 30-day readmission risk; included interpretability layer for clinician review.",
                "technologies": [
                    "Spark",
                    "XGBoost",
                    "Airflow",
                    "Snowflake"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S., Computer Science (Machine Learning)"
            },
            {
                "name": "University of Michigan, Ann Arbor",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S., Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "Hugging Face",
            "Large Language Models (LLMs)",
            "Retrieval-Augmented Generation (RAG)",
            "Model Distillation & Quantization",
            "MLOps",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, EKS, Lambda)",
            "GCP",
            "Spark",
            "SQL",
            "Airflow",
            "ONNX",
            "Prometheus & Grafana",
            "scikit-learn",
            "pandas"
        ],
        "achievements": [
            "Published workshop paper on efficient RAG architectures (NeurIPS Workshop, 2022).",
            "Reduced production inference costs by 30% and latency by 45% at Neurolytics through model engineering and orchestration changes.",
            "Introduced company-wide model testing and CI for ML leading to 40% faster deployment cycles.",
            "Mentored and grew a team of ML engineers; two mentees promoted to senior roles."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Asha Rao",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, inclusive; values mentorship, cross-functional partnership, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0192",
            "email": "asha.rao@example.com",
            "linkedin": "https://www.linkedin.com/in/asharao",
            "github": "https://github.com/asharao"
        },
        "summary": "Data Scientist with 10+ years of experience building production ML systems for fintech and e-commerce. Strong background in supervised learning, time-series forecasting, recommendation systems, and MLOps. Experienced in end-to-end model development, deployment, and monitoring; comfortable partnering with engineering and product teams to deliver measurable business impact.",
        "experience": [
            {
                "name": "Luma Financial \u2014 Senior Data Scientist",
                "date": {
                    "start": 2020,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a credit risk scoring system using XGBoost and PyTorch that reduced default rates by 14% and lowered provisioning by $2.1M annually.",
                    "Designed and implemented automated feature pipelines (Spark + Airflow) and model retraining workflows (MLflow), reducing model refresh time from weekly manual runs to continuous scheduled retraining.",
                    "Built real-time scoring service (FastAPI, Docker, Kubernetes) integrated with transaction processing; achieved 99.9% uptime and sub-200ms latency for scoring requests.",
                    "Mentored a team of 4 data scientists and collaborated with engineering to integrate model explainability (SHAP) into underwriting dashboards for compliance and product teams."
                ]
            },
            {
                "name": "Shopwise \u2014 Data Scientist",
                "date": {
                    "start": 2017,
                    "end": 2020
                },
                "bullets": [
                    "Developed a hybrid recommendation engine (matrix factorization + content-based embeddings) that increased click-through-rate on recommendation panels by 28% and drove a 6% lift in average order value.",
                    "Led experimentation and A/B testing framework to evaluate personalization and promotions, enabling data-driven rollout of pricing and targeting strategies.",
                    "Worked with product and analytics to produce key ML-backed insights for customer segmentation and lifetime value modelling using survival analysis and gradient boosting.",
                    "Reduced feature computation latency by migrating key pipelines from batch Hadoop jobs to Spark streaming, enabling near real-time personalization."
                ]
            },
            {
                "name": "MediCore Analytics \u2014 Data Analyst",
                "date": {
                    "start": 2014,
                    "end": 2017
                },
                "bullets": [
                    "Built ETL pipelines and dashboards (Tableau) for clinical operations to track KPIs; improved data quality and reduced report generation time by 60%.",
                    "Performed cohort analyses and time-to-event studies to inform clinical program decisions, contributing to improved patient retention strategies.",
                    "Collaborated with engineering to standardize data schema and implement logging practices that improved downstream model reliability."
                ]
            }
        ],
        "projects": [
            {
                "name": "ChurnPredict \u2014 Customer Churn Prediction",
                "description": "End-to-end churn prediction system for subscription product combining behavioral features, transaction time-series, and survival analysis to prioritize retention campaigns.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "XGBoost",
                    "Pandas",
                    "Spark",
                    "Airflow",
                    "MLflow"
                ],
                "year": 2022
            },
            {
                "name": "Realtime Recommender",
                "description": "Low-latency recommendation service using item embeddings and online feature stores for personalization across web and mobile; included A/B testing and continuous learning.",
                "technologies": [
                    "TensorFlow",
                    "Faiss",
                    "Redis",
                    "Kafka",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2021
            },
            {
                "name": "MLOps Platform & Model Governance",
                "description": "Built standardized CI/CD pipelines for model training and deployment, integrated model versioning, drift detection, and automated alerting to reduce model incidents.",
                "technologies": [
                    "GitHub Actions",
                    "MLflow",
                    "Prometheus",
                    "Grafana",
                    "AWS (S3, EKS)"
                ],
                "year": 2023
            },
            {
                "name": "Conversational Support Assistant (LLM Integration)",
                "description": "Prototype of a customer support assistant using retrieval-augmented generation and fine-tuned LLMs to answer billing/product questions and auto-generate ticket summaries.",
                "technologies": [
                    "PyTorch",
                    "Hugging Face Transformers",
                    "ElasticSearch",
                    "LangChain",
                    "Docker"
                ],
                "year": 2024
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2012,
                    "end": 2014
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "Indian Institute of Technology Madras",
                "date": {
                    "start": 2008,
                    "end": 2012
                },
                "degree": "B.Tech Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "XGBoost",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLflow",
            "Hugging Face",
            "NLP",
            "Time-series forecasting",
            "Causal inference",
            "Experimentation",
            "Data visualization"
        ],
        "achievements": [
            "Reduced loan default rate by 14% through a new risk scoring model, saving $2.1M annually.",
            "Increased recommendation CTR by 28% and drove a 6% lift in average order value at Shopwise.",
            "Presented a talk on productionizing ML pipelines at regional ML Summit 2023.",
            "Published a workshop paper on sequence-based customer lifetime models (workshop proceedings, 2020)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            },
            {
                "name": "IBM Data Science Professional Certificate",
                "date": 2018
            }
        ],
        "total_experience": 11,
        "availability": true
    },
    {
        "name": "Maya R. Singh",
        "title": "AI Engineer",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, inclusive, product-focused team that values engineering rigor, end-to-end ownership, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-6823",
            "email": "maya.singh@example.com",
            "linkedin": "https://www.linkedin.com/in/mayarisingh",
            "github": "https://github.com/mayarisingh"
        },
        "summary": "AI Engineer with 10+ years building production ML systems and research-driven models for healthcare, finance, and robotics. Strong background in model architecture, MLOps, and model compression. Experienced taking models from prototype to scalable services on cloud and edge, optimizing latency and cost while maintaining accuracy.",
        "experience": [
            {
                "name": "Senior AI Engineer \u2014 Nimbus Labs",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led design and deployment of a real-time transaction risk scoring service that processes 20k TPS; reduced average prediction latency from 85ms to 12ms through model quantization, pruning, and optimized inference pipelines.",
                    "Built end-to-end ML platform components (feature store, model registry, CI/CD) using Kafka, Spark, Docker, and Kubernetes; cut model deployment time from weeks to hours.",
                    "Collaborated with product and fraud ops to improve detection precision, reducing false positives by 28% while improving true positive rate by 12%, saving ~$3.2M annually.",
                    "Mentored a team of 4 ML engineers and established code review, testing, and monitoring standards (unit tests for data pipelines, model drift alerts, SLO dashboards)."
                ]
            },
            {
                "name": "Data Scientist \u2014 Aurelia Health",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed predictive models for patient readmission and resource allocation using XGBoost and deep learning; increased bed utilization forecasting accuracy by 18%.",
                    "Created an explainable ML dashboard (SHAP-based) used by clinicians to interpret model recommendations, improving clinician adoption of ML insights by 35%.",
                    "Led migration of training workloads to cloud (GCP) with autoscaling training clusters, decreasing training costs by 40% and accelerating model iteration cycles."
                ]
            },
            {
                "name": "Machine Learning Engineer \u2014 Veridian Robotics",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Implemented perception and control ML models for autonomous mobile platforms using TensorFlow and PyTorch; improved object detection mAP by 9% through data augmentation and architecture tweaks.",
                    "Designed lightweight CNNs and converted models to ONNX for deployment on edge devices, achieving real-time performance under strict resource limits.",
                    "Integrated continuous integration for model training and evaluation, enabling reproducible experiments and faster benchmarking."
                ]
            },
            {
                "name": "Research Intern \u2014 UC Berkeley AI Lab",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "bullets": [
                    "Researched model compression techniques and co-authored a workshop paper on structured pruning methods for CNNs.",
                    "Implemented experimental baselines in Theano/TensorFlow and contributed code to open-source research repositories."
                ]
            }
        ],
        "projects": [
            {
                "name": "Realtime Fraud Detection",
                "description": "Production microservice for scoring transactions in real-time with low latency. End-to-end system includes streaming feature computation, model serving, and alerting.",
                "technologies": [
                    "Python",
                    "PyTorch",
                    "Kafka",
                    "Spark",
                    "Docker",
                    "Kubernetes",
                    "AWS"
                ],
                "year": 2023
            },
            {
                "name": "Neural Compression Toolkit",
                "description": "Toolkit for model pruning, quantization, and knowledge distillation to reduce inference cost on CPU and edge accelerators. Integrated with CI to validate accuracy vs size tradeoffs.",
                "technologies": [
                    "PyTorch",
                    "ONNX",
                    "TensorRT",
                    "NumPy"
                ],
                "year": 2022
            },
            {
                "name": "Explainable ML Dashboard",
                "description": "Interactive dashboard exposing feature importances, SHAP visualizations, and model health metrics for clinical users to interpret predictions and monitor drift.",
                "technologies": [
                    "Python",
                    "scikit-learn",
                    "SHAP",
                    "FastAPI",
                    "React"
                ],
                "year": 2020
            },
            {
                "name": "Edge Anomaly Detector",
                "description": "Lightweight time-series anomaly detection deployed on edge devices for predictive maintenance; supports on-device retraining with constrained resources.",
                "technologies": [
                    "TensorFlow Lite",
                    "C++",
                    "Docker",
                    "GCP"
                ],
                "year": 2019
            }
        ],
        "education": [
            {
                "name": "Stanford University",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. Computer Science (AI specialization)"
            },
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. Electrical Engineering & Computer Sciences"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "SQL",
            "Spark",
            "Kafka",
            "Docker",
            "Kubernetes",
            "AWS",
            "GCP",
            "MLOps",
            "Model compression",
            "Statistics",
            "Causal inference",
            "NLP"
        ],
        "achievements": [
            "Reduced production model latency by 86% (85ms -> 12ms) through quantization, pruning, and inference optimization.",
            "Delivered fraud detection improvements saving ~$3.2M annually via model and workflow enhancements.",
            "Co-author of a workshop paper on structured pruning; contributed open-source compression utilities used internally at two companies.",
            "Built ML platform features that cut model deployment time from weeks to hours across multiple teams."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "Google Cloud Professional Data Engineer",
                "date": 2020
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2019
            }
        ],
        "total_experience": 12,
        "availability": true
    },
    {
        "name": "Dr. Maya R. Singh",
        "title": "AI Researcher",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven, open-source friendly, and results-oriented. Values reproducibility, mentorship, and continuous learning.",
        "contact": {
            "address": {
                "region": "Cambridge, MA, USA",
                "detail": "Based in Cambridge; open to hybrid roles and willing to relocate for on-site positions."
            },
            "phone": "+1-617-555-0147",
            "email": "maya.singh.ai@example.com",
            "linkedin": "https://www.linkedin.com/in/maya-r-singh",
            "github": "https://github.com/mayar-singh"
        },
        "summary": "AI researcher with 8+ years of experience developing state-of-the-art deep learning models for computer vision and multimodal reasoning. Strong track record of publishing in top-tier conferences, productionizing research prototypes, and leading cross-functional teams to deploy scalable ML systems. Expertise in foundation models, representation learning, and principled evaluation.",
        "experience": [
            {
                "name": "Senior Research Scientist, DeepVision Labs",
                "date": {
                    "start": 2022,
                    "end": null
                },
                "bullets": [
                    "Led research on multimodal representation learning, delivering a vision-language model that improved cross-modal retrieval mAP by 18% over baseline.",
                    "Designed and implemented contrastive and generative pretraining pipelines using PyTorch and JAX, scaling experiments to 64 A100 GPUs with reproducible hyperparameter sweeps.",
                    "Collaborated with product and infra teams to productionize model inference with TensorRT and ONNX, reducing latency by 40% while maintaining accuracy.",
                    "Mentored a team of 4 junior researchers and interns; authored internal best-practices for evaluation and dataset curation."
                ]
            },
            {
                "name": "Machine Learning Researcher, OpenSense AI",
                "date": {
                    "start": 2019,
                    "end": 2022
                },
                "bullets": [
                    "Developed robust data augmentation and domain adaptation techniques for medical imaging, increasing diagnostic classification AUC from 0.82 to 0.90 on held-out hospital data.",
                    "Published 3 papers in peer-reviewed venues (ICLR, MICCAI) and presented results to clinical partners to guide deployment decisions.",
                    "Built end-to-end training and CI/CD pipelines with MLflow and Kubernetes for continuous model training and evaluation."
                ]
            },
            {
                "name": "Postdoctoral Researcher, Vision & Learning Lab, MIT",
                "date": {
                    "start": 2017,
                    "end": 2019
                },
                "bullets": [
                    "Researched unsupervised representation learning methods; co-authored a paper that introduced a novel attention-based pretraining objective.",
                    "Implemented large-scale experiments and benchmarked methods across multiple datasets, establishing reproducible evaluation protocols."
                ]
            }
        ],
        "projects": [
            {
                "name": "MultiModal-CLIP++",
                "description": "Extended contrastive vision-language pretraining with hierarchical curriculum learning and hard-negative mining; produced embeddings used for retrieval and captioning tasks across 7 datasets.",
                "technologies": [
                    "PyTorch",
                    "Transformer",
                    "FAISS",
                    "Horovod",
                    "W&B"
                ],
                "year": 2023
            },
            {
                "name": "RobustMedSeg",
                "description": "End-to-end pipeline for robust medical image segmentation using self-supervised pretraining and domain adaptation; integrated uncertainty estimation for clinical triage.",
                "technologies": [
                    "TensorFlow",
                    "MONAI",
                    "Docker",
                    "Kubernetes"
                ],
                "year": 2021
            },
            {
                "name": "OpenEval: Reproducible Evaluation Suite",
                "description": "Open-source evaluation framework for standardized benchmarks, metrics, and reproducible model cards used by internal teams and community contributors.",
                "technologies": [
                    "Python",
                    "PyTest",
                    "MLflow",
                    "GitHub Actions"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "Massachusetts Institute of Technology (MIT) \u2014 Ph.D., Computer Science",
                "date": {
                    "start": 2013,
                    "end": 2017
                },
                "degree": "Ph.D. in Computer Science (Machine Learning)"
            },
            {
                "name": "University of California, Berkeley \u2014 M.S., Electrical Engineering & Computer Sciences",
                "date": {
                    "start": 2011,
                    "end": 2013
                },
                "degree": "M.S. in EECS"
            },
            {
                "name": "University of Delhi \u2014 B.Tech., Computer Science",
                "date": {
                    "start": 2007,
                    "end": 2011
                },
                "degree": "B.Tech. in Computer Science"
            }
        ],
        "skills": [
            "Deep Learning",
            "Computer Vision",
            "Multimodal Learning",
            "Representation Learning",
            "PyTorch",
            "JAX",
            "TensorFlow",
            "Distributed Training",
            "Model Deployment (Docker, Kubernetes, ONNX)",
            "Research Design & Scientific Writing",
            "SQL",
            "Python"
        ],
        "achievements": [
            "Authored 8 peer-reviewed publications including ICLR and MICCAI; h-index: 11",
            "Contributed to open-source libraries used by internal and external teams; core maintainer for an evaluation toolkit with 1k+ stars",
            "Recipient of DeepVision Labs Research Excellence Award (2023) for advancing multimodal retrieval methods",
            "Scaled pretraining pipelines to 64 A100 GPUs, enabling 3x faster experimentation and reducing iteration cycle time by 60%"
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2021
            },
            {
                "name": "DeepLearning.AI: Generative AI Specialization",
                "date": 2023
            }
        ],
        "total_experience": 8,
        "availability": true
    },
    {
        "name": "Rowan Patel",
        "title": "Data Scientist",
        "work_type": "Remote",
        "prefer_culture": "Collaborative, data-driven teams that prioritize reproducibility, clear metrics, and continuous learning. I thrive in environments with high ownership, transparent feedback, and strong product\u2013engineering\u2013data partnership.",
        "contact": {
            "address": {
                "region": "San Francisco, CA",
                "detail": "Remote (based in Mission District). Authorized to work in the U.S."
            },
            "phone": "+1 (415) 555-0132",
            "email": "rowan.patel@example.com",
            "linkedin": "https://www.linkedin.com/in/rowan-patel-ds",
            "github": "https://github.com/rowanpatel"
        },
        "summary": "Data scientist with 8+ years building and shipping ML systems in healthcare and analytics. Experienced across the full ML lifecycle: problem framing, feature engineering, model development, production deployment, monitoring, and cross-functional stakeholder communication. Strong background in applied ML (supervised, time-series, NLP), MLOps, and causal inference to drive measurable business impact.",
        "experience": [
            {
                "name": "Nexa Health \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development and production deployment of a hospital readmission risk model used in clinician workflows; improved AUC by 0.12 versus baseline and reduced 30-day readmissions by estimated 8% in pilot.",
                    "Designed end-to-end ML pipeline (data ingestion, feature store, model training, CI/CD, monitoring) using AWS SageMaker, Fargate, MLflow and Terraform; reduced model rollout time from weeks to days.",
                    "Implemented model explainability (SHAP) and fairness checks; partnered with clinicians to translate model outputs into actionable care plans and acceptance criteria.",
                    "Mentored a team of 4 data scientists and ran weekly model reviews, raising overall model quality and reproducibility across teams."
                ]
            },
            {
                "name": "OptiScale Analytics \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Built customer churn and LTV models for SaaS clients using gradient boosting and survival analysis; model-driven interventions recovered ~$1.2M annual revenue for a major client.",
                    "Led time-series demand forecasting initiative using Prophet and LSTM ensembles on Spark; improved forecast accuracy by 25% and optimized inventory allocation.",
                    "Productized models as microservices with Docker, Kubernetes, Airflow and CI pipelines; decreased model deployment incidents by 70%.",
                    "Partnered with product and sales to design A/B tests and interpret results; improved retention via targeted experiments."
                ]
            },
            {
                "name": "Skyline Labs \u2014 ML Engineer",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Developed low-latency inference pipelines for NLP and CV models; optimized serving stack to reduce 95th percentile latency by 60%.",
                    "Implemented feature validation and data quality monitoring; detected and resolved multiple data drift incidents prior to production impact.",
                    "Collaborated with research team to productionize a BERT-based clinical text extractor used for downstream analytics."
                ]
            }
        ],
        "projects": [
            {
                "name": "PatientReadmit Predictor",
                "description": "End-to-end EHR-based readmission risk system: data ingestion, feature store, model training (XGBoost + Transformer-derived embeddings), model explainability, and deployment to SageMaker endpoints with CI/CD and monitoring.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "PyTorch",
                    "AWS SageMaker",
                    "MLflow",
                    "Terraform",
                    "Docker",
                    "SHAP"
                ],
                "year": 2023
            },
            {
                "name": "AutoDemand Forecast",
                "description": "Multi-horizon demand forecasting pipeline combining classical (Prophet) and deep-learning (LSTM/Temporal CNN) models with probabilistic outputs; scheduled and monitored via Airflow and Spark.",
                "technologies": [
                    "Python",
                    "Prophet",
                    "TensorFlow",
                    "Apache Spark",
                    "Airflow",
                    "Docker"
                ],
                "year": 2020
            },
            {
                "name": "Customer Churn Ensemble",
                "description": "Built an ensemble churn prediction system with feature engineering, class-imbalance handling, calibrated probabilities, and SHAP-based explanations for marketing targeting.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "pandas",
                    "SHAP",
                    "PostgreSQL"
                ],
                "year": 2019
            },
            {
                "name": "Clinical NLP Extractor",
                "description": "Named-entity and relation extraction pipeline for clinical notes using spaCy and fine-tuned BERT, packaged as a REST service and integrated into analytics dashboards.",
                "technologies": [
                    "spaCy",
                    "Transformers (Hugging Face)",
                    "FastAPI",
                    "Docker"
                ],
                "year": 2022
            }
        ],
        "education": [
            {
                "name": "University of Edinburgh",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "degree": "MSc Data Science"
            },
            {
                "name": "University of Mumbai",
                "date": {
                    "start": 2012,
                    "end": 2016
                },
                "degree": "BSc Computer Science"
            }
        ],
        "skills": [
            "Python",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "numpy",
            "SQL",
            "Apache Spark",
            "AWS (SageMaker, Lambda, S3, EKS)",
            "GCP",
            "Docker",
            "Kubernetes",
            "MLflow",
            "Airflow",
            "Model monitoring",
            "Causal inference",
            "A/B testing",
            "NLP",
            "Time-series forecasting",
            "Statistics"
        ],
        "achievements": [
            "Deployed production ML platform that reduced model rollout time from weeks to days.",
            "Pilot of readmission model estimated to lower 30-day readmissions by 8% in participating hospitals.",
            "Implemented monitoring and CI/CD practices that cut production incidents by 70%.",
            "Delivered model-driven interventions that recovered approximately $1.2M ARR for a client."
        ],
        "certifications": [
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "Coursera \u2014 Advanced Machine Learning Specialization",
                "date": 2019
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Morgan Lee",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, experiment-oriented environment that values mentorship, clear metrics, and product impact.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1-415-555-0196",
            "email": "morgan.lee96@example.com",
            "linkedin": "https://www.linkedin.com/in/morgan-lee-96",
            "github": "https://github.com/morganlee96"
        },
        "summary": "Data Scientist with 8+ years experience building production ML systems and analytics platforms for e-commerce and healthcare. Strong background in end-to-end model development, feature engineering, causal inference, and scalable data pipelines. Experienced in mentoring teams and translating business requirements into measurable models and experiments.",
        "experience": [
            {
                "name": "Senior Data Scientist, Nimbus Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led development of personalized recommendation models that increased click-through rate by 18% and purchase conversion by 12% using hybrid collaborative + content-based architectures.",
                    "Designed and deployed A/B testing framework and experimentation dashboard, reducing experiment rollout time from 3 weeks to 3 days.",
                    "Built real-time feature store and inference service (Kafka + Redis) to serve low-latency predictions for recommendation and fraud models.",
                    "Mentored 4 junior data scientists, instituted code review practices, and improved onboarding documentation and reproducibility."
                ]
            },
            {
                "name": "Data Scientist, BrightMart (e-commerce)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed customer churn and lifetime value (LTV) models using gradient boosting and survival analysis; enabled targeted retention campaigns that reduced churn by 9%.",
                    "Built end-to-end sales forecasting pipeline with Prophet and LightGBM, improving 4-week horizon forecast MAPE by 22%.",
                    "Collaborated with product and engineering to productionize models using Docker, Airflow, and AWS SageMaker leading to 99.9% uptime of prediction services."
                ]
            },
            {
                "name": "Junior Data Scientist, CityHealth",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Created predictive models for patient no-shows and resource utilization leading to a 10% improvement in clinic scheduling efficiency.",
                    "Performed causal analyses and cohort studies to evaluate program interventions; results informed policy changes adopted across 5 clinics.",
                    "Automated ETL pipelines using Python and SQL to integrate clinical and billing data for analytics use cases."
                ]
            }
        ],
        "projects": [
            {
                "name": "ChurnPredictor",
                "description": "A production-ready churn prediction pipeline combining feature store, LightGBM models, and automated retraining triggered by data drift detection. Integrated with marketing to drive targeted offers.",
                "technologies": [
                    "Python",
                    "LightGBM",
                    "Airflow",
                    "Redis",
                    "Docker",
                    "AWS"
                ],
                "year": 2022
            },
            {
                "name": "Real-time Fraud Detection",
                "description": "Streaming fraud detection system using feature enrichment in Kafka, model scoring in a low-latency microservice, and ensemble models to detect anomalous transactions in real time.",
                "technologies": [
                    "Kafka",
                    "Spark Structured Streaming",
                    "scikit-learn",
                    "XGBoost",
                    "Redis"
                ],
                "year": 2020
            },
            {
                "name": "Sales Forecasting Pipeline",
                "description": "End-to-end forecasting solution for SKU-level demand using feature engineering (promotions, seasonality), Prophet and gradient boosting, with automated model selection and monitoring.",
                "technologies": [
                    "Python",
                    "Prophet",
                    "LightGBM",
                    "Pandas",
                    "SQL"
                ],
                "year": 2019
            },
            {
                "name": "ts-helpers (open-source)",
                "description": "Open-source Python toolkit providing utilities for time series cross-validation, feature windows, and backtesting used by internal teams and public contributors.",
                "technologies": [
                    "Python",
                    "pytest",
                    "pandas"
                ],
                "year": 2021
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "scikit-learn",
            "LightGBM",
            "XGBoost",
            "TensorFlow",
            "PyTorch",
            "Spark",
            "Airflow",
            "Docker",
            "AWS",
            "GCP",
            "Tableau",
            "NLP",
            "Time Series"
        ],
        "achievements": [
            "Improved recommendation CTR by 18% and overall revenue contribution from recommendations by 12% at Nimbus Analytics.",
            "Published a conference talk on scalable feature stores at DataEngCon 2023.",
            "Maintainer of an open-source time series utilities package with 150+ stars on GitHub.",
            "Mentored cross-functional team members and led internal workshops on production ML best practices."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2019
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2021
            },
            {
                "name": "Certified Data Scientist (CDS)",
                "date": 2017
            }
        ],
        "total_experience": 9,
        "availability": true
    },
    {
        "name": "Amina R. Patel",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven, and learning-oriented; prefers cross-functional teams, transparent decision-making, and rapid iteration with strong emphasis on reproducibility and mentorship.",
        "contact": {
            "address": {
                "region": "Seattle, WA, USA",
                "detail": "Capitol Hill"
            },
            "phone": "+1-206-555-0143",
            "email": "amina.patel97@example.com",
            "linkedin": "https://www.linkedin.com/in/aminarpatel",
            "github": "https://github.com/aminapatel"
        },
        "summary": "Data scientist with 9+ years of experience building production ML systems, causal inference analyses, and data pipelines to drive business decisions. Strong background in statistical modeling, feature engineering, and deploying interpretable models in cloud environments. Passionate about mentoring engineers and establishing strong MLOps practices.",
        "experience": [
            {
                "name": "Senior Data Scientist, Orion Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led a cross-functional initiative to design and deploy a customer churn prediction pipeline, improving early retention interventions and reducing churn by 18% within 9 months.",
                    "Architected end-to-end ML workflow using Airflow, Docker, and AWS SageMaker; reduced model deployment time from weeks to hours.",
                    "Introduced SHAP-based interpretability and monitoring dashboards (Grafana + Prometheus) to track data drift and model performance, catching two concept drift events proactively.",
                    "Mentored a team of 4 junior data scientists and established code review and testing standards for model reproducibility."
                ]
            },
            {
                "name": "Machine Learning Engineer, NimbleHealth",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed a predictive care-risk scoring model using gradient boosting and survival analysis that increased appropriate care outreach by 24%.",
                    "Built scalable feature store and ETL pipelines using Spark on EMR, cutting feature generation latency by 60%.",
                    "Collaborated with clinical teams to validate model fairness and reduce bias across demographic cohorts; documented mitigation strategies and A/B tested interventions.",
                    "Published internal tech note and presented results to executive stakeholders to secure ongoing funding for analytics initiatives."
                ]
            },
            {
                "name": "Data Analyst, GreenGrid Energy",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Performed time-series analyses and demand forecasting for regional microgrids, improving load balancing and reducing operational cost by 12%.",
                    "Automated reporting and KPI dashboards using SQL, Python, and Tableau; reduced manual reporting time from 8 hours/week to under 1 hour.",
                    "Designed A/B experiments for energy-saving programs and analyzed results to inform program scaling decisions."
                ]
            }
        ],
        "projects": [
            {
                "name": "Real-time Fraud Detection Service",
                "description": "Built a streaming model to detect anomalous transactions with sub-second latency, integrating feature enrichment, model inference, and risk scoring into a scalable microservice.",
                "technologies": [
                    "Kafka",
                    "Flink",
                    "Python",
                    "XGBoost",
                    "Docker",
                    "Kubernetes",
                    "AWS"
                ],
                "year": 2024
            },
            {
                "name": "Causal Impact Framework for Marketing",
                "description": "Implemented a causal inference framework using synthetic controls and uplift modeling to quantify the true incremental impact of marketing campaigns.",
                "technologies": [
                    "Python",
                    "DoWhy",
                    "EconML",
                    "Pandas",
                    "SQL"
                ],
                "year": 2023
            },
            {
                "name": "Feature Store Prototype",
                "description": "Designed a centralized feature store and API for real-time and batch feature access, improving feature reuse and consistency across ML teams.",
                "technologies": [
                    "Feast",
                    "Spark",
                    "Parquet",
                    "AWS S3",
                    "Terraform"
                ],
                "year": 2022
            },
            {
                "name": "Energy Demand Forecast Dashboard",
                "description": "Created interactive dashboards and forecasting models for municipal energy planners to visualize demand scenarios and optimize resource allocation.",
                "technologies": [
                    "Prophet",
                    "Tableau",
                    "Postgres",
                    "Python"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of Washington",
                "date": {
                    "start": 2013,
                    "end": 2015
                },
                "degree": "M.S. in Computer Science (Machine Learning)"
            },
            {
                "name": "University of Texas at Austin",
                "date": {
                    "start": 2009,
                    "end": 2013
                },
                "degree": "B.S. in Statistics"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "Spark",
            "TensorFlow",
            "PyTorch",
            "scikit-learn",
            "XGBoost",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS (SageMaker, S3, EMR)",
            "Feature engineering",
            "Causal inference",
            "Model interpretability",
            "A/B testing"
        ],
        "achievements": [
            "Reduced customer churn by 18% through a production churn prediction system.",
            "Cut feature generation latency by 60% via a scalable Spark-based ETL redesign.",
            "Presented a paper on fairness-aware modeling at an industry workshop (2021).",
            "Mentored 6 junior engineers; 3 promoted to mid-level roles within 18 months."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2021
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Data Scientist (CDS)",
                "date": 2019
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Aisha Rahman",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, research-driven, inclusive. I thrive in teams that prioritize experimentation, clear communication, and continuous learning.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area, CA",
                "detail": "Oakland, CA"
            },
            "phone": "+1-510-555-2198",
            "email": "aisha.rahman@example.com",
            "linkedin": "https://www.linkedin.com/in/aisharahman",
            "github": "https://github.com/aisharahman"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems and data products for healthcare and analytics startups. Strong background in end-to-end model development, MLOps, causal inference, and translating business problems into measurable ML solutions. Experienced mentoring cross-functional teams and shipping high-impact features that improve retention and revenue.",
        "experience": [
            {
                "name": "Meridian HealthTech \u2014 Senior Data Scientist",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led cross-functional initiative to build a patient risk-scoring platform using PyTorch and XGBoost; improved early-detection sensitivity by 28% and reduced downstream hospitalization costs by 15%.",
                    "Designed and implemented end-to-end MLOps pipeline (Airflow, Docker, AWS SageMaker) for model training, validation, and deployment, cutting model release time from 6 weeks to 10 days.",
                    "Collaborated with product and clinical teams to define metrics and A/B tests; used causal inference methods to attribute a 12% lift in engagement to personalized outreach.",
                    "Mentored 4 junior data scientists and established best practices for model monitoring, data quality checks, and experiment tracking (MLflow)."
                ]
            },
            {
                "name": "Nova Analytics \u2014 Data Scientist",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed demand forecasting models (hierarchical time series + Prophet ensembles) that reduced inventory overstock by 22% for retail clients.",
                    "Built recommendation and personalization components using matrix factorization and feature-based gradient boosting models; increased average order value by 9%.",
                    "Implemented CI/CD for model training and feature pipelines with dbt and Jenkins; standardized model evaluation and deployment across projects.",
                    "Performed cohort analyses and designed experiments to optimize pricing and promotions; presented insights to executive stakeholders."
                ]
            },
            {
                "name": "OpenStreet Labs \u2014 Data Engineer / Analyst",
                "date": {
                    "start": 2015,
                    "end": 2018
                },
                "bullets": [
                    "Built ETL pipelines in Python and SQL to ingest and normalize large geospatial datasets; reduced data latency from 48h to 4h.",
                    "Developed dashboards and reporting (Looker, Tableau) for operations and product teams to monitor KPIs and inform roadmap decisions.",
                    "Optimized data models and schema designs for analytics workloads on PostgreSQL and Redshift, improving query performance by up to 5x."
                ]
            }
        ],
        "projects": [
            {
                "name": "Clinical Deterioration Early Warning System",
                "description": "Developed and deployed a real-time model that predicts patient deterioration within 48 hours using EHR time-series and lab data. Integrated into clinician workflow to prioritize patient reviews.",
                "technologies": [
                    "PyTorch",
                    "pandas",
                    "Airflow",
                    "AWS SageMaker",
                    "Docker"
                ],
                "year": 2022
            },
            {
                "name": "Customer Lifetime Value (LTV) Modeling Framework",
                "description": "Built probabilistic LTV models combining survival analysis and transaction-level feature engineering to inform acquisition budget allocation and targeting.",
                "technologies": [
                    "scikit-learn",
                    "XGBoost",
                    "SQL",
                    "MLflow"
                ],
                "year": 2020
            },
            {
                "name": "Open-Source Geospatial ETL Toolkit",
                "description": "Authored a lightweight Python toolkit for cleaning and transforming geospatial datasets with built-in validation and parallel processing. Used by several civic-tech projects.",
                "technologies": [
                    "Python",
                    "GeoPandas",
                    "PostGIS"
                ],
                "year": 2017
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley \u2014 M.S. Computer Science (Data Science)",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Computer Science"
            },
            {
                "name": "University of Illinois Urbana-Champaign \u2014 B.S. Computer Science",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "scikit-learn",
            "XGBoost",
            "Time Series Forecasting",
            "Causal Inference",
            "MLOps (Airflow, MLflow, SageMaker)",
            "Docker & Kubernetes",
            "Data Modeling",
            "A/B Testing",
            "Tableau / Looker",
            "Cloud: AWS"
        ],
        "achievements": [
            "Published conference paper on time-series imbalance handling at NeurIPS Workshop (2021).",
            "Speaker at PyData SF: 'From Prototype to Production: Building Responsible Health ML' (2023).",
            "Delivered a model that reduced patient readmission cost by 15% at Meridian HealthTech."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning - Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            }
        ],
        "total_experience": 10,
        "availability": true
    },
    {
        "name": "Jordan Park",
        "title": "Data Scientist",
        "work_type": "Hybrid",
        "prefer_culture": "Collaborative, data-driven teams that prioritize rapid experimentation, clear metrics, and mentorship. I value inclusive environments where engineers and product teams iterate quickly and learn from measured outcomes.",
        "contact": {
            "address": {
                "region": "San Francisco Bay Area",
                "detail": "Oakland, CA"
            },
            "phone": "+1 (415) 555-0199",
            "email": "jordan.park99@example.com",
            "linkedin": "https://www.linkedin.com/in/jordan-park99",
            "github": "https://github.com/jordanpark99"
        },
        "summary": "Data Scientist with 9+ years of experience building production ML systems and analytics to drive product and business decisions. Strong background in predictive modeling, causal inference, and scalable data pipelines. Experienced in leading cross-functional teams to ship models into production and establishing model governance and monitoring.",
        "experience": [
            {
                "name": "Senior Data Scientist, HelioHealth Analytics",
                "date": {
                    "start": 2021,
                    "end": null
                },
                "bullets": [
                    "Led end-to-end development and deployment of a risk stratification model for patient readmission using XGBoost and deep ensembled models, improving early-intervention targeting and reducing 30-day readmission by 9%.",
                    "Designed and ran online A/B tests and Bayesian analyses to evaluate model-driven interventions, accelerating decision cycles from months to weeks.",
                    "Built automated feature pipelines with Spark and Airflow and containerized model scoring with Docker and Kubernetes for real-time inference (99th percentile latency <150ms).",
                    "Mentored a team of 4 data scientists and codified model review and monitoring process using MLflow and Prometheus, reducing post-deployment defects by 40%."
                ]
            },
            {
                "name": "Data Scientist, Moovate (SaaS mobility startup)",
                "date": {
                    "start": 2018,
                    "end": 2021
                },
                "bullets": [
                    "Developed hybrid collaborative-filtering + content-based recommender that increased click-through rate by 18% and conversion by 12%.",
                    "Built time-series demand forecasting models (Prophet + LSTM ensembles) to optimize fleet allocation, cutting idle time by 22% and saving ~$1.1M annual operating cost.",
                    "Improved event instrumentation and SQL-based analytics, empowering product teams with self-serve dashboards and executable diagnostics."
                ]
            },
            {
                "name": "Data Analyst, Blueport Solutions",
                "date": {
                    "start": 2016,
                    "end": 2018
                },
                "bullets": [
                    "Created dashboard-driven KPIs and automated weekly reporting that reduced manual reporting time by 75%.",
                    "Performed cohort analyses and retention modeling to surface growth opportunities; collaborated with engineering to A/B test product experiments.",
                    "Implemented ETL pipelines in Python and Airflow to consolidate disparate data sources into a centralized analytics warehouse."
                ]
            }
        ],
        "projects": [
            {
                "name": "Predictive Readmission Model",
                "description": "Built and deployed an ensemble model to predict 30-day hospital readmission risk. Integrated model outputs into clinician workflows with prioritized patient lists and explanation cards using SHAP.",
                "technologies": [
                    "Python",
                    "XGBoost",
                    "scikit-learn",
                    "SHAP",
                    "Docker",
                    "AWS"
                ],
                "year": 2019
            },
            {
                "name": "Real-time Fraud Detection Pipeline",
                "description": "Designed a streaming feature store and low-latency scoring pipeline for transaction fraud detection using Kafka, Spark Structured Streaming, and a LightGBM model with drift monitoring.",
                "technologies": [
                    "Kafka",
                    "Spark",
                    "LightGBM",
                    "Prometheus",
                    "Kubernetes"
                ],
                "year": 2022
            },
            {
                "name": "pdpreprocess (open-source)",
                "description": "Open-source Python library for robust preprocessing of tabular data (imputation, target encoding, leakage checks). Used by internal teams to standardize feature engineering.",
                "technologies": [
                    "Python",
                    "pandas",
                    "pytest"
                ],
                "year": 2020
            }
        ],
        "education": [
            {
                "name": "University of California, Berkeley",
                "date": {
                    "start": 2014,
                    "end": 2016
                },
                "degree": "M.S. Data Science"
            },
            {
                "name": "University of Washington",
                "date": {
                    "start": 2010,
                    "end": 2014
                },
                "degree": "B.S. Computer Science"
            }
        ],
        "skills": [
            "Python",
            "SQL",
            "PyTorch",
            "TensorFlow",
            "scikit-learn",
            "pandas",
            "NumPy",
            "Spark",
            "Airflow",
            "Docker",
            "Kubernetes",
            "AWS (S3, Lambda, SageMaker)",
            "GCP",
            "MLflow",
            "A/B testing",
            "Causal inference",
            "Time-series forecasting",
            "Data visualization (Tableau, Looker)"
        ],
        "achievements": [
            "Reduced product churn by 12% through a retention model and targeted campaigns, delivering ~$2M annualized savings.",
            "Established company-wide model governance and CI/CD best practices adopted across three engineering teams.",
            "Presented work on productionizing ML pipelines at a regional ML meetup (2023)."
        ],
        "certifications": [
            {
                "name": "AWS Certified Machine Learning \u2013 Specialty",
                "date": 2022
            },
            {
                "name": "TensorFlow Developer Certificate",
                "date": 2020
            },
            {
                "name": "Certified Data Scientist (DataCamp)",
                "date": 2017
            }
        ],
        "total_experience": 9,
        "availability": true
    }
]